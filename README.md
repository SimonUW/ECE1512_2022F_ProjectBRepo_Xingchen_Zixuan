# ECE1512_2022F_ProjectB

This repository contains:

1. Directory "DC_GM" which contains all the code and results for dataset condensation with gradient matching method in task 1.
2. Directory "Nerual_Architecture_Search" which contains all the code and results for the implementation of neural architecture search on condensed MNIST and CIFAR10 datasets in taks 1.
3. Directory "DC_TM" which contains all the code and results for dataset condensation with trajectory matching method in task 2.
4. Directory "DC_DM" which contains all the code and results for dataset condensation with distribution matching method in task 2.
5. README.md to introduce the task.


## Table of Contents

- [Introduction](#Introduction)
- [Tool](#Tool)
- [Contributors](#Contributors)
- [License](#license)


## Introduction

The goal of this project is to equip students with the tools and technologies required to condense a large training set into a small synthetic set S such that the model trained on the small synthetic set can obtain comparable testing performance to that trained on the large training set. Specifically, the project implemented and analysed three different dataset condensation methods: dataset condensation with gradient matching, dataset condensation with trajectory matching, and dataset condensation with distribution matching.


## Tool

In this project, we use a GPU by accessing <a href="https://colab.research.google.com/">Google Colab</a>.


### Contributors

These are the people who contribute this project. </br>
<a href="https://github.com/SimonUW">Zixuan Li</a></br>
<a href="https://github.com/huxingchen1119">Xingchen Hu

## License

[UofT](LICENSE) Â© Zixuan Li & Xingchen Hu
