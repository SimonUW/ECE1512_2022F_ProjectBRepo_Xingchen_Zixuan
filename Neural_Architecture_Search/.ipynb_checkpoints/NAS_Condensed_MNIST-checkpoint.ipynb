{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82c713f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from utils import get_loops, get_dataset, get_network, get_eval_pool, evaluate_synset, get_daparam, match_loss, get_time, TensorDataset, epoch, DiffAugment, ParamDiffAug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83339829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Start training on the first LeNet architecture on the condensed MNIST dataset\n",
      "Training takes 2.3343489170074463 seconds\n",
      "Test accuracy is 72.5%\n",
      "Start training on the second LeNet architecture on the condensed MNIST dataset\n",
      "Training takes 2.2657482624053955 seconds\n",
      "Test accuracy is 77.58%\n",
      "Start training on the third LeNet architecture on the condensed MNIST dataset\n",
      "Training takes 2.2814524173736572 seconds\n",
      "Test accuracy is 66.73%\n",
      "----------------------------------------\n",
      "Average training time is 2.2938498655954995 seconds\n",
      "Average test accuracy is 72.27%\n",
      "========================================\n",
      "Start training on the first AlexNet architecture on the condensed MNIST dataset\n",
      "Training takes 3.1708226203918457 seconds\n",
      "Test accuracy is 86.15%\n",
      "Start training on the second AlexNet architecture on the condensed MNIST dataset\n",
      "Training takes 3.108701229095459 seconds\n",
      "Test accuracy is 85.49%\n",
      "Start training on the third AlexNet architecture on the condensed MNIST dataset\n",
      "Training takes 3.0839149951934814 seconds\n",
      "Test accuracy is 85.00999999999999%\n",
      "----------------------------------------\n",
      "Average training time is 3.121146281560262 seconds\n",
      "Average test accuracy is 85.55%\n",
      "========================================\n",
      "Start training on the first VGG11 architecture on the condensed MNIST dataset\n",
      "Training takes 3.9725756645202637 seconds\n",
      "Test accuracy is 89.25999999999999%\n",
      "Start training on the second VGG11 architecture on the condensed MNIST dataset\n",
      "Training takes 4.083381652832031 seconds\n",
      "Test accuracy is 88.82%\n",
      "Start training on the third VGG11 architecture on the condensed MNIST dataset\n",
      "Training takes 4.071716547012329 seconds\n",
      "Test accuracy is 88.48%\n",
      "----------------------------------------\n",
      "Average training time is 4.042557954788208 seconds\n",
      "Average test accuracy is 88.85333333333334%\n",
      "========================================\n",
      "Start training on the first ConvNetD4 architecture on the condensed MNIST dataset\n",
      "Training takes 3.11156964302063 seconds\n",
      "Test accuracy is 91.79%\n",
      "Start training on the second ConvNetD4 architecture on the condensed MNIST dataset\n",
      "Training takes 3.0859568119049072 seconds\n",
      "Test accuracy is 93.32000000000001%\n",
      "Start training on the third ConvNetD4 architecture on the condensed MNIST dataset\n",
      "Training takes 3.1088273525238037 seconds\n",
      "Test accuracy is 92.29%\n",
      "----------------------------------------\n",
      "Average training time is 3.102117935816447 seconds\n",
      "Average test accuracy is 92.46666666666668%\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, test_loader, optimizer, scheduler, criterion, epochs):\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss_avg, acc_avg, num_exp = 0, 0, 0\n",
    "        for i_batch, datum in enumerate(train_loader):\n",
    "            img = datum[0].float().to(device)\n",
    "            lab = datum[1].long().to(device)\n",
    "            n_b = lab.shape[0]\n",
    "            output = model(img)\n",
    "            loss = criterion(output, lab)\n",
    "            acc = np.sum(np.equal(np.argmax(output.cpu().data.numpy(), axis=-1), lab.cpu().data.numpy()))\n",
    "            loss_avg += loss.item()*n_b\n",
    "            acc_avg += acc\n",
    "            num_exp += n_b\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            del img, lab\n",
    "                \n",
    "        loss_avg /= num_exp\n",
    "        acc_avg /= num_exp\n",
    "        scheduler.step()\n",
    "\n",
    "    loss_avg, acc_avg, num_exp = 0, 0, 0   \n",
    "    model.eval()\n",
    "    for i_batch, datum in enumerate(test_loader):\n",
    "        img = datum[0].float().to(device)\n",
    "        lab = datum[1].long().to(device)\n",
    "        n_b = lab.shape[0]\n",
    "        output = model(img)\n",
    "        loss = criterion(output, lab)\n",
    "        acc = np.sum(np.equal(np.argmax(output.cpu().data.numpy(), axis=-1), lab.cpu().data.numpy()))\n",
    "        loss_avg += loss.item()*n_b\n",
    "        acc_avg += acc\n",
    "        num_exp += n_b\n",
    "        \n",
    "        del img, lab\n",
    "\n",
    "    loss_avg /= num_exp\n",
    "    acc_avg /= num_exp\n",
    "    \n",
    "    return loss_avg, acc_avg\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform): # images: n x c x h x w tensor\n",
    "        self.images = images.detach().float()\n",
    "        self.labels = labels.detach()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transform(self.images[index]), self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "data_path = './MNISTresult/realres_DC_MNIST_ConvNet_10ipc.pt'\n",
    "data = torch.load(data_path)\n",
    "images = data['data'][0][0]\n",
    "\n",
    "MNIST_dataset = 'MNIST'\n",
    "MNIST_data_path = './MNISTdata'\n",
    "MNIST_channel, MNIST_im_size, MNIST_num_classes, MNIST_class_names, MNIST_mean, MNIST_std, MNIST_dst_train, MNIST_dst_test, MNIST_testloader = get_dataset(MNIST_dataset, MNIST_data_path)\n",
    "condensed_labs_train = torch.ones(10*MNIST_num_classes)\n",
    "mean = [0.1307]\n",
    "std = [0.3081]\n",
    "transform = transforms.Compose([transforms.Normalize(mean=mean, std=std)])\n",
    "\n",
    "for c in range(MNIST_num_classes):  \n",
    "    condensed_labs_train[c*10:(c+1)*10]*=c\n",
    "    \n",
    "condensed_train_dst = CustomDataset(images, condensed_labs_train, transform)\n",
    "MNIST_trainloader = torch.utils.data.DataLoader(condensed_train_dst, batch_size=8, shuffle=True, num_workers=0)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 20\n",
    "model_set = ['LeNet', 'AlexNet', 'VGG11', 'ConvNetD4']\n",
    "iteration_set = ['first', 'second', 'third']\n",
    "for model_architecture in model_set:\n",
    "    print('========================================')\n",
    "    accs_each_model = []\n",
    "    training_times_each_model = []\n",
    "    for itr in iteration_set:\n",
    "        print('Start training on the '+itr+' '+model_architecture+' architecture on the condensed MNIST dataset')\n",
    "        model = get_network(model_architecture, MNIST_channel, MNIST_num_classes, MNIST_im_size).to(device) # get a random model\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=0)\n",
    "        start = time.time()\n",
    "        _, acc_avg = train(model, MNIST_trainloader , MNIST_testloader , optimizer, scheduler, criterion, epochs)\n",
    "        elapsed_time = time.time()-start\n",
    "        training_times_each_model.append(elapsed_time)\n",
    "        accs_each_model.append(acc_avg*100)\n",
    "        print('Training takes {} seconds'.format(training_times_each_model[-1]))\n",
    "        print('Test accuracy is {}%'.format(accs_each_model[-1]))\n",
    "    print('----------------------------------------')\n",
    "    print('Average training time is {} seconds'.format(sum(training_times_each_model)/len(training_times_each_model)))\n",
    "    print('Average test accuracy is {}%'.format(sum(accs_each_model)/len(accs_each_model)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
