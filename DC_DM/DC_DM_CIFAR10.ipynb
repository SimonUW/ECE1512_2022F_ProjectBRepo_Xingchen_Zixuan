{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aeccb70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_it_pool:  [0, 200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "================== Exp 0 ==================\n",
      " \n",
      "Hyper-parameters: \n",
      " {'method': 'DM', 'dataset': 'CIFAR10', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'S', 'num_exp': 1, 'num_eval': 1, 'epoch_eval_train': 100, 'Iteration': 2000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': 'CIFAR10data', 'save_path': 'CIFAR10result', 'dis_metric': 'ours', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x00000206A5E64130>, 'dsa': True}\n",
      "class c = 0: 5000 real images\n",
      "class c = 1: 5000 real images\n",
      "class c = 2: 5000 real images\n",
      "class c = 3: 5000 real images\n",
      "class c = 4: 5000 real images\n",
      "class c = 5: 5000 real images\n",
      "class c = 6: 5000 real images\n",
      "class c = 7: 5000 real images\n",
      "class c = 8: 5000 real images\n",
      "class c = 9: 5000 real images\n",
      "real images channel 0, mean = -0.0000, std = 1.2211\n",
      "real images channel 1, mean = -0.0002, std = 1.2211\n",
      "real images channel 2, mean = 0.0002, std = 1.3014\n",
      "initialize synthetic data from random real images\n",
      "[2022-12-01 20:56:25] training begins\n",
      "[2022-12-01 20:56:30] iter = 00000, loss = 26.1947\n",
      "[2022-12-01 20:56:32] iter = 00010, loss = 16.8715\n",
      "[2022-12-01 20:56:34] iter = 00020, loss = 14.8277\n",
      "[2022-12-01 20:56:35] iter = 00030, loss = 11.8367\n",
      "[2022-12-01 20:56:37] iter = 00040, loss = 12.1699\n",
      "[2022-12-01 20:56:39] iter = 00050, loss = 10.2204\n",
      "[2022-12-01 20:56:41] iter = 00060, loss = 9.5727\n",
      "[2022-12-01 20:56:42] iter = 00070, loss = 8.8020\n",
      "[2022-12-01 20:56:44] iter = 00080, loss = 8.8545\n",
      "[2022-12-01 20:56:46] iter = 00090, loss = 8.2297\n",
      "[2022-12-01 20:56:48] iter = 00100, loss = 7.9509\n",
      "[2022-12-01 20:56:49] iter = 00110, loss = 7.8132\n",
      "[2022-12-01 20:56:51] iter = 00120, loss = 7.7272\n",
      "[2022-12-01 20:56:53] iter = 00130, loss = 8.1465\n",
      "[2022-12-01 20:56:54] iter = 00140, loss = 7.6926\n",
      "[2022-12-01 20:56:56] iter = 00150, loss = 7.9351\n",
      "[2022-12-01 20:56:58] iter = 00160, loss = 7.0497\n",
      "[2022-12-01 20:57:00] iter = 00170, loss = 6.9672\n",
      "[2022-12-01 20:57:01] iter = 00180, loss = 6.9673\n",
      "[2022-12-01 20:57:03] iter = 00190, loss = 6.9119\n",
      "[2022-12-01 20:57:05] iter = 00200, loss = 6.9362\n",
      "[2022-12-01 20:57:07] iter = 00210, loss = 6.7053\n",
      "[2022-12-01 20:57:08] iter = 00220, loss = 6.7742\n",
      "[2022-12-01 20:57:10] iter = 00230, loss = 6.7018\n",
      "[2022-12-01 20:57:12] iter = 00240, loss = 6.7049\n",
      "[2022-12-01 20:57:13] iter = 00250, loss = 6.5839\n",
      "[2022-12-01 20:57:15] iter = 00260, loss = 6.5068\n",
      "[2022-12-01 20:57:17] iter = 00270, loss = 6.7480\n",
      "[2022-12-01 20:57:19] iter = 00280, loss = 6.3689\n",
      "[2022-12-01 20:57:20] iter = 00290, loss = 6.3203\n",
      "[2022-12-01 20:57:22] iter = 00300, loss = 6.0957\n",
      "[2022-12-01 20:57:24] iter = 00310, loss = 6.8578\n",
      "[2022-12-01 20:57:25] iter = 00320, loss = 6.2092\n",
      "[2022-12-01 20:57:27] iter = 00330, loss = 6.5316\n",
      "[2022-12-01 20:57:29] iter = 00340, loss = 5.8548\n",
      "[2022-12-01 20:57:31] iter = 00350, loss = 6.3059\n",
      "[2022-12-01 20:57:32] iter = 00360, loss = 6.1488\n",
      "[2022-12-01 20:57:34] iter = 00370, loss = 5.9069\n",
      "[2022-12-01 20:57:36] iter = 00380, loss = 5.7761\n",
      "[2022-12-01 20:57:37] iter = 00390, loss = 6.1728\n",
      "[2022-12-01 20:57:39] iter = 00400, loss = 5.7361\n",
      "[2022-12-01 20:57:41] iter = 00410, loss = 5.7992\n",
      "[2022-12-01 20:57:43] iter = 00420, loss = 6.0266\n",
      "[2022-12-01 20:57:44] iter = 00430, loss = 5.9771\n",
      "[2022-12-01 20:57:46] iter = 00440, loss = 5.6117\n",
      "[2022-12-01 20:57:48] iter = 00450, loss = 5.8011\n",
      "[2022-12-01 20:57:49] iter = 00460, loss = 5.7938\n",
      "[2022-12-01 20:57:51] iter = 00470, loss = 5.7672\n",
      "[2022-12-01 20:57:53] iter = 00480, loss = 5.5069\n",
      "[2022-12-01 20:57:55] iter = 00490, loss = 5.8921\n",
      "[2022-12-01 20:57:56] iter = 00500, loss = 5.8415\n",
      "[2022-12-01 20:57:58] iter = 00510, loss = 5.7055\n",
      "[2022-12-01 20:58:00] iter = 00520, loss = 5.5355\n",
      "[2022-12-01 20:58:01] iter = 00530, loss = 5.7256\n",
      "[2022-12-01 20:58:03] iter = 00540, loss = 5.4559\n",
      "[2022-12-01 20:58:05] iter = 00550, loss = 5.5306\n",
      "[2022-12-01 20:58:06] iter = 00560, loss = 5.5047\n",
      "[2022-12-01 20:58:08] iter = 00570, loss = 5.3504\n",
      "[2022-12-01 20:58:10] iter = 00580, loss = 5.0713\n",
      "[2022-12-01 20:58:12] iter = 00590, loss = 5.6511\n",
      "[2022-12-01 20:58:13] iter = 00600, loss = 5.8482\n",
      "[2022-12-01 20:58:15] iter = 00610, loss = 5.5236\n",
      "[2022-12-01 20:58:17] iter = 00620, loss = 5.7998\n",
      "[2022-12-01 20:58:18] iter = 00630, loss = 5.3944\n",
      "[2022-12-01 20:58:20] iter = 00640, loss = 5.3619\n",
      "[2022-12-01 20:58:22] iter = 00650, loss = 5.3697\n",
      "[2022-12-01 20:58:24] iter = 00660, loss = 5.1433\n",
      "[2022-12-01 20:58:25] iter = 00670, loss = 5.8165\n",
      "[2022-12-01 20:58:27] iter = 00680, loss = 5.3001\n",
      "[2022-12-01 20:58:29] iter = 00690, loss = 5.4435\n",
      "[2022-12-01 20:58:30] iter = 00700, loss = 5.2386\n",
      "[2022-12-01 20:58:32] iter = 00710, loss = 5.3815\n",
      "[2022-12-01 20:58:34] iter = 00720, loss = 5.1898\n",
      "[2022-12-01 20:58:36] iter = 00730, loss = 5.4713\n",
      "[2022-12-01 20:58:37] iter = 00740, loss = 5.8031\n",
      "[2022-12-01 20:58:39] iter = 00750, loss = 5.0640\n",
      "[2022-12-01 20:58:41] iter = 00760, loss = 5.2208\n",
      "[2022-12-01 20:58:43] iter = 00770, loss = 5.1624\n",
      "[2022-12-01 20:58:44] iter = 00780, loss = 5.2649\n",
      "[2022-12-01 20:58:46] iter = 00790, loss = 5.2656\n",
      "[2022-12-01 20:58:48] iter = 00800, loss = 5.3041\n",
      "[2022-12-01 20:58:49] iter = 00810, loss = 5.1670\n",
      "[2022-12-01 20:58:51] iter = 00820, loss = 5.1006\n",
      "[2022-12-01 20:58:53] iter = 00830, loss = 5.5080\n",
      "[2022-12-01 20:58:54] iter = 00840, loss = 5.6049\n",
      "[2022-12-01 20:58:56] iter = 00850, loss = 5.2059\n",
      "[2022-12-01 20:58:58] iter = 00860, loss = 5.2740\n",
      "[2022-12-01 20:59:00] iter = 00870, loss = 5.1462\n",
      "[2022-12-01 20:59:01] iter = 00880, loss = 5.1473\n",
      "[2022-12-01 20:59:03] iter = 00890, loss = 5.6732\n",
      "[2022-12-01 20:59:05] iter = 00900, loss = 4.9119\n",
      "[2022-12-01 20:59:06] iter = 00910, loss = 5.0230\n",
      "[2022-12-01 20:59:08] iter = 00920, loss = 5.1176\n",
      "[2022-12-01 20:59:10] iter = 00930, loss = 5.0109\n",
      "[2022-12-01 20:59:12] iter = 00940, loss = 4.8784\n",
      "[2022-12-01 20:59:13] iter = 00950, loss = 5.0376\n",
      "[2022-12-01 20:59:15] iter = 00960, loss = 5.4135\n",
      "[2022-12-01 20:59:17] iter = 00970, loss = 4.8279\n",
      "[2022-12-01 20:59:18] iter = 00980, loss = 4.9415\n",
      "[2022-12-01 20:59:20] iter = 00990, loss = 4.8370\n",
      "[2022-12-01 20:59:22] iter = 01000, loss = 5.1334\n",
      "[2022-12-01 20:59:23] iter = 01010, loss = 5.2167\n",
      "[2022-12-01 20:59:25] iter = 01020, loss = 5.0005\n",
      "[2022-12-01 20:59:27] iter = 01030, loss = 5.3218\n",
      "[2022-12-01 20:59:29] iter = 01040, loss = 5.0058\n",
      "[2022-12-01 20:59:30] iter = 01050, loss = 5.0246\n",
      "[2022-12-01 20:59:32] iter = 01060, loss = 5.3578\n",
      "[2022-12-01 20:59:34] iter = 01070, loss = 4.6264\n",
      "[2022-12-01 20:59:35] iter = 01080, loss = 4.9683\n",
      "[2022-12-01 20:59:37] iter = 01090, loss = 4.9695\n",
      "[2022-12-01 20:59:39] iter = 01100, loss = 5.2387\n",
      "[2022-12-01 20:59:41] iter = 01110, loss = 5.0347\n",
      "[2022-12-01 20:59:42] iter = 01120, loss = 5.0587\n",
      "[2022-12-01 20:59:44] iter = 01130, loss = 5.0613\n",
      "[2022-12-01 20:59:46] iter = 01140, loss = 4.9479\n",
      "[2022-12-01 20:59:47] iter = 01150, loss = 4.9048\n",
      "[2022-12-01 20:59:49] iter = 01160, loss = 4.5150\n",
      "[2022-12-01 20:59:51] iter = 01170, loss = 4.9918\n",
      "[2022-12-01 20:59:53] iter = 01180, loss = 4.9453\n",
      "[2022-12-01 20:59:54] iter = 01190, loss = 5.2743\n",
      "[2022-12-01 20:59:56] iter = 01200, loss = 4.7348\n",
      "[2022-12-01 20:59:58] iter = 01210, loss = 4.8477\n",
      "[2022-12-01 21:00:00] iter = 01220, loss = 4.7015\n",
      "[2022-12-01 21:00:01] iter = 01230, loss = 4.7761\n",
      "[2022-12-01 21:00:03] iter = 01240, loss = 4.9447\n",
      "[2022-12-01 21:00:05] iter = 01250, loss = 5.1810\n",
      "[2022-12-01 21:00:06] iter = 01260, loss = 4.9332\n",
      "[2022-12-01 21:00:08] iter = 01270, loss = 5.1473\n",
      "[2022-12-01 21:00:10] iter = 01280, loss = 5.0456\n",
      "[2022-12-01 21:00:12] iter = 01290, loss = 4.7087\n",
      "[2022-12-01 21:00:14] iter = 01300, loss = 4.7775\n",
      "[2022-12-01 21:00:18] iter = 01310, loss = 4.8508\n",
      "[2022-12-01 21:00:22] iter = 01320, loss = 4.9710\n",
      "[2022-12-01 21:00:25] iter = 01330, loss = 4.8319\n",
      "[2022-12-01 21:00:30] iter = 01340, loss = 5.0360\n",
      "[2022-12-01 21:00:34] iter = 01350, loss = 5.0277\n",
      "[2022-12-01 21:00:37] iter = 01360, loss = 5.0388\n",
      "[2022-12-01 21:00:41] iter = 01370, loss = 4.8687\n",
      "[2022-12-01 21:00:45] iter = 01380, loss = 5.2094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-12-01 21:00:48] iter = 01390, loss = 5.1676\n",
      "[2022-12-01 21:00:53] iter = 01400, loss = 4.9596\n",
      "[2022-12-01 21:00:57] iter = 01410, loss = 4.8319\n",
      "[2022-12-01 21:01:00] iter = 01420, loss = 5.1900\n",
      "[2022-12-01 21:01:04] iter = 01430, loss = 4.8074\n",
      "[2022-12-01 21:01:09] iter = 01440, loss = 4.9288\n",
      "[2022-12-01 21:01:13] iter = 01450, loss = 4.7676\n",
      "[2022-12-01 21:01:16] iter = 01460, loss = 4.8914\n",
      "[2022-12-01 21:01:20] iter = 01470, loss = 4.8280\n",
      "[2022-12-01 21:01:25] iter = 01480, loss = 4.5113\n",
      "[2022-12-01 21:01:28] iter = 01490, loss = 4.7616\n",
      "[2022-12-01 21:01:32] iter = 01500, loss = 4.6956\n",
      "[2022-12-01 21:01:36] iter = 01510, loss = 4.9331\n",
      "[2022-12-01 21:01:39] iter = 01520, loss = 4.7885\n",
      "[2022-12-01 21:01:44] iter = 01530, loss = 4.4702\n",
      "[2022-12-01 21:01:48] iter = 01540, loss = 4.7576\n",
      "[2022-12-01 21:01:52] iter = 01550, loss = 4.7279\n",
      "[2022-12-01 21:01:55] iter = 01560, loss = 4.8036\n",
      "[2022-12-01 21:02:00] iter = 01570, loss = 4.7272\n",
      "[2022-12-01 21:02:04] iter = 01580, loss = 4.6700\n",
      "[2022-12-01 21:02:07] iter = 01590, loss = 4.4526\n",
      "[2022-12-01 21:02:11] iter = 01600, loss = 4.9925\n",
      "[2022-12-01 21:02:16] iter = 01610, loss = 4.7712\n",
      "[2022-12-01 21:02:19] iter = 01620, loss = 4.8691\n",
      "[2022-12-01 21:02:23] iter = 01630, loss = 4.3329\n",
      "[2022-12-01 21:02:28] iter = 01640, loss = 4.5920\n",
      "[2022-12-01 21:02:31] iter = 01650, loss = 4.8545\n",
      "[2022-12-01 21:02:35] iter = 01660, loss = 4.6133\n",
      "[2022-12-01 21:02:39] iter = 01670, loss = 4.3770\n",
      "[2022-12-01 21:02:44] iter = 01680, loss = 5.0709\n",
      "[2022-12-01 21:02:47] iter = 01690, loss = 4.6861\n",
      "[2022-12-01 21:02:51] iter = 01700, loss = 4.8508\n",
      "[2022-12-01 21:02:55] iter = 01710, loss = 4.5467\n",
      "[2022-12-01 21:02:58] iter = 01720, loss = 4.7118\n",
      "[2022-12-01 21:03:03] iter = 01730, loss = 4.6252\n",
      "[2022-12-01 21:03:07] iter = 01740, loss = 4.8342\n",
      "[2022-12-01 21:03:10] iter = 01750, loss = 4.4131\n",
      "[2022-12-01 21:03:14] iter = 01760, loss = 4.6399\n",
      "[2022-12-01 21:03:19] iter = 01770, loss = 4.7197\n",
      "[2022-12-01 21:03:23] iter = 01780, loss = 4.6327\n",
      "[2022-12-01 21:03:26] iter = 01790, loss = 4.6090\n",
      "[2022-12-01 21:03:30] iter = 01800, loss = 4.6509\n",
      "[2022-12-01 21:03:35] iter = 01810, loss = 4.6205\n",
      "[2022-12-01 21:03:38] iter = 01820, loss = 4.5942\n",
      "[2022-12-01 21:03:42] iter = 01830, loss = 4.8916\n",
      "[2022-12-01 21:03:46] iter = 01840, loss = 4.6069\n",
      "[2022-12-01 21:03:49] iter = 01850, loss = 4.7879\n",
      "[2022-12-01 21:03:54] iter = 01860, loss = 4.5187\n",
      "[2022-12-01 21:03:58] iter = 01870, loss = 4.7162\n",
      "[2022-12-01 21:04:03] iter = 01880, loss = 4.6415\n",
      "[2022-12-01 21:04:06] iter = 01890, loss = 4.5424\n",
      "[2022-12-01 21:04:10] iter = 01900, loss = 4.7719\n",
      "[2022-12-01 21:04:14] iter = 01910, loss = 4.7868\n",
      "[2022-12-01 21:04:17] iter = 01920, loss = 4.6102\n",
      "[2022-12-01 21:04:22] iter = 01930, loss = 4.8064\n",
      "[2022-12-01 21:04:26] iter = 01940, loss = 4.4437\n",
      "[2022-12-01 21:04:30] iter = 01950, loss = 4.7031\n",
      "[2022-12-01 21:04:33] iter = 01960, loss = 4.8033\n",
      "[2022-12-01 21:04:38] iter = 01970, loss = 4.6338\n",
      "[2022-12-01 21:04:42] iter = 01980, loss = 4.7249\n",
      "[2022-12-01 21:04:45] iter = 01990, loss = 4.4587\n",
      "[2022-12-01 21:04:49] iter = 02000, loss = 4.5343\n",
      "\n",
      "==================== Final Results ====================\n",
      "\n",
      "After 2000 iterations, the model test accuracy on synthetic data is 44.75%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import tqdm\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from utils import get_loops, get_dataset, get_network, get_eval_pool, evaluate_synset, get_daparam, match_loss, get_time, TensorDataset, epoch, DiffAugment, ParamDiffAug\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "def main(args):\n",
    "    if not os.path.exists(args.data_path):\n",
    "        os.mkdir(args.data_path)\n",
    "\n",
    "    if not os.path.exists(args.save_path):\n",
    "        os.mkdir(args.save_path)\n",
    "\n",
    "    eval_it_pool = np.arange(0, args.Iteration+1, 200).tolist() if args.eval_mode == 'S' or args.eval_mode == 'SS' else [args.Iteration] # The list of iterations when we evaluate models and record results.\n",
    "    print('eval_it_pool: ', eval_it_pool)\n",
    "    channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader = get_dataset(args.dataset, args.data_path)\n",
    "\n",
    "    data_save = []\n",
    "\n",
    "    for exp in range(args.num_exp):\n",
    "        print('\\n================== Exp %d ==================\\n '%exp)\n",
    "        print('Hyper-parameters: \\n', args.__dict__)\n",
    "\n",
    "        ''' organize the real dataset '''\n",
    "        images_all = []\n",
    "        labels_all = []\n",
    "        indices_class = [[] for c in range(num_classes)]\n",
    "\n",
    "        images_all = [torch.unsqueeze(dst_train[i][0], dim=0) for i in range(len(dst_train))]\n",
    "        labels_all = [dst_train[i][1] for i in range(len(dst_train))]\n",
    "        for i, lab in enumerate(labels_all):\n",
    "            indices_class[lab].append(i)\n",
    "        images_all = torch.cat(images_all, dim=0).to(args.device)\n",
    "        labels_all = torch.tensor(labels_all, dtype=torch.long, device=args.device)\n",
    "\n",
    "\n",
    "\n",
    "        for c in range(num_classes):\n",
    "            print('class c = %d: %d real images'%(c, len(indices_class[c])))\n",
    "\n",
    "        def get_images(c, n): # get random n images from class c\n",
    "            idx_shuffle = np.random.permutation(indices_class[c])[:n]\n",
    "            return images_all[idx_shuffle]\n",
    "\n",
    "        for ch in range(channel):\n",
    "            print('real images channel %d, mean = %.4f, std = %.4f'%(ch, torch.mean(images_all[:, ch]), torch.std(images_all[:, ch])))\n",
    "\n",
    "\n",
    "        ''' initialize the synthetic data '''\n",
    "        image_syn = torch.randn(size=(num_classes*args.ipc, channel, im_size[0], im_size[1]), dtype=torch.float, requires_grad=True, device=args.device)\n",
    "        label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]\n",
    "\n",
    "        if args.init == 'real':\n",
    "            print('initialize synthetic data from random real images')\n",
    "            for c in range(num_classes):\n",
    "                image_syn.data[c*args.ipc:(c+1)*args.ipc] = get_images(c, args.ipc).detach().data\n",
    "        else:\n",
    "            print('initialize synthetic data from random noise')\n",
    "\n",
    "\n",
    "        ''' training '''\n",
    "        optimizer_img = torch.optim.SGD([image_syn, ], lr=args.lr_img, momentum=0.5) # optimizer_img for synthetic data\n",
    "        optimizer_img.zero_grad()\n",
    "        print('%s training begins'%get_time())\n",
    "\n",
    "        for it in range(args.Iteration+1):\n",
    "            ''' Train synthetic data '''\n",
    "            net = get_network(args.model, channel, num_classes, im_size).to(args.device) # get a random model\n",
    "            net.train()\n",
    "            for param in list(net.parameters()):\n",
    "                param.requires_grad = False\n",
    "\n",
    "            embed = net.module.embed if torch.cuda.device_count() > 1 else net.embed # for GPU parallel\n",
    "\n",
    "            loss_avg = 0\n",
    "\n",
    "            ''' update synthetic data '''\n",
    "            if 'BN' not in args.model: # for ConvNet\n",
    "                loss = torch.tensor(0.0).to(args.device)\n",
    "                for c in range(num_classes):\n",
    "                    img_real = get_images(c, args.batch_real)\n",
    "                    img_syn = image_syn[c*args.ipc:(c+1)*args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
    "\n",
    "                    if args.dsa:\n",
    "                        seed = int(time.time() * 1000) % 100000\n",
    "                        img_real = DiffAugment(img_real, args.dsa_strategy, seed=seed, param=args.dsa_param)\n",
    "                        img_syn = DiffAugment(img_syn, args.dsa_strategy, seed=seed, param=args.dsa_param)\n",
    "\n",
    "                    output_real = embed(img_real).detach()\n",
    "                    output_syn = embed(img_syn)\n",
    "#                     import pdb;pdb.set_trace()\n",
    "                    loss += torch.sum((torch.mean(output_real, dim=0) - torch.mean(output_syn, dim=0))**2)\n",
    "\n",
    "            else: # for ConvNetBN\n",
    "                images_real_all = []\n",
    "                images_syn_all = []\n",
    "                loss = torch.tensor(0.0).to(args.device)\n",
    "                for c in range(num_classes):\n",
    "                    img_real = get_images(c, args.batch_real)\n",
    "                    img_syn = image_syn[c*args.ipc:(c+1)*args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
    "\n",
    "                    if args.dsa:\n",
    "                        seed = int(time.time() * 1000) % 100000\n",
    "                        img_real = DiffAugment(img_real, args.dsa_strategy, seed=seed, param=args.dsa_param)\n",
    "                        img_syn = DiffAugment(img_syn, args.dsa_strategy, seed=seed, param=args.dsa_param)\n",
    "\n",
    "                    images_real_all.append(img_real)\n",
    "                    images_syn_all.append(img_syn)\n",
    "\n",
    "                images_real_all = torch.cat(images_real_all, dim=0)\n",
    "                images_syn_all = torch.cat(images_syn_all, dim=0)\n",
    "\n",
    "                output_real = embed(images_real_all).detach()\n",
    "                output_syn = embed(images_syn_all)\n",
    "\n",
    "                loss += torch.sum((torch.mean(output_real.reshape(num_classes, args.batch_real, -1), dim=1) - torch.mean(output_syn.reshape(num_classes, args.ipc, -1), dim=1))**2)\n",
    "\n",
    "\n",
    "\n",
    "            optimizer_img.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_img.step()\n",
    "            loss_avg += loss.item()\n",
    "\n",
    "\n",
    "            loss_avg /= (num_classes)\n",
    "\n",
    "            if it%10 == 0:\n",
    "                print('%s iter = %05d, loss = %.4f' % (get_time(), it, loss_avg))\n",
    "\n",
    "            if it == args.Iteration: # only record the final results\n",
    "                data_save.append([copy.deepcopy(image_syn.detach().cpu()), copy.deepcopy(label_syn.detach().cpu())])\n",
    "                torch.save({'data': data_save}, os.path.join(args.save_path, args.init+'res_%s_%s_%s_%dipc.pt'%(args.method, args.dataset, args.model, args.ipc)))\n",
    "                        \n",
    "            ''' Evaluate synthetic data '''\n",
    "            if it == eval_it_pool[-1]:\n",
    "                net_eval = get_network(args.model, channel, num_classes, im_size).to(args.device) # get a random model\n",
    "                image_syn_eval, label_syn_eval = copy.deepcopy(image_syn.detach()), copy.deepcopy(label_syn.detach()) # avoid any unaware modification\n",
    "                _, acc_train, acc_test = evaluate_synset(net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "                print('\\n==================== Final Results ====================\\n')\n",
    "                print('After {} iterations, the model test accuracy on synthetic data is {}%'.format(it, acc_test*100))\n",
    "            \n",
    "            if it in eval_it_pool:    \n",
    "                ''' visualize and save '''\n",
    "                save_name = os.path.join(args.save_path, args.init+'vis_%s_%s_%s_%dipc_exp%d_iter%d.png'%(args.method, args.dataset, args.model, args.ipc, exp, it))\n",
    "                image_syn_vis = copy.deepcopy(image_syn.detach().cpu())\n",
    "                for ch in range(channel):\n",
    "                    image_syn_vis[:, ch] = image_syn_vis[:, ch]  * std[ch] + mean[ch]\n",
    "                image_syn_vis[image_syn_vis<0] = 0.0\n",
    "                image_syn_vis[image_syn_vis>1] = 1.0\n",
    "                save_image(image_syn_vis, save_name, nrow=args.ipc) # Trying normalize = True/False may get better visual effects.\n",
    "\n",
    "class arguments():\n",
    "    def __init__(self,): \n",
    "        self.method = 'DM'\n",
    "        self.dataset = 'CIFAR10'\n",
    "        self.model = 'ConvNet'\n",
    "        #'image(s) per class'\n",
    "        self.ipc = 10\n",
    "         # S: the same to training model, M: multi architectures,  W: net width, D: net depth, A: activation function, P: pooling layer, N: normalization layer,\n",
    "        self.eval_mode = 'S'\n",
    "        #the number of experiments\n",
    "        self.num_exp = 1\n",
    "        #the number of evaluating randomly initialized models\n",
    "        self.num_eval = 1\n",
    "        #c\n",
    "        self.epoch_eval_train = 100\n",
    "        #training iterations\n",
    "        self.Iteration = 2000\n",
    "        self.lr_img = 1.0\n",
    "        self.lr_net = 0.01\n",
    "        self.batch_real = 256\n",
    "        self.batch_train = 256\n",
    "        #'noise/real: initialize synthetic images from random noise or randomly sampled real images.'\n",
    "        self.init = 'real'\n",
    "        self.dsa_strategy = 'none'\n",
    "        self.data_path = 'CIFAR10data'\n",
    "        self.save_path = 'CIFAR10result'\n",
    "        self.dis_metric = 'ours'\n",
    "        self.outer_loop = 10\n",
    "        self.inner_loop = 50\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.dsa_param = ParamDiffAug()\n",
    "        self.dsa = True\n",
    "        \n",
    "args = arguments()\n",
    "main(args)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "305f48f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_it_pool:  [0, 200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "================== Exp 0 ==================\n",
      " \n",
      "Hyper-parameters: \n",
      " {'method': 'DM', 'dataset': 'CIFAR10', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'S', 'num_exp': 1, 'num_eval': 1, 'epoch_eval_train': 100, 'Iteration': 2000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'noise', 'dsa_strategy': 'none', 'data_path': 'CIFAR10data', 'save_path': 'CIFAR10result', 'dis_metric': 'ours', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x000001DCDBA27700>, 'dsa': True}\n",
      "class c = 0: 5000 real images\n",
      "class c = 1: 5000 real images\n",
      "class c = 2: 5000 real images\n",
      "class c = 3: 5000 real images\n",
      "class c = 4: 5000 real images\n",
      "class c = 5: 5000 real images\n",
      "class c = 6: 5000 real images\n",
      "class c = 7: 5000 real images\n",
      "class c = 8: 5000 real images\n",
      "class c = 9: 5000 real images\n",
      "real images channel 0, mean = -0.0000, std = 1.2211\n",
      "real images channel 1, mean = -0.0002, std = 1.2211\n",
      "real images channel 2, mean = 0.0002, std = 1.3014\n",
      "initialize synthetic data from random noise\n",
      "[2022-12-01 22:45:00] training begins\n",
      "[2022-12-01 22:45:00] iter = 00000, loss = 46.1359\n",
      "[2022-12-01 22:45:01] iter = 00010, loss = 23.9581\n",
      "[2022-12-01 22:45:03] iter = 00020, loss = 22.2834\n",
      "[2022-12-01 22:45:04] iter = 00030, loss = 18.5232\n",
      "[2022-12-01 22:45:06] iter = 00040, loss = 17.0914\n",
      "[2022-12-01 22:45:07] iter = 00050, loss = 15.3200\n",
      "[2022-12-01 22:45:09] iter = 00060, loss = 14.5330\n",
      "[2022-12-01 22:45:10] iter = 00070, loss = 14.7891\n",
      "[2022-12-01 22:45:12] iter = 00080, loss = 14.3047\n",
      "[2022-12-01 22:45:13] iter = 00090, loss = 15.1808\n",
      "[2022-12-01 22:45:15] iter = 00100, loss = 12.3415\n",
      "[2022-12-01 22:45:16] iter = 00110, loss = 12.6834\n",
      "[2022-12-01 22:45:18] iter = 00120, loss = 12.5641\n",
      "[2022-12-01 22:45:19] iter = 00130, loss = 11.0759\n",
      "[2022-12-01 22:45:21] iter = 00140, loss = 11.9437\n",
      "[2022-12-01 22:45:23] iter = 00150, loss = 11.3591\n",
      "[2022-12-01 22:45:24] iter = 00160, loss = 11.4423\n",
      "[2022-12-01 22:45:26] iter = 00170, loss = 10.6265\n",
      "[2022-12-01 22:45:27] iter = 00180, loss = 10.6234\n",
      "[2022-12-01 22:45:29] iter = 00190, loss = 11.0112\n",
      "[2022-12-01 22:45:30] iter = 00200, loss = 11.1248\n",
      "[2022-12-01 22:45:32] iter = 00210, loss = 10.6963\n",
      "[2022-12-01 22:45:33] iter = 00220, loss = 9.7188\n",
      "[2022-12-01 22:45:35] iter = 00230, loss = 9.8724\n",
      "[2022-12-01 22:45:36] iter = 00240, loss = 9.6990\n",
      "[2022-12-01 22:45:38] iter = 00250, loss = 9.8284\n",
      "[2022-12-01 22:45:39] iter = 00260, loss = 9.5434\n",
      "[2022-12-01 22:45:41] iter = 00270, loss = 9.4878\n",
      "[2022-12-01 22:45:42] iter = 00280, loss = 9.4573\n",
      "[2022-12-01 22:45:44] iter = 00290, loss = 9.3689\n",
      "[2022-12-01 22:45:45] iter = 00300, loss = 8.8379\n",
      "[2022-12-01 22:45:47] iter = 00310, loss = 8.8418\n",
      "[2022-12-01 22:45:48] iter = 00320, loss = 8.7133\n",
      "[2022-12-01 22:45:50] iter = 00330, loss = 10.0714\n",
      "[2022-12-01 22:45:51] iter = 00340, loss = 8.6240\n",
      "[2022-12-01 22:45:53] iter = 00350, loss = 8.8169\n",
      "[2022-12-01 22:45:55] iter = 00360, loss = 8.5338\n",
      "[2022-12-01 22:45:56] iter = 00370, loss = 8.8101\n",
      "[2022-12-01 22:45:58] iter = 00380, loss = 8.0887\n",
      "[2022-12-01 22:45:59] iter = 00390, loss = 8.2294\n",
      "[2022-12-01 22:46:01] iter = 00400, loss = 7.8258\n",
      "[2022-12-01 22:46:02] iter = 00410, loss = 8.3779\n",
      "[2022-12-01 22:46:04] iter = 00420, loss = 8.2367\n",
      "[2022-12-01 22:46:05] iter = 00430, loss = 7.9540\n",
      "[2022-12-01 22:46:07] iter = 00440, loss = 8.0452\n",
      "[2022-12-01 22:46:08] iter = 00450, loss = 8.3125\n",
      "[2022-12-01 22:46:10] iter = 00460, loss = 7.8215\n",
      "[2022-12-01 22:46:11] iter = 00470, loss = 8.1621\n",
      "[2022-12-01 22:46:13] iter = 00480, loss = 7.4073\n",
      "[2022-12-01 22:46:14] iter = 00490, loss = 7.1327\n",
      "[2022-12-01 22:46:16] iter = 00500, loss = 7.6852\n",
      "[2022-12-01 22:46:17] iter = 00510, loss = 7.8332\n",
      "[2022-12-01 22:46:19] iter = 00520, loss = 7.1266\n",
      "[2022-12-01 22:46:20] iter = 00530, loss = 7.7620\n",
      "[2022-12-01 22:46:22] iter = 00540, loss = 7.6005\n",
      "[2022-12-01 22:46:23] iter = 00550, loss = 7.2119\n",
      "[2022-12-01 22:46:25] iter = 00560, loss = 7.1810\n",
      "[2022-12-01 22:46:27] iter = 00570, loss = 7.3816\n",
      "[2022-12-01 22:46:28] iter = 00580, loss = 6.9983\n",
      "[2022-12-01 22:46:30] iter = 00590, loss = 6.7143\n",
      "[2022-12-01 22:46:31] iter = 00600, loss = 7.1099\n",
      "[2022-12-01 22:46:33] iter = 00610, loss = 7.0985\n",
      "[2022-12-01 22:46:34] iter = 00620, loss = 6.9957\n",
      "[2022-12-01 22:46:36] iter = 00630, loss = 7.1333\n",
      "[2022-12-01 22:46:37] iter = 00640, loss = 6.7296\n",
      "[2022-12-01 22:46:39] iter = 00650, loss = 6.6896\n",
      "[2022-12-01 22:46:40] iter = 00660, loss = 6.9562\n",
      "[2022-12-01 22:46:42] iter = 00670, loss = 6.4199\n",
      "[2022-12-01 22:46:43] iter = 00680, loss = 6.7270\n",
      "[2022-12-01 22:46:45] iter = 00690, loss = 6.6554\n",
      "[2022-12-01 22:46:46] iter = 00700, loss = 6.7643\n",
      "[2022-12-01 22:46:48] iter = 00710, loss = 6.7970\n",
      "[2022-12-01 22:46:49] iter = 00720, loss = 6.5933\n",
      "[2022-12-01 22:46:51] iter = 00730, loss = 6.3968\n",
      "[2022-12-01 22:46:52] iter = 00740, loss = 6.4825\n",
      "[2022-12-01 22:46:54] iter = 00750, loss = 7.0950\n",
      "[2022-12-01 22:46:55] iter = 00760, loss = 6.3774\n",
      "[2022-12-01 22:46:57] iter = 00770, loss = 6.5470\n",
      "[2022-12-01 22:46:59] iter = 00780, loss = 6.4996\n",
      "[2022-12-01 22:47:00] iter = 00790, loss = 6.4918\n",
      "[2022-12-01 22:47:02] iter = 00800, loss = 6.4932\n",
      "[2022-12-01 22:47:03] iter = 00810, loss = 6.6089\n",
      "[2022-12-01 22:47:05] iter = 00820, loss = 7.0540\n",
      "[2022-12-01 22:47:06] iter = 00830, loss = 6.5812\n",
      "[2022-12-01 22:47:08] iter = 00840, loss = 6.1253\n",
      "[2022-12-01 22:47:09] iter = 00850, loss = 6.1552\n",
      "[2022-12-01 22:47:11] iter = 00860, loss = 6.1470\n",
      "[2022-12-01 22:47:12] iter = 00870, loss = 6.3811\n",
      "[2022-12-01 22:47:14] iter = 00880, loss = 6.0201\n",
      "[2022-12-01 22:47:15] iter = 00890, loss = 6.0380\n",
      "[2022-12-01 22:47:17] iter = 00900, loss = 5.8961\n",
      "[2022-12-01 22:47:18] iter = 00910, loss = 6.0311\n",
      "[2022-12-01 22:47:20] iter = 00920, loss = 6.2188\n",
      "[2022-12-01 22:47:21] iter = 00930, loss = 5.9482\n",
      "[2022-12-01 22:47:23] iter = 00940, loss = 5.9493\n",
      "[2022-12-01 22:47:24] iter = 00950, loss = 6.1291\n",
      "[2022-12-01 22:47:26] iter = 00960, loss = 6.2049\n",
      "[2022-12-01 22:47:27] iter = 00970, loss = 6.2709\n",
      "[2022-12-01 22:47:29] iter = 00980, loss = 5.8368\n",
      "[2022-12-01 22:47:31] iter = 00990, loss = 6.4154\n",
      "[2022-12-01 22:47:32] iter = 01000, loss = 5.7706\n",
      "[2022-12-01 22:47:34] iter = 01010, loss = 6.0405\n",
      "[2022-12-01 22:47:35] iter = 01020, loss = 5.8160\n",
      "[2022-12-01 22:47:37] iter = 01030, loss = 5.8635\n",
      "[2022-12-01 22:47:38] iter = 01040, loss = 5.7633\n",
      "[2022-12-01 22:47:40] iter = 01050, loss = 6.1054\n",
      "[2022-12-01 22:47:41] iter = 01060, loss = 6.0036\n",
      "[2022-12-01 22:47:43] iter = 01070, loss = 5.6553\n",
      "[2022-12-01 22:47:44] iter = 01080, loss = 5.7462\n",
      "[2022-12-01 22:47:46] iter = 01090, loss = 5.9819\n",
      "[2022-12-01 22:47:47] iter = 01100, loss = 5.5260\n",
      "[2022-12-01 22:47:49] iter = 01110, loss = 5.8438\n",
      "[2022-12-01 22:47:50] iter = 01120, loss = 5.9293\n",
      "[2022-12-01 22:47:52] iter = 01130, loss = 6.2079\n",
      "[2022-12-01 22:47:53] iter = 01140, loss = 5.6901\n",
      "[2022-12-01 22:47:55] iter = 01150, loss = 5.8770\n",
      "[2022-12-01 22:47:56] iter = 01160, loss = 5.6165\n",
      "[2022-12-01 22:47:58] iter = 01170, loss = 5.4610\n",
      "[2022-12-01 22:48:00] iter = 01180, loss = 5.9606\n",
      "[2022-12-01 22:48:01] iter = 01190, loss = 5.8352\n",
      "[2022-12-01 22:48:03] iter = 01200, loss = 5.5698\n",
      "[2022-12-01 22:48:04] iter = 01210, loss = 5.7418\n",
      "[2022-12-01 22:48:06] iter = 01220, loss = 5.8518\n",
      "[2022-12-01 22:48:07] iter = 01230, loss = 5.2948\n",
      "[2022-12-01 22:48:09] iter = 01240, loss = 5.6091\n",
      "[2022-12-01 22:48:10] iter = 01250, loss = 5.6328\n",
      "[2022-12-01 22:48:12] iter = 01260, loss = 5.6636\n",
      "[2022-12-01 22:48:13] iter = 01270, loss = 5.6252\n",
      "[2022-12-01 22:48:15] iter = 01280, loss = 5.5880\n",
      "[2022-12-01 22:48:16] iter = 01290, loss = 5.4731\n",
      "[2022-12-01 22:48:18] iter = 01300, loss = 5.3996\n",
      "[2022-12-01 22:48:19] iter = 01310, loss = 5.6500\n",
      "[2022-12-01 22:48:21] iter = 01320, loss = 5.6671\n",
      "[2022-12-01 22:48:23] iter = 01330, loss = 5.3296\n",
      "[2022-12-01 22:48:24] iter = 01340, loss = 5.3283\n",
      "[2022-12-01 22:48:26] iter = 01350, loss = 5.2340\n",
      "[2022-12-01 22:48:27] iter = 01360, loss = 5.4230\n",
      "[2022-12-01 22:48:29] iter = 01370, loss = 5.2838\n",
      "[2022-12-01 22:48:30] iter = 01380, loss = 5.4084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-12-01 22:48:32] iter = 01390, loss = 5.5567\n",
      "[2022-12-01 22:48:33] iter = 01400, loss = 5.4769\n",
      "[2022-12-01 22:48:35] iter = 01410, loss = 5.2686\n",
      "[2022-12-01 22:48:36] iter = 01420, loss = 5.4101\n",
      "[2022-12-01 22:48:38] iter = 01430, loss = 5.2225\n",
      "[2022-12-01 22:48:39] iter = 01440, loss = 5.5644\n",
      "[2022-12-01 22:48:41] iter = 01450, loss = 5.7927\n",
      "[2022-12-01 22:48:42] iter = 01460, loss = 5.2755\n",
      "[2022-12-01 22:48:44] iter = 01470, loss = 5.3785\n",
      "[2022-12-01 22:48:45] iter = 01480, loss = 5.1901\n",
      "[2022-12-01 22:48:47] iter = 01490, loss = 5.1421\n",
      "[2022-12-01 22:48:49] iter = 01500, loss = 5.4532\n",
      "[2022-12-01 22:48:50] iter = 01510, loss = 5.0711\n",
      "[2022-12-01 22:48:52] iter = 01520, loss = 5.5171\n",
      "[2022-12-01 22:48:53] iter = 01530, loss = 5.2506\n",
      "[2022-12-01 22:48:55] iter = 01540, loss = 5.1772\n",
      "[2022-12-01 22:48:56] iter = 01550, loss = 5.4313\n",
      "[2022-12-01 22:48:58] iter = 01560, loss = 5.3931\n",
      "[2022-12-01 22:48:59] iter = 01570, loss = 5.4736\n",
      "[2022-12-01 22:49:01] iter = 01580, loss = 5.3460\n",
      "[2022-12-01 22:49:02] iter = 01590, loss = 5.3281\n",
      "[2022-12-01 22:49:04] iter = 01600, loss = 5.1805\n",
      "[2022-12-01 22:49:05] iter = 01610, loss = 5.4260\n",
      "[2022-12-01 22:49:07] iter = 01620, loss = 5.3904\n",
      "[2022-12-01 22:49:08] iter = 01630, loss = 5.5310\n",
      "[2022-12-01 22:49:10] iter = 01640, loss = 5.2036\n",
      "[2022-12-01 22:49:11] iter = 01650, loss = 5.1816\n",
      "[2022-12-01 22:49:13] iter = 01660, loss = 4.9527\n",
      "[2022-12-01 22:49:14] iter = 01670, loss = 5.2005\n",
      "[2022-12-01 22:49:16] iter = 01680, loss = 5.0947\n",
      "[2022-12-01 22:49:17] iter = 01690, loss = 5.1334\n",
      "[2022-12-01 22:49:19] iter = 01700, loss = 5.3493\n",
      "[2022-12-01 22:49:21] iter = 01710, loss = 5.0906\n",
      "[2022-12-01 22:49:22] iter = 01720, loss = 5.2398\n",
      "[2022-12-01 22:49:24] iter = 01730, loss = 5.0389\n",
      "[2022-12-01 22:49:25] iter = 01740, loss = 5.1913\n",
      "[2022-12-01 22:49:27] iter = 01750, loss = 5.3379\n",
      "[2022-12-01 22:49:28] iter = 01760, loss = 4.9935\n",
      "[2022-12-01 22:49:30] iter = 01770, loss = 5.1890\n",
      "[2022-12-01 22:49:31] iter = 01780, loss = 5.2466\n",
      "[2022-12-01 22:49:33] iter = 01790, loss = 4.8860\n",
      "[2022-12-01 22:49:34] iter = 01800, loss = 5.0984\n",
      "[2022-12-01 22:49:36] iter = 01810, loss = 5.4298\n",
      "[2022-12-01 22:49:37] iter = 01820, loss = 4.9558\n",
      "[2022-12-01 22:49:39] iter = 01830, loss = 5.0346\n",
      "[2022-12-01 22:49:40] iter = 01840, loss = 5.0835\n",
      "[2022-12-01 22:49:42] iter = 01850, loss = 4.9293\n",
      "[2022-12-01 22:49:43] iter = 01860, loss = 5.1859\n",
      "[2022-12-01 22:49:45] iter = 01870, loss = 5.1164\n",
      "[2022-12-01 22:49:46] iter = 01880, loss = 5.0161\n",
      "[2022-12-01 22:49:48] iter = 01890, loss = 5.0248\n",
      "[2022-12-01 22:49:50] iter = 01900, loss = 5.1352\n",
      "[2022-12-01 22:49:51] iter = 01910, loss = 4.9188\n",
      "[2022-12-01 22:49:53] iter = 01920, loss = 4.8583\n",
      "[2022-12-01 22:49:54] iter = 01930, loss = 5.0721\n",
      "[2022-12-01 22:49:56] iter = 01940, loss = 4.5457\n",
      "[2022-12-01 22:49:57] iter = 01950, loss = 4.9214\n",
      "[2022-12-01 22:49:59] iter = 01960, loss = 5.2045\n",
      "[2022-12-01 22:50:00] iter = 01970, loss = 4.6546\n",
      "[2022-12-01 22:50:02] iter = 01980, loss = 4.6239\n",
      "[2022-12-01 22:50:03] iter = 01990, loss = 5.0130\n",
      "[2022-12-01 22:50:05] iter = 02000, loss = 4.6279\n",
      "\n",
      "==================== Final Results ====================\n",
      "\n",
      "After 2000 iterations, the model test accuracy on synthetic data is 39.11%\n"
     ]
    }
   ],
   "source": [
    "args.init = 'noise'\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7cbb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
