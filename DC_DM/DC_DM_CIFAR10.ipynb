{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aeccb70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_it_pool:  [0, 200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "================== Exp 0 ==================\n",
      " \n",
      "Hyper-parameters: \n",
      " {'method': 'DM', 'dataset': 'CIFAR10', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'S', 'num_exp': 1, 'num_eval': 1, 'epoch_eval_train': 100, 'Iteration': 2000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': 'CIFAR10data', 'save_path': 'CIFAR10result', 'dis_metric': 'ours', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x0000022CE07680A0>, 'dsa': 'False'}\n",
      "class c = 0: 5000 real images\n",
      "class c = 1: 5000 real images\n",
      "class c = 2: 5000 real images\n",
      "class c = 3: 5000 real images\n",
      "class c = 4: 5000 real images\n",
      "class c = 5: 5000 real images\n",
      "class c = 6: 5000 real images\n",
      "class c = 7: 5000 real images\n",
      "class c = 8: 5000 real images\n",
      "class c = 9: 5000 real images\n",
      "real images channel 0, mean = -0.0000, std = 1.2211\n",
      "real images channel 1, mean = -0.0002, std = 1.2211\n",
      "real images channel 2, mean = 0.0002, std = 1.3014\n",
      "initialize synthetic data from random real images\n",
      "[2022-12-02 12:33:45] training begins\n",
      "[2022-12-02 12:33:51] iter = 00000, loss = 23.6674\n",
      "[2022-12-02 12:33:53] iter = 00010, loss = 16.7356\n",
      "[2022-12-02 12:33:55] iter = 00020, loss = 13.1216\n",
      "[2022-12-02 12:33:56] iter = 00030, loss = 10.9468\n",
      "[2022-12-02 12:33:58] iter = 00040, loss = 10.4815\n",
      "[2022-12-02 12:34:00] iter = 00050, loss = 9.7301\n",
      "[2022-12-02 12:34:02] iter = 00060, loss = 9.4788\n",
      "[2022-12-02 12:34:03] iter = 00070, loss = 8.9421\n",
      "[2022-12-02 12:34:05] iter = 00080, loss = 8.4250\n",
      "[2022-12-02 12:34:07] iter = 00090, loss = 8.8622\n",
      "[2022-12-02 12:34:08] iter = 00100, loss = 8.1710\n",
      "[2022-12-02 12:34:10] iter = 00110, loss = 8.1333\n",
      "[2022-12-02 12:34:12] iter = 00120, loss = 7.6585\n",
      "[2022-12-02 12:34:14] iter = 00130, loss = 7.4795\n",
      "[2022-12-02 12:34:16] iter = 00140, loss = 7.8204\n",
      "[2022-12-02 12:34:17] iter = 00150, loss = 7.4401\n",
      "[2022-12-02 12:34:19] iter = 00160, loss = 7.4887\n",
      "[2022-12-02 12:34:21] iter = 00170, loss = 7.5597\n",
      "[2022-12-02 12:34:23] iter = 00180, loss = 7.7893\n",
      "[2022-12-02 12:34:24] iter = 00190, loss = 7.1007\n",
      "[2022-12-02 12:34:26] iter = 00200, loss = 7.1588\n",
      "[2022-12-02 12:34:28] iter = 00210, loss = 6.5159\n",
      "[2022-12-02 12:34:30] iter = 00220, loss = 6.6033\n",
      "[2022-12-02 12:34:31] iter = 00230, loss = 6.2822\n",
      "[2022-12-02 12:34:33] iter = 00240, loss = 6.3982\n",
      "[2022-12-02 12:34:35] iter = 00250, loss = 6.2875\n",
      "[2022-12-02 12:34:37] iter = 00260, loss = 6.3482\n",
      "[2022-12-02 12:34:39] iter = 00270, loss = 6.2313\n",
      "[2022-12-02 12:34:41] iter = 00280, loss = 6.2980\n",
      "[2022-12-02 12:34:43] iter = 00290, loss = 6.8433\n",
      "[2022-12-02 12:34:44] iter = 00300, loss = 6.4800\n",
      "[2022-12-02 12:34:46] iter = 00310, loss = 6.0860\n",
      "[2022-12-02 12:34:48] iter = 00320, loss = 6.7995\n",
      "[2022-12-02 12:34:50] iter = 00330, loss = 5.8547\n",
      "[2022-12-02 12:34:52] iter = 00340, loss = 5.8325\n",
      "[2022-12-02 12:34:54] iter = 00350, loss = 6.0850\n",
      "[2022-12-02 12:34:56] iter = 00360, loss = 5.9884\n",
      "[2022-12-02 12:34:57] iter = 00370, loss = 6.1576\n",
      "[2022-12-02 12:34:59] iter = 00380, loss = 6.1809\n",
      "[2022-12-02 12:35:01] iter = 00390, loss = 6.1498\n",
      "[2022-12-02 12:35:03] iter = 00400, loss = 5.6569\n",
      "[2022-12-02 12:35:05] iter = 00410, loss = 5.6222\n",
      "[2022-12-02 12:35:07] iter = 00420, loss = 5.9494\n",
      "[2022-12-02 12:35:09] iter = 00430, loss = 6.1836\n",
      "[2022-12-02 12:35:11] iter = 00440, loss = 5.8959\n",
      "[2022-12-02 12:35:12] iter = 00450, loss = 5.5846\n",
      "[2022-12-02 12:35:14] iter = 00460, loss = 5.5923\n",
      "[2022-12-02 12:35:16] iter = 00470, loss = 5.7624\n",
      "[2022-12-02 12:35:18] iter = 00480, loss = 5.6617\n",
      "[2022-12-02 12:35:20] iter = 00490, loss = 5.6391\n",
      "[2022-12-02 12:35:22] iter = 00500, loss = 5.7593\n",
      "[2022-12-02 12:35:24] iter = 00510, loss = 5.6591\n",
      "[2022-12-02 12:35:25] iter = 00520, loss = 5.9049\n",
      "[2022-12-02 12:35:27] iter = 00530, loss = 5.4782\n",
      "[2022-12-02 12:35:29] iter = 00540, loss = 5.5211\n",
      "[2022-12-02 12:35:31] iter = 00550, loss = 5.6490\n",
      "[2022-12-02 12:35:33] iter = 00560, loss = 5.5935\n",
      "[2022-12-02 12:35:34] iter = 00570, loss = 5.6725\n",
      "[2022-12-02 12:35:36] iter = 00580, loss = 5.3100\n",
      "[2022-12-02 12:35:38] iter = 00590, loss = 5.4106\n",
      "[2022-12-02 12:35:40] iter = 00600, loss = 5.7908\n",
      "[2022-12-02 12:35:42] iter = 00610, loss = 5.6207\n",
      "[2022-12-02 12:35:44] iter = 00620, loss = 5.6151\n",
      "[2022-12-02 12:35:46] iter = 00630, loss = 5.9121\n",
      "[2022-12-02 12:35:47] iter = 00640, loss = 5.2655\n",
      "[2022-12-02 12:35:49] iter = 00650, loss = 5.7865\n",
      "[2022-12-02 12:35:51] iter = 00660, loss = 5.1555\n",
      "[2022-12-02 12:35:53] iter = 00670, loss = 5.4700\n",
      "[2022-12-02 12:35:55] iter = 00680, loss = 5.6252\n",
      "[2022-12-02 12:35:57] iter = 00690, loss = 5.1398\n",
      "[2022-12-02 12:35:59] iter = 00700, loss = 5.0675\n",
      "[2022-12-02 12:36:00] iter = 00710, loss = 5.4284\n",
      "[2022-12-02 12:36:02] iter = 00720, loss = 5.4078\n",
      "[2022-12-02 12:36:04] iter = 00730, loss = 5.2849\n",
      "[2022-12-02 12:36:06] iter = 00740, loss = 5.2461\n",
      "[2022-12-02 12:36:08] iter = 00750, loss = 4.9906\n",
      "[2022-12-02 12:36:09] iter = 00760, loss = 5.2651\n",
      "[2022-12-02 12:36:11] iter = 00770, loss = 5.1185\n",
      "[2022-12-02 12:36:13] iter = 00780, loss = 5.4198\n",
      "[2022-12-02 12:36:15] iter = 00790, loss = 5.0462\n",
      "[2022-12-02 12:36:17] iter = 00800, loss = 5.6099\n",
      "[2022-12-02 12:36:19] iter = 00810, loss = 5.0103\n",
      "[2022-12-02 12:36:20] iter = 00820, loss = 5.5804\n",
      "[2022-12-02 12:36:22] iter = 00830, loss = 5.6177\n",
      "[2022-12-02 12:36:24] iter = 00840, loss = 5.0224\n",
      "[2022-12-02 12:36:26] iter = 00850, loss = 4.9950\n",
      "[2022-12-02 12:36:28] iter = 00860, loss = 5.2429\n",
      "[2022-12-02 12:36:30] iter = 00870, loss = 5.3912\n",
      "[2022-12-02 12:36:32] iter = 00880, loss = 5.2336\n",
      "[2022-12-02 12:36:33] iter = 00890, loss = 4.9495\n",
      "[2022-12-02 12:36:35] iter = 00900, loss = 4.8484\n",
      "[2022-12-02 12:36:37] iter = 00910, loss = 5.1173\n",
      "[2022-12-02 12:36:39] iter = 00920, loss = 5.7047\n",
      "[2022-12-02 12:36:41] iter = 00930, loss = 5.0419\n",
      "[2022-12-02 12:36:43] iter = 00940, loss = 5.0923\n",
      "[2022-12-02 12:36:44] iter = 00950, loss = 5.5073\n",
      "[2022-12-02 12:36:46] iter = 00960, loss = 4.7364\n",
      "[2022-12-02 12:36:48] iter = 00970, loss = 5.0233\n",
      "[2022-12-02 12:36:50] iter = 00980, loss = 5.1379\n",
      "[2022-12-02 12:36:52] iter = 00990, loss = 5.0507\n",
      "[2022-12-02 12:36:54] iter = 01000, loss = 5.1422\n",
      "[2022-12-02 12:36:56] iter = 01010, loss = 4.9743\n",
      "[2022-12-02 12:36:57] iter = 01020, loss = 5.0241\n",
      "[2022-12-02 12:36:59] iter = 01030, loss = 5.1621\n",
      "[2022-12-02 12:37:01] iter = 01040, loss = 4.8270\n",
      "[2022-12-02 12:37:03] iter = 01050, loss = 4.9178\n",
      "[2022-12-02 12:37:05] iter = 01060, loss = 4.9161\n",
      "[2022-12-02 12:37:07] iter = 01070, loss = 5.2203\n",
      "[2022-12-02 12:37:08] iter = 01080, loss = 4.8915\n",
      "[2022-12-02 12:37:10] iter = 01090, loss = 5.1035\n",
      "[2022-12-02 12:37:12] iter = 01100, loss = 4.8203\n",
      "[2022-12-02 12:37:14] iter = 01110, loss = 4.9029\n",
      "[2022-12-02 12:37:16] iter = 01120, loss = 5.0548\n",
      "[2022-12-02 12:37:18] iter = 01130, loss = 4.9476\n",
      "[2022-12-02 12:37:20] iter = 01140, loss = 4.5695\n",
      "[2022-12-02 12:37:21] iter = 01150, loss = 4.5945\n",
      "[2022-12-02 12:37:23] iter = 01160, loss = 4.9293\n",
      "[2022-12-02 12:37:25] iter = 01170, loss = 4.8368\n",
      "[2022-12-02 12:37:27] iter = 01180, loss = 5.0136\n",
      "[2022-12-02 12:37:29] iter = 01190, loss = 4.8036\n",
      "[2022-12-02 12:37:30] iter = 01200, loss = 5.0223\n",
      "[2022-12-02 12:37:32] iter = 01210, loss = 4.9173\n",
      "[2022-12-02 12:37:34] iter = 01220, loss = 4.8945\n",
      "[2022-12-02 12:37:36] iter = 01230, loss = 4.8647\n",
      "[2022-12-02 12:37:38] iter = 01240, loss = 4.5993\n",
      "[2022-12-02 12:37:40] iter = 01250, loss = 4.9532\n",
      "[2022-12-02 12:37:42] iter = 01260, loss = 4.6423\n",
      "[2022-12-02 12:37:43] iter = 01270, loss = 4.6852\n",
      "[2022-12-02 12:37:45] iter = 01280, loss = 4.7845\n",
      "[2022-12-02 12:37:47] iter = 01290, loss = 4.6608\n",
      "[2022-12-02 12:37:49] iter = 01300, loss = 4.8385\n",
      "[2022-12-02 12:37:51] iter = 01310, loss = 4.7666\n",
      "[2022-12-02 12:37:53] iter = 01320, loss = 4.8813\n",
      "[2022-12-02 12:37:54] iter = 01330, loss = 4.7180\n",
      "[2022-12-02 12:37:56] iter = 01340, loss = 4.5703\n",
      "[2022-12-02 12:37:58] iter = 01350, loss = 4.8634\n",
      "[2022-12-02 12:38:00] iter = 01360, loss = 5.3447\n",
      "[2022-12-02 12:38:02] iter = 01370, loss = 5.2740\n",
      "[2022-12-02 12:38:04] iter = 01380, loss = 4.6158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-12-02 12:38:06] iter = 01390, loss = 4.5655\n",
      "[2022-12-02 12:38:08] iter = 01400, loss = 4.8891\n",
      "[2022-12-02 12:38:09] iter = 01410, loss = 4.8769\n",
      "[2022-12-02 12:38:11] iter = 01420, loss = 4.7897\n",
      "[2022-12-02 12:38:13] iter = 01430, loss = 5.0828\n",
      "[2022-12-02 12:38:15] iter = 01440, loss = 4.8701\n",
      "[2022-12-02 12:38:17] iter = 01450, loss = 5.0008\n",
      "[2022-12-02 12:38:19] iter = 01460, loss = 4.4651\n",
      "[2022-12-02 12:38:21] iter = 01470, loss = 4.5683\n",
      "[2022-12-02 12:38:22] iter = 01480, loss = 5.0472\n",
      "[2022-12-02 12:38:24] iter = 01490, loss = 4.5284\n",
      "[2022-12-02 12:38:26] iter = 01500, loss = 4.8956\n",
      "[2022-12-02 12:38:28] iter = 01510, loss = 4.8097\n",
      "[2022-12-02 12:38:30] iter = 01520, loss = 4.4813\n",
      "[2022-12-02 12:38:32] iter = 01530, loss = 4.6184\n",
      "[2022-12-02 12:38:34] iter = 01540, loss = 4.7038\n",
      "[2022-12-02 12:38:35] iter = 01550, loss = 4.5501\n",
      "[2022-12-02 12:38:37] iter = 01560, loss = 4.7198\n",
      "[2022-12-02 12:38:39] iter = 01570, loss = 4.7077\n",
      "[2022-12-02 12:38:41] iter = 01580, loss = 4.6549\n",
      "[2022-12-02 12:38:43] iter = 01590, loss = 4.9700\n",
      "[2022-12-02 12:38:44] iter = 01600, loss = 4.2381\n",
      "[2022-12-02 12:38:46] iter = 01610, loss = 4.4454\n",
      "[2022-12-02 12:38:48] iter = 01620, loss = 4.5674\n",
      "[2022-12-02 12:38:50] iter = 01630, loss = 5.2870\n",
      "[2022-12-02 12:38:52] iter = 01640, loss = 5.0121\n",
      "[2022-12-02 12:38:54] iter = 01650, loss = 4.7666\n",
      "[2022-12-02 12:38:56] iter = 01660, loss = 4.5512\n",
      "[2022-12-02 12:38:57] iter = 01670, loss = 4.7945\n",
      "[2022-12-02 12:38:59] iter = 01680, loss = 4.8049\n",
      "[2022-12-02 12:39:01] iter = 01690, loss = 4.9063\n",
      "[2022-12-02 12:39:03] iter = 01700, loss = 4.3282\n",
      "[2022-12-02 12:39:05] iter = 01710, loss = 4.8913\n",
      "[2022-12-02 12:39:07] iter = 01720, loss = 4.6843\n",
      "[2022-12-02 12:39:09] iter = 01730, loss = 4.6598\n",
      "[2022-12-02 12:39:10] iter = 01740, loss = 4.9981\n",
      "[2022-12-02 12:39:12] iter = 01750, loss = 4.4559\n",
      "[2022-12-02 12:39:14] iter = 01760, loss = 4.5736\n",
      "[2022-12-02 12:39:16] iter = 01770, loss = 4.9575\n",
      "[2022-12-02 12:39:18] iter = 01780, loss = 4.3662\n",
      "[2022-12-02 12:39:20] iter = 01790, loss = 4.5883\n",
      "[2022-12-02 12:39:21] iter = 01800, loss = 4.6421\n",
      "[2022-12-02 12:39:23] iter = 01810, loss = 5.0053\n",
      "[2022-12-02 12:39:25] iter = 01820, loss = 4.6128\n",
      "[2022-12-02 12:39:27] iter = 01830, loss = 4.6690\n",
      "[2022-12-02 12:39:29] iter = 01840, loss = 4.4246\n",
      "[2022-12-02 12:39:31] iter = 01850, loss = 4.5583\n",
      "[2022-12-02 12:39:33] iter = 01860, loss = 4.6966\n",
      "[2022-12-02 12:39:35] iter = 01870, loss = 4.5088\n",
      "[2022-12-02 12:39:37] iter = 01880, loss = 4.8785\n",
      "[2022-12-02 12:39:38] iter = 01890, loss = 4.6439\n",
      "[2022-12-02 12:39:40] iter = 01900, loss = 4.6321\n",
      "[2022-12-02 12:39:42] iter = 01910, loss = 4.9390\n",
      "[2022-12-02 12:39:44] iter = 01920, loss = 4.5365\n",
      "[2022-12-02 12:39:46] iter = 01930, loss = 4.7215\n",
      "[2022-12-02 12:39:48] iter = 01940, loss = 4.4178\n",
      "[2022-12-02 12:39:50] iter = 01950, loss = 4.6210\n",
      "[2022-12-02 12:39:51] iter = 01960, loss = 4.7596\n",
      "[2022-12-02 12:39:53] iter = 01970, loss = 4.8903\n",
      "[2022-12-02 12:39:55] iter = 01980, loss = 4.5533\n",
      "[2022-12-02 12:39:57] iter = 01990, loss = 4.7071\n",
      "[2022-12-02 12:39:59] iter = 02000, loss = 4.7626\n",
      "\n",
      "==================== Final Results ====================\n",
      "\n",
      "After 2000 iterations, the model test accuracy on synthetic data is 44.379999999999995%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import tqdm\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from utils import get_loops, get_dataset, get_network, get_eval_pool, evaluate_synset, get_daparam, match_loss, get_time, TensorDataset, epoch, DiffAugment, ParamDiffAug\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "def main(args):\n",
    "    if not os.path.exists(args.data_path):\n",
    "        os.mkdir(args.data_path)\n",
    "\n",
    "    if not os.path.exists(args.save_path):\n",
    "        os.mkdir(args.save_path)\n",
    "\n",
    "    eval_it_pool = np.arange(0, args.Iteration+1, 200).tolist() if args.eval_mode == 'S' or args.eval_mode == 'SS' else [args.Iteration] # The list of iterations when we evaluate models and record results.\n",
    "    print('eval_it_pool: ', eval_it_pool)\n",
    "    channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader = get_dataset(args.dataset, args.data_path)\n",
    "\n",
    "    data_save = []\n",
    "\n",
    "    for exp in range(args.num_exp):\n",
    "        print('\\n================== Exp %d ==================\\n '%exp)\n",
    "        print('Hyper-parameters: \\n', args.__dict__)\n",
    "\n",
    "        ''' organize the real dataset '''\n",
    "        images_all = []\n",
    "        labels_all = []\n",
    "        indices_class = [[] for c in range(num_classes)]\n",
    "\n",
    "        images_all = [torch.unsqueeze(dst_train[i][0], dim=0) for i in range(len(dst_train))]\n",
    "        labels_all = [dst_train[i][1] for i in range(len(dst_train))]\n",
    "        for i, lab in enumerate(labels_all):\n",
    "            indices_class[lab].append(i)\n",
    "        images_all = torch.cat(images_all, dim=0).to(args.device)\n",
    "        labels_all = torch.tensor(labels_all, dtype=torch.long, device=args.device)\n",
    "\n",
    "\n",
    "\n",
    "        for c in range(num_classes):\n",
    "            print('class c = %d: %d real images'%(c, len(indices_class[c])))\n",
    "\n",
    "        def get_images(c, n): # get random n images from class c\n",
    "            idx_shuffle = np.random.permutation(indices_class[c])[:n]\n",
    "            return images_all[idx_shuffle]\n",
    "\n",
    "        for ch in range(channel):\n",
    "            print('real images channel %d, mean = %.4f, std = %.4f'%(ch, torch.mean(images_all[:, ch]), torch.std(images_all[:, ch])))\n",
    "\n",
    "\n",
    "        ''' initialize the synthetic data '''\n",
    "        image_syn = torch.randn(size=(num_classes*args.ipc, channel, im_size[0], im_size[1]), dtype=torch.float, requires_grad=True, device=args.device)\n",
    "        label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]\n",
    "\n",
    "        if args.init == 'real':\n",
    "            print('initialize synthetic data from random real images')\n",
    "            for c in range(num_classes):\n",
    "                image_syn.data[c*args.ipc:(c+1)*args.ipc] = get_images(c, args.ipc).detach().data\n",
    "        else:\n",
    "            print('initialize synthetic data from random noise')\n",
    "\n",
    "\n",
    "        ''' training '''\n",
    "        optimizer_img = torch.optim.SGD([image_syn, ], lr=args.lr_img, momentum=0.5) # optimizer_img for synthetic data\n",
    "        optimizer_img.zero_grad()\n",
    "        print('%s training begins'%get_time())\n",
    "\n",
    "        for it in range(args.Iteration+1):\n",
    "            ''' Train synthetic data '''\n",
    "            net = get_network(args.model, channel, num_classes, im_size).to(args.device) # get a random model\n",
    "            net.train()\n",
    "            for param in list(net.parameters()):\n",
    "                param.requires_grad = False\n",
    "\n",
    "            embed = net.module.embed if torch.cuda.device_count() > 1 else net.embed # for GPU parallel\n",
    "\n",
    "            loss_avg = 0\n",
    "\n",
    "            ''' update synthetic data '''\n",
    "            if 'BN' not in args.model: # for ConvNet\n",
    "                loss = torch.tensor(0.0).to(args.device)\n",
    "                for c in range(num_classes):\n",
    "                    img_real = get_images(c, args.batch_real)\n",
    "                    img_syn = image_syn[c*args.ipc:(c+1)*args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
    "\n",
    "                    if args.dsa:\n",
    "                        seed = int(time.time() * 1000) % 100000\n",
    "                        img_real = DiffAugment(img_real, args.dsa_strategy, seed=seed, param=args.dsa_param)\n",
    "                        img_syn = DiffAugment(img_syn, args.dsa_strategy, seed=seed, param=args.dsa_param)\n",
    "\n",
    "                    output_real = embed(img_real).detach()\n",
    "                    output_syn = embed(img_syn)\n",
    "#                     import pdb;pdb.set_trace()\n",
    "                    loss += torch.sum((torch.mean(output_real, dim=0) - torch.mean(output_syn, dim=0))**2)\n",
    "\n",
    "            else: # for ConvNetBN\n",
    "                images_real_all = []\n",
    "                images_syn_all = []\n",
    "                loss = torch.tensor(0.0).to(args.device)\n",
    "                for c in range(num_classes):\n",
    "                    img_real = get_images(c, args.batch_real)\n",
    "                    img_syn = image_syn[c*args.ipc:(c+1)*args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
    "\n",
    "                    if args.dsa:\n",
    "                        seed = int(time.time() * 1000) % 100000\n",
    "                        img_real = DiffAugment(img_real, args.dsa_strategy, seed=seed, param=args.dsa_param)\n",
    "                        img_syn = DiffAugment(img_syn, args.dsa_strategy, seed=seed, param=args.dsa_param)\n",
    "\n",
    "                    images_real_all.append(img_real)\n",
    "                    images_syn_all.append(img_syn)\n",
    "\n",
    "                images_real_all = torch.cat(images_real_all, dim=0)\n",
    "                images_syn_all = torch.cat(images_syn_all, dim=0)\n",
    "\n",
    "                output_real = embed(images_real_all).detach()\n",
    "                output_syn = embed(images_syn_all)\n",
    "\n",
    "                loss += torch.sum((torch.mean(output_real.reshape(num_classes, args.batch_real, -1), dim=1) - torch.mean(output_syn.reshape(num_classes, args.ipc, -1), dim=1))**2)\n",
    "\n",
    "\n",
    "\n",
    "            optimizer_img.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_img.step()\n",
    "            loss_avg += loss.item()\n",
    "\n",
    "\n",
    "            loss_avg /= (num_classes)\n",
    "\n",
    "            if it%10 == 0:\n",
    "                print('%s iter = %05d, loss = %.4f' % (get_time(), it, loss_avg))\n",
    "\n",
    "            if it == args.Iteration: # only record the final results\n",
    "                data_save.append([copy.deepcopy(image_syn.detach().cpu()), copy.deepcopy(label_syn.detach().cpu())])\n",
    "                torch.save({'data': data_save}, os.path.join(args.save_path, args.init+'res_%s_%s_%s_%dipc.pt'%(args.method, args.dataset, args.model, args.ipc)))\n",
    "                        \n",
    "            ''' Evaluate synthetic data '''\n",
    "            if it == eval_it_pool[-1]:\n",
    "                net_eval = get_network(args.model, channel, num_classes, im_size).to(args.device) # get a random model\n",
    "                image_syn_eval, label_syn_eval = copy.deepcopy(image_syn.detach()), copy.deepcopy(label_syn.detach()) # avoid any unaware modification\n",
    "                _, acc_train, acc_test = evaluate_synset(net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "                print('\\n==================== Final Results ====================\\n')\n",
    "                print('After {} iterations, the model test accuracy on synthetic data is {}%'.format(it, acc_test*100))\n",
    "            \n",
    "            if it in eval_it_pool:    \n",
    "                ''' visualize and save '''\n",
    "                save_name = os.path.join(args.save_path, args.init+'vis_%s_%s_%s_%dipc_exp%d_iter%d.png'%(args.method, args.dataset, args.model, args.ipc, exp, it))\n",
    "                image_syn_vis = copy.deepcopy(image_syn.detach().cpu())\n",
    "                for ch in range(channel):\n",
    "                    image_syn_vis[:, ch] = image_syn_vis[:, ch]  * std[ch] + mean[ch]\n",
    "                image_syn_vis[image_syn_vis<0] = 0.0\n",
    "                image_syn_vis[image_syn_vis>1] = 1.0\n",
    "                save_image(image_syn_vis, save_name, nrow=args.ipc) # Trying normalize = True/False may get better visual effects.\n",
    "\n",
    "class arguments():\n",
    "    def __init__(self,): \n",
    "        self.method = 'DM'\n",
    "        self.dataset = 'CIFAR10'\n",
    "        self.model = 'ConvNet'\n",
    "        #'image(s) per class'\n",
    "        self.ipc = 10\n",
    "         # S: the same to training model, M: multi architectures,  W: net width, D: net depth, A: activation function, P: pooling layer, N: normalization layer,\n",
    "        self.eval_mode = 'S'\n",
    "        #the number of experiments\n",
    "        self.num_exp = 1\n",
    "        #the number of evaluating randomly initialized models\n",
    "        self.num_eval = 1\n",
    "        #c\n",
    "        self.epoch_eval_train = 100\n",
    "        #training iterations\n",
    "        self.Iteration = 2000\n",
    "        self.lr_img = 1.0\n",
    "        self.lr_net = 0.01\n",
    "        self.batch_real = 256\n",
    "        self.batch_train = 256\n",
    "        #'noise/real: initialize synthetic images from random noise or randomly sampled real images.'\n",
    "        self.init = 'real'\n",
    "        self.dsa_strategy = 'color_crop_cutout_flip_scale_rotate'\n",
    "        self.data_path = 'CIFAR10data'\n",
    "        self.save_path = 'CIFAR10result'\n",
    "        self.dis_metric = 'ours'\n",
    "        self.outer_loop = 10\n",
    "        self.inner_loop = 50\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.dsa_param = ParamDiffAug()\n",
    "        self.dsa = 'False'\n",
    "        \n",
    "args = arguments()\n",
    "main(args)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "305f48f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_it_pool:  [0, 200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "================== Exp 0 ==================\n",
      " \n",
      "Hyper-parameters: \n",
      " {'method': 'DM', 'dataset': 'CIFAR10', 'model': 'ConvNet', 'ipc': 10, 'eval_mode': 'S', 'num_exp': 1, 'num_eval': 1, 'epoch_eval_train': 100, 'Iteration': 2000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'noise', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': 'CIFAR10data', 'save_path': 'CIFAR10result', 'dis_metric': 'ours', 'outer_loop': 10, 'inner_loop': 50, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x0000022CE07680A0>, 'dsa': 'False'}\n",
      "class c = 0: 5000 real images\n",
      "class c = 1: 5000 real images\n",
      "class c = 2: 5000 real images\n",
      "class c = 3: 5000 real images\n",
      "class c = 4: 5000 real images\n",
      "class c = 5: 5000 real images\n",
      "class c = 6: 5000 real images\n",
      "class c = 7: 5000 real images\n",
      "class c = 8: 5000 real images\n",
      "class c = 9: 5000 real images\n",
      "real images channel 0, mean = -0.0000, std = 1.2211\n",
      "real images channel 1, mean = -0.0002, std = 1.2211\n",
      "real images channel 2, mean = 0.0002, std = 1.3014\n",
      "initialize synthetic data from random noise\n",
      "[2022-12-02 12:40:27] training begins\n",
      "[2022-12-02 12:40:28] iter = 00000, loss = 57.8880\n",
      "[2022-12-02 12:40:30] iter = 00010, loss = 43.5092\n",
      "[2022-12-02 12:40:32] iter = 00020, loss = 27.0655\n",
      "[2022-12-02 12:40:34] iter = 00030, loss = 26.1203\n",
      "[2022-12-02 12:40:35] iter = 00040, loss = 17.0708\n",
      "[2022-12-02 12:40:38] iter = 00050, loss = 23.7103\n",
      "[2022-12-02 12:40:41] iter = 00060, loss = 15.1739\n",
      "[2022-12-02 12:40:42] iter = 00070, loss = 14.4874\n",
      "[2022-12-02 12:40:44] iter = 00080, loss = 17.5137\n",
      "[2022-12-02 12:40:46] iter = 00090, loss = 15.8970\n",
      "[2022-12-02 12:40:48] iter = 00100, loss = 13.1820\n",
      "[2022-12-02 12:40:50] iter = 00110, loss = 13.4501\n",
      "[2022-12-02 12:40:52] iter = 00120, loss = 15.9352\n",
      "[2022-12-02 12:40:53] iter = 00130, loss = 18.9592\n",
      "[2022-12-02 12:40:55] iter = 00140, loss = 15.4916\n",
      "[2022-12-02 12:40:57] iter = 00150, loss = 16.3149\n",
      "[2022-12-02 12:40:59] iter = 00160, loss = 12.1446\n",
      "[2022-12-02 12:41:01] iter = 00170, loss = 14.2435\n",
      "[2022-12-02 12:41:03] iter = 00180, loss = 11.8596\n",
      "[2022-12-02 12:41:05] iter = 00190, loss = 14.1358\n",
      "[2022-12-02 12:41:07] iter = 00200, loss = 13.5845\n",
      "[2022-12-02 12:41:08] iter = 00210, loss = 10.6399\n",
      "[2022-12-02 12:41:10] iter = 00220, loss = 11.2248\n",
      "[2022-12-02 12:41:12] iter = 00230, loss = 12.2902\n",
      "[2022-12-02 12:41:14] iter = 00240, loss = 10.2213\n",
      "[2022-12-02 12:41:16] iter = 00250, loss = 9.1968\n",
      "[2022-12-02 12:41:18] iter = 00260, loss = 10.1262\n",
      "[2022-12-02 12:41:20] iter = 00270, loss = 12.3334\n",
      "[2022-12-02 12:41:22] iter = 00280, loss = 9.5004\n",
      "[2022-12-02 12:41:23] iter = 00290, loss = 10.3807\n",
      "[2022-12-02 12:41:25] iter = 00300, loss = 9.0729\n",
      "[2022-12-02 12:41:27] iter = 00310, loss = 10.5825\n",
      "[2022-12-02 12:41:29] iter = 00320, loss = 9.0136\n",
      "[2022-12-02 12:41:32] iter = 00330, loss = 10.7839\n",
      "[2022-12-02 12:41:35] iter = 00340, loss = 13.4196\n",
      "[2022-12-02 12:41:37] iter = 00350, loss = 8.2735\n",
      "[2022-12-02 12:41:38] iter = 00360, loss = 9.8710\n",
      "[2022-12-02 12:41:40] iter = 00370, loss = 9.7843\n",
      "[2022-12-02 12:41:42] iter = 00380, loss = 10.0347\n",
      "[2022-12-02 12:41:44] iter = 00390, loss = 9.9749\n",
      "[2022-12-02 12:41:46] iter = 00400, loss = 8.5429\n",
      "[2022-12-02 12:41:48] iter = 00410, loss = 8.8692\n",
      "[2022-12-02 12:41:50] iter = 00420, loss = 10.2899\n",
      "[2022-12-02 12:41:52] iter = 00430, loss = 9.3568\n",
      "[2022-12-02 12:41:54] iter = 00440, loss = 9.1480\n",
      "[2022-12-02 12:41:56] iter = 00450, loss = 8.0973\n",
      "[2022-12-02 12:41:58] iter = 00460, loss = 8.9629\n",
      "[2022-12-02 12:41:59] iter = 00470, loss = 7.9880\n",
      "[2022-12-02 12:42:01] iter = 00480, loss = 7.9103\n",
      "[2022-12-02 12:42:03] iter = 00490, loss = 6.9137\n",
      "[2022-12-02 12:42:05] iter = 00500, loss = 9.5818\n",
      "[2022-12-02 12:42:07] iter = 00510, loss = 7.8783\n",
      "[2022-12-02 12:42:09] iter = 00520, loss = 7.4081\n",
      "[2022-12-02 12:42:10] iter = 00530, loss = 7.7276\n",
      "[2022-12-02 12:42:12] iter = 00540, loss = 8.3962\n",
      "[2022-12-02 12:42:14] iter = 00550, loss = 7.6752\n",
      "[2022-12-02 12:42:16] iter = 00560, loss = 8.9875\n",
      "[2022-12-02 12:42:18] iter = 00570, loss = 8.3048\n",
      "[2022-12-02 12:42:20] iter = 00580, loss = 7.7100\n",
      "[2022-12-02 12:42:22] iter = 00590, loss = 7.9415\n",
      "[2022-12-02 12:42:24] iter = 00600, loss = 7.5720\n",
      "[2022-12-02 12:42:26] iter = 00610, loss = 8.6582\n",
      "[2022-12-02 12:42:27] iter = 00620, loss = 8.4004\n",
      "[2022-12-02 12:42:29] iter = 00630, loss = 8.6155\n",
      "[2022-12-02 12:42:31] iter = 00640, loss = 8.3651\n",
      "[2022-12-02 12:42:33] iter = 00650, loss = 6.8516\n",
      "[2022-12-02 12:42:35] iter = 00660, loss = 7.6661\n",
      "[2022-12-02 12:42:37] iter = 00670, loss = 7.7479\n",
      "[2022-12-02 12:42:39] iter = 00680, loss = 7.1515\n",
      "[2022-12-02 12:42:41] iter = 00690, loss = 7.4201\n",
      "[2022-12-02 12:42:42] iter = 00700, loss = 6.5985\n",
      "[2022-12-02 12:42:44] iter = 00710, loss = 7.1816\n",
      "[2022-12-02 12:42:46] iter = 00720, loss = 8.2340\n",
      "[2022-12-02 12:42:48] iter = 00730, loss = 6.3980\n",
      "[2022-12-02 12:42:50] iter = 00740, loss = 7.5458\n",
      "[2022-12-02 12:42:52] iter = 00750, loss = 7.3566\n",
      "[2022-12-02 12:42:54] iter = 00760, loss = 7.3248\n",
      "[2022-12-02 12:42:55] iter = 00770, loss = 7.2312\n",
      "[2022-12-02 12:42:57] iter = 00780, loss = 7.3204\n",
      "[2022-12-02 12:42:59] iter = 00790, loss = 7.9874\n",
      "[2022-12-02 12:43:01] iter = 00800, loss = 6.2283\n",
      "[2022-12-02 12:43:03] iter = 00810, loss = 6.5657\n",
      "[2022-12-02 12:43:05] iter = 00820, loss = 6.4802\n",
      "[2022-12-02 12:43:07] iter = 00830, loss = 7.1749\n",
      "[2022-12-02 12:43:09] iter = 00840, loss = 6.6073\n",
      "[2022-12-02 12:43:11] iter = 00850, loss = 6.7392\n",
      "[2022-12-02 12:43:13] iter = 00860, loss = 7.5969\n",
      "[2022-12-02 12:43:15] iter = 00870, loss = 6.9748\n",
      "[2022-12-02 12:43:16] iter = 00880, loss = 6.5336\n",
      "[2022-12-02 12:43:18] iter = 00890, loss = 7.2702\n",
      "[2022-12-02 12:43:20] iter = 00900, loss = 6.3527\n",
      "[2022-12-02 12:43:22] iter = 00910, loss = 6.0731\n",
      "[2022-12-02 12:43:24] iter = 00920, loss = 6.6299\n",
      "[2022-12-02 12:43:26] iter = 00930, loss = 7.6852\n",
      "[2022-12-02 12:43:28] iter = 00940, loss = 7.1062\n",
      "[2022-12-02 12:43:30] iter = 00950, loss = 7.1035\n",
      "[2022-12-02 12:43:32] iter = 00960, loss = 6.9084\n",
      "[2022-12-02 12:43:33] iter = 00970, loss = 6.3566\n",
      "[2022-12-02 12:43:35] iter = 00980, loss = 7.1212\n",
      "[2022-12-02 12:43:37] iter = 00990, loss = 6.6978\n",
      "[2022-12-02 12:43:39] iter = 01000, loss = 7.1671\n",
      "[2022-12-02 12:43:41] iter = 01010, loss = 6.3148\n",
      "[2022-12-02 12:43:43] iter = 01020, loss = 6.5115\n",
      "[2022-12-02 12:43:44] iter = 01030, loss = 6.2605\n",
      "[2022-12-02 12:43:46] iter = 01040, loss = 6.6995\n",
      "[2022-12-02 12:43:48] iter = 01050, loss = 6.6536\n",
      "[2022-12-02 12:43:50] iter = 01060, loss = 6.5664\n",
      "[2022-12-02 12:43:52] iter = 01070, loss = 7.1779\n",
      "[2022-12-02 12:43:54] iter = 01080, loss = 6.3302\n",
      "[2022-12-02 12:43:56] iter = 01090, loss = 6.6622\n",
      "[2022-12-02 12:43:58] iter = 01100, loss = 6.9020\n",
      "[2022-12-02 12:44:00] iter = 01110, loss = 6.7308\n",
      "[2022-12-02 12:44:02] iter = 01120, loss = 6.2702\n",
      "[2022-12-02 12:44:04] iter = 01130, loss = 6.0212\n",
      "[2022-12-02 12:44:05] iter = 01140, loss = 5.8143\n",
      "[2022-12-02 12:44:07] iter = 01150, loss = 6.2333\n",
      "[2022-12-02 12:44:09] iter = 01160, loss = 5.9939\n",
      "[2022-12-02 12:44:11] iter = 01170, loss = 6.7315\n",
      "[2022-12-02 12:44:13] iter = 01180, loss = 6.1669\n",
      "[2022-12-02 12:44:15] iter = 01190, loss = 5.8132\n",
      "[2022-12-02 12:44:17] iter = 01200, loss = 5.7421\n",
      "[2022-12-02 12:44:19] iter = 01210, loss = 5.6845\n",
      "[2022-12-02 12:44:20] iter = 01220, loss = 6.4006\n",
      "[2022-12-02 12:44:22] iter = 01230, loss = 7.1732\n",
      "[2022-12-02 12:44:24] iter = 01240, loss = 5.8814\n",
      "[2022-12-02 12:44:26] iter = 01250, loss = 5.6861\n",
      "[2022-12-02 12:44:28] iter = 01260, loss = 5.9574\n",
      "[2022-12-02 12:44:29] iter = 01270, loss = 5.7878\n",
      "[2022-12-02 12:44:31] iter = 01280, loss = 6.5035\n",
      "[2022-12-02 12:44:33] iter = 01290, loss = 6.0757\n",
      "[2022-12-02 12:44:35] iter = 01300, loss = 5.9658\n",
      "[2022-12-02 12:44:37] iter = 01310, loss = 5.8090\n",
      "[2022-12-02 12:44:39] iter = 01320, loss = 6.3654\n",
      "[2022-12-02 12:44:41] iter = 01330, loss = 5.6344\n",
      "[2022-12-02 12:44:43] iter = 01340, loss = 5.9412\n",
      "[2022-12-02 12:44:44] iter = 01350, loss = 6.2624\n",
      "[2022-12-02 12:44:46] iter = 01360, loss = 5.6132\n",
      "[2022-12-02 12:44:48] iter = 01370, loss = 5.7917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-12-02 12:44:50] iter = 01380, loss = 5.5881\n",
      "[2022-12-02 12:44:52] iter = 01390, loss = 5.5504\n",
      "[2022-12-02 12:44:54] iter = 01400, loss = 5.9756\n",
      "[2022-12-02 12:44:56] iter = 01410, loss = 5.5081\n",
      "[2022-12-02 12:44:58] iter = 01420, loss = 6.0259\n",
      "[2022-12-02 12:45:00] iter = 01430, loss = 5.1876\n",
      "[2022-12-02 12:45:02] iter = 01440, loss = 5.5011\n",
      "[2022-12-02 12:45:03] iter = 01450, loss = 5.9627\n",
      "[2022-12-02 12:45:05] iter = 01460, loss = 6.0879\n",
      "[2022-12-02 12:45:07] iter = 01470, loss = 5.8868\n",
      "[2022-12-02 12:45:09] iter = 01480, loss = 6.3117\n",
      "[2022-12-02 12:45:11] iter = 01490, loss = 5.8311\n",
      "[2022-12-02 12:45:13] iter = 01500, loss = 5.5588\n",
      "[2022-12-02 12:45:15] iter = 01510, loss = 5.4481\n",
      "[2022-12-02 12:45:16] iter = 01520, loss = 5.8353\n",
      "[2022-12-02 12:45:18] iter = 01530, loss = 5.3948\n",
      "[2022-12-02 12:45:20] iter = 01540, loss = 5.5860\n",
      "[2022-12-02 12:45:22] iter = 01550, loss = 5.6611\n",
      "[2022-12-02 12:45:24] iter = 01560, loss = 5.8683\n",
      "[2022-12-02 12:45:26] iter = 01570, loss = 5.6886\n",
      "[2022-12-02 12:45:28] iter = 01580, loss = 5.7089\n",
      "[2022-12-02 12:45:29] iter = 01590, loss = 5.9134\n",
      "[2022-12-02 12:45:31] iter = 01600, loss = 5.7743\n",
      "[2022-12-02 12:45:33] iter = 01610, loss = 5.4118\n",
      "[2022-12-02 12:45:35] iter = 01620, loss = 5.2217\n",
      "[2022-12-02 12:45:37] iter = 01630, loss = 5.1463\n",
      "[2022-12-02 12:45:39] iter = 01640, loss = 5.3067\n",
      "[2022-12-02 12:45:41] iter = 01650, loss = 5.6075\n",
      "[2022-12-02 12:45:43] iter = 01660, loss = 5.2704\n",
      "[2022-12-02 12:45:44] iter = 01670, loss = 5.3948\n",
      "[2022-12-02 12:45:46] iter = 01680, loss = 5.5002\n",
      "[2022-12-02 12:45:48] iter = 01690, loss = 5.8733\n",
      "[2022-12-02 12:45:50] iter = 01700, loss = 5.4467\n",
      "[2022-12-02 12:45:52] iter = 01710, loss = 4.9076\n",
      "[2022-12-02 12:45:54] iter = 01720, loss = 4.9563\n",
      "[2022-12-02 12:45:56] iter = 01730, loss = 5.0955\n",
      "[2022-12-02 12:45:57] iter = 01740, loss = 5.3915\n",
      "[2022-12-02 12:45:59] iter = 01750, loss = 5.0860\n",
      "[2022-12-02 12:46:01] iter = 01760, loss = 5.5929\n",
      "[2022-12-02 12:46:03] iter = 01770, loss = 5.3998\n",
      "[2022-12-02 12:46:05] iter = 01780, loss = 5.4601\n",
      "[2022-12-02 12:46:07] iter = 01790, loss = 5.5529\n",
      "[2022-12-02 12:46:09] iter = 01800, loss = 5.0286\n",
      "[2022-12-02 12:46:11] iter = 01810, loss = 5.4083\n",
      "[2022-12-02 12:46:12] iter = 01820, loss = 5.4970\n",
      "[2022-12-02 12:46:14] iter = 01830, loss = 5.2624\n",
      "[2022-12-02 12:46:16] iter = 01840, loss = 4.9113\n",
      "[2022-12-02 12:46:18] iter = 01850, loss = 5.0278\n",
      "[2022-12-02 12:46:20] iter = 01860, loss = 4.9530\n",
      "[2022-12-02 12:46:22] iter = 01870, loss = 5.1831\n",
      "[2022-12-02 12:46:24] iter = 01880, loss = 4.9561\n",
      "[2022-12-02 12:46:25] iter = 01890, loss = 5.5684\n",
      "[2022-12-02 12:46:27] iter = 01900, loss = 5.4443\n",
      "[2022-12-02 12:46:29] iter = 01910, loss = 5.0447\n",
      "[2022-12-02 12:46:31] iter = 01920, loss = 4.9094\n",
      "[2022-12-02 12:46:33] iter = 01930, loss = 5.6149\n",
      "[2022-12-02 12:46:35] iter = 01940, loss = 5.2967\n",
      "[2022-12-02 12:46:37] iter = 01950, loss = 4.9999\n",
      "[2022-12-02 12:46:38] iter = 01960, loss = 5.2642\n",
      "[2022-12-02 12:46:40] iter = 01970, loss = 5.7091\n",
      "[2022-12-02 12:46:42] iter = 01980, loss = 5.0626\n",
      "[2022-12-02 12:46:44] iter = 01990, loss = 5.0467\n",
      "[2022-12-02 12:46:46] iter = 02000, loss = 5.3474\n",
      "\n",
      "==================== Final Results ====================\n",
      "\n",
      "After 2000 iterations, the model test accuracy on synthetic data is 43.97%\n"
     ]
    }
   ],
   "source": [
    "args.init = 'noise'\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7cbb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
