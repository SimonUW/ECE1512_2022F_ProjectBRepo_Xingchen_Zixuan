{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd02171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from utils import get_loops, get_dataset, get_network, get_eval_pool, evaluate_synset, get_daparam, match_loss, get_time, TensorDataset, epoch, DiffAugment, ParamDiffAug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "493fb55d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Epoch #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
      " 23%|███████████████████▏                                                               | 3/13 [00:00<00:00, 27.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The FLOPs is 1907605504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 43.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 5.0%\n",
      "Average train loss is 2.319987335205078\n",
      "Start Epoch #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 199.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 20.0%\n",
      "Average train loss is 2.296140041351318\n",
      "Start Epoch #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 173.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 23.0%\n",
      "Average train loss is 2.2753256511688233\n",
      "Start Epoch #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 189.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 32.0%\n",
      "Average train loss is 2.251053409576416\n",
      "Start Epoch #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 203.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 20.0%\n",
      "Average train loss is 2.2358448696136475\n",
      "Start Epoch #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 180.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 31.0%\n",
      "Average train loss is 2.2027390098571775\n",
      "Start Epoch #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 188.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 40.0%\n",
      "Average train loss is 2.163063716888428\n",
      "Start Epoch #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 186.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 42.0%\n",
      "Average train loss is 2.1130717849731444\n",
      "Start Epoch #9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 197.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 36.0%\n",
      "Average train loss is 2.0642401790618896\n",
      "Start Epoch #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 185.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 40.0%\n",
      "Average train loss is 1.9499921894073486\n",
      "Start Epoch #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 194.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 46.0%\n",
      "Average train loss is 1.8242185974121095\n",
      "Start Epoch #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 196.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 51.0%\n",
      "Average train loss is 1.682830400466919\n",
      "Start Epoch #13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 181.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 62.0%\n",
      "Average train loss is 1.5456060647964478\n",
      "Start Epoch #14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 209.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 68.0%\n",
      "Average train loss is 1.3750854015350342\n",
      "Start Epoch #15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 213.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 69.0%\n",
      "Average train loss is 1.2651242113113403\n",
      "Start Epoch #16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 203.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 73.0%\n",
      "Average train loss is 1.1190080404281617\n",
      "Start Epoch #17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 212.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 77.0%\n",
      "Average train loss is 1.0172993516921998\n",
      "Start Epoch #18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 209.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 79.0%\n",
      "Average train loss is 0.9866066837310791\n",
      "Start Epoch #19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 219.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 84.0%\n",
      "Average train loss is 0.925868968963623\n",
      "Start Epoch #20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 228.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 86.0%\n",
      "Average train loss is 0.9039381456375122\n",
      "Test accuracy is 82.89%\n",
      "Average test loss is 1.647504403114319\n",
      "Training on the original MNIST dataset takes 3.6319658756256104 seconds\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, test_loader, optimizer, scheduler, criterion, epochs):\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('Start Epoch #{}'.format(epoch+1))\n",
    "        with tqdm.tqdm(total=len(train_loader)) as pbar:\n",
    "            loss_avg, acc_avg, num_exp = 0, 0, 0\n",
    "            for i_batch, datum in enumerate(train_loader):\n",
    "                img = datum[0].float().to(device)\n",
    "                if epoch == 0 and i_batch == 0:\n",
    "                    flops = FlopCountAnalysis(model, img)\n",
    "                    print('The FLOPs is {}'.format(flops.total()))\n",
    "        #         if aug:\n",
    "        #             if args.dsa:\n",
    "        #                 img = DiffAugment(img, args.dsa_strategy, param=args.dsa_param)\n",
    "        #             else:\n",
    "        #                 img = augment(img, args.dc_aug_param, device=args.device)\n",
    "                lab = datum[1].long().to(device)\n",
    "                n_b = lab.shape[0]\n",
    "                output = model(img)\n",
    "                loss = criterion(output, lab)\n",
    "                acc = np.sum(np.equal(np.argmax(output.cpu().data.numpy(), axis=-1), lab.cpu().data.numpy()))\n",
    "                loss_avg += loss.item()*n_b\n",
    "                acc_avg += acc\n",
    "                num_exp += n_b\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                pbar.update(1)\n",
    "                del img, lab\n",
    "                \n",
    "        loss_avg /= num_exp\n",
    "        acc_avg /= num_exp\n",
    "        scheduler.step()\n",
    "        print('Train accuracy is {}%'.format(acc_avg*100))\n",
    "        print('Average train loss is {}'.format(loss_avg))\n",
    "        \n",
    "    loss_avg, acc_avg, num_exp = 0, 0, 0   \n",
    "    model.eval()\n",
    "    for i_batch, datum in enumerate(test_loader):\n",
    "        img = datum[0].float().to(device)\n",
    "        lab = datum[1].long().to(device)\n",
    "        n_b = lab.shape[0]\n",
    "        output = model(img)\n",
    "        loss = criterion(output, lab)\n",
    "        acc = np.sum(np.equal(np.argmax(output.cpu().data.numpy(), axis=-1), lab.cpu().data.numpy()))\n",
    "        loss_avg += loss.item()*n_b\n",
    "        acc_avg += acc\n",
    "        num_exp += n_b\n",
    "        \n",
    "        del img, lab\n",
    "\n",
    "    loss_avg /= num_exp\n",
    "    acc_avg /= num_exp\n",
    "    print('Test accuracy is {}%'.format(acc_avg*100))\n",
    "    print('Average test loss is {}'.format(loss_avg))          \n",
    "\n",
    "    return loss_avg, acc_avg\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform): # images: n x c x h x w tensor\n",
    "        self.images = images.detach().float()\n",
    "        self.labels = labels.detach()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transform(self.images[index]), self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "    \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "data_path = './MNISTresult/realres_DC_MNIST_ConvNet_10ipc.pt'\n",
    "data = torch.load(data_path)\n",
    "images = data['data'][0][0]\n",
    "\n",
    "# for img in images:\n",
    "#     img = img*255\n",
    "#     plt.imshow(img.permute(1,2,0), cmap='gray', vmin=0, vmax=255)\n",
    "#     plt.show()\n",
    "MNIST_dataset = 'MNIST'\n",
    "MNIST_data_path = './MNISTdata'\n",
    "MNIST_channel, MNIST_im_size, MNIST_num_classes, MNIST_class_names, MNIST_mean, MNIST_std, MNIST_dst_train, MNIST_dst_test, MNIST_testloader = get_dataset(MNIST_dataset, MNIST_data_path)\n",
    "condensed_labs_train = torch.ones(10*MNIST_num_classes)\n",
    "mean = [0.1307]\n",
    "std = [0.3081]\n",
    "transform = transforms.Compose([transforms.Normalize(mean=mean, std=std)])\n",
    "\n",
    "for c in range(MNIST_num_classes):  \n",
    "    condensed_labs_train[c*10:(c+1)*10]*=c\n",
    "    \n",
    "condensed_train_dst = CustomDataset(images, condensed_labs_train, transform)\n",
    "MNIST_trainloader = torch.utils.data.DataLoader(condensed_train_dst, batch_size=8, shuffle=True, num_workers=0)\n",
    "model = get_network('AlexNet', MNIST_channel, MNIST_num_classes, MNIST_im_size).to(device) # get a random model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=0)\n",
    "epochs = 20\n",
    "start = time.time()\n",
    "train(model, MNIST_trainloader , MNIST_testloader , optimizer, scheduler, criterion, epochs)\n",
    "print('Training on the original MNIST dataset takes {} seconds'.format(time.time()-start))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f195068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee899cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
