{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c97bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from utils import get_loops, get_dataset, get_network, get_eval_pool, evaluate_synset, get_daparam, match_loss, get_time, TensorDataset, epoch, DiffAugment, ParamDiffAug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd6214b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Start Epoch #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
      " 31%|█████████████████████████▌                                                         | 4/13 [00:00<00:00, 33.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The FLOPs is 1960034304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 39.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 7.000000000000001%\n",
      "Average train loss is 2.322800941467285\n",
      "Start Epoch #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 191.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 15.0%\n",
      "Average train loss is 2.2777725219726563\n",
      "Start Epoch #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 203.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 16.0%\n",
      "Average train loss is 2.2258460330963135\n",
      "Start Epoch #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 206.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 22.0%\n",
      "Average train loss is 2.143567943572998\n",
      "Start Epoch #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 210.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 19.0%\n",
      "Average train loss is 2.103898735046387\n",
      "Start Epoch #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 215.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 26.0%\n",
      "Average train loss is 2.007688226699829\n",
      "Start Epoch #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 210.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 30.0%\n",
      "Average train loss is 1.9272135877609253\n",
      "Start Epoch #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 224.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 30.0%\n",
      "Average train loss is 1.845277795791626\n",
      "Start Epoch #9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 182.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 32.0%\n",
      "Average train loss is 1.8748187828063965\n",
      "Start Epoch #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 224.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 33.0%\n",
      "Average train loss is 1.6779120635986329\n",
      "Start Epoch #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 220.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 48.0%\n",
      "Average train loss is 1.539889931678772\n",
      "Start Epoch #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 222.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 45.0%\n",
      "Average train loss is 1.5718065452575685\n",
      "Start Epoch #13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 219.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 54.0%\n",
      "Average train loss is 1.3636942100524903\n",
      "Start Epoch #14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 219.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 54.0%\n",
      "Average train loss is 1.298374834060669\n",
      "Start Epoch #15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 233.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 59.0%\n",
      "Average train loss is 1.2198048973083495\n",
      "Start Epoch #16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 227.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 66.0%\n",
      "Average train loss is 1.147015345096588\n",
      "Start Epoch #17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 235.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 69.0%\n",
      "Average train loss is 1.0841358757019044\n",
      "Start Epoch #18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 234.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 75.0%\n",
      "Average train loss is 1.028213918209076\n",
      "Start Epoch #19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 235.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 76.0%\n",
      "Average train loss is 1.0008485651016235\n",
      "Start Epoch #20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 234.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 76.0%\n",
      "Average train loss is 0.9808714413642883\n",
      "Test accuracy is 29.520000000000003%\n",
      "Average test loss is 2.0852886209487913\n",
      "Training on the original CIFAR10 dataset takes 3.881880760192871 seconds\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, test_loader, optimizer, scheduler, criterion, epochs):\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('Start Epoch #{}'.format(epoch+1))\n",
    "        with tqdm.tqdm(total=len(train_loader)) as pbar:\n",
    "            loss_avg, acc_avg, num_exp = 0, 0, 0\n",
    "            for i_batch, datum in enumerate(train_loader):\n",
    "                img = datum[0].float().to(device)\n",
    "                if epoch == 0 and i_batch == 0:\n",
    "                    flops = FlopCountAnalysis(model, img)\n",
    "                    print('The FLOPs is {}'.format(flops.total()))\n",
    "        #         if aug:\n",
    "        #             if args.dsa:\n",
    "        #                 img = DiffAugment(img, args.dsa_strategy, param=args.dsa_param)\n",
    "        #             else:\n",
    "        #                 img = augment(img, args.dc_aug_param, device=args.device)\n",
    "                lab = datum[1].long().to(device)\n",
    "                n_b = lab.shape[0]\n",
    "                output = model(img)\n",
    "                loss = criterion(output, lab)\n",
    "                acc = np.sum(np.equal(np.argmax(output.cpu().data.numpy(), axis=-1), lab.cpu().data.numpy()))\n",
    "                loss_avg += loss.item()*n_b\n",
    "                acc_avg += acc\n",
    "                num_exp += n_b\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                pbar.update(1)\n",
    "                del img, lab\n",
    "                \n",
    "        loss_avg /= num_exp\n",
    "        acc_avg /= num_exp\n",
    "        scheduler.step()\n",
    "        print('Train accuracy is {}%'.format(acc_avg*100))\n",
    "        print('Average train loss is {}'.format(loss_avg))\n",
    "        \n",
    "    loss_avg, acc_avg, num_exp = 0, 0, 0   \n",
    "    model.eval()\n",
    "    for i_batch, datum in enumerate(test_loader):\n",
    "        img = datum[0].float().to(device)\n",
    "        lab = datum[1].long().to(device)\n",
    "        n_b = lab.shape[0]\n",
    "        output = model(img)\n",
    "        loss = criterion(output, lab)\n",
    "        acc = np.sum(np.equal(np.argmax(output.cpu().data.numpy(), axis=-1), lab.cpu().data.numpy()))\n",
    "        loss_avg += loss.item()*n_b\n",
    "        acc_avg += acc\n",
    "        num_exp += n_b\n",
    "        \n",
    "        del img, lab\n",
    "\n",
    "    loss_avg /= num_exp\n",
    "    acc_avg /= num_exp\n",
    "    print('Test accuracy is {}%'.format(acc_avg*100))\n",
    "    print('Average test loss is {}'.format(loss_avg))          \n",
    "\n",
    "    return loss_avg, acc_avg\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform): # images: n x c x h x w tensor\n",
    "        self.images = images.detach().float()\n",
    "        self.labels = labels.detach()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transform(self.images[index]), self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "    \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "data_path = './CIFAR10result/realres_DC_CIFAR10_ConvNet_10ipc.pt'\n",
    "data = torch.load(data_path)\n",
    "images = data['data'][0][0]\n",
    "\n",
    "# for img in images:\n",
    "#     img = img*255\n",
    "#     plt.imshow(img.permute(1,2,0), cmap='gray', vmin=0, vmax=255)\n",
    "#     plt.show()\n",
    "CIFAR10_dataset = 'CIFAR10'\n",
    "CIFAR10_data_path = './CIFAR10data'\n",
    "CIFAR10_channel, CIFAR10_im_size, CIFAR10_num_classes, CIFAR10_class_names, CIFAR10_mean, CIFAR10_std, CIFAR10_dst_train, CIFAR10_dst_test, CIFAR10_testloader = get_dataset(CIFAR10_dataset, CIFAR10_data_path)\n",
    "condensed_labs_train = torch.ones(10*CIFAR10_num_classes)\n",
    "mean = [0.4914, 0.4822, 0.4465]\n",
    "std = [0.2023, 0.1994, 0.2010]\n",
    "transform = transforms.Compose([transforms.Normalize(mean=mean, std=std)])\n",
    "\n",
    "for c in range(CIFAR10_num_classes):  \n",
    "    condensed_labs_train[c*10:(c+1)*10]*=c\n",
    "    \n",
    "condensed_train_dst = CustomDataset(images, condensed_labs_train, transform)\n",
    "CIFAR10_trainloader = torch.utils.data.DataLoader(condensed_train_dst, batch_size=8, shuffle=True, num_workers=0)\n",
    "model = get_network('AlexNet', CIFAR10_channel, CIFAR10_num_classes, CIFAR10_im_size).to(device) # get a random model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=0)\n",
    "epochs = 20\n",
    "start = time.time()\n",
    "train(model, CIFAR10_trainloader , CIFAR10_testloader , optimizer, scheduler, criterion, epochs)\n",
    "print('Training on the original CIFAR10 dataset takes {} seconds'.format(time.time()-start))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3bbb68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a4ad48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
