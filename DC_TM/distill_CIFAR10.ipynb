{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da05e030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDNN STATUS: True\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzixuanuw\u001b[0m (\u001b[33mece1512\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\zixua\\Documents\\M1\\ECE1512\\PB\\DC_TM\\wandb\\run-20221130_203540-vci56iw4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ece1512/DatasetDistillation/runs/vci56iw4\" target=\"_blank\">graceful-yogurt-22</a></strong> to <a href=\"https://wandb.ai/ece1512/DatasetDistillation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper-parameters: \n",
      " {'dataset': 'CIFAR10', 'subset': 'imagenette', 'model': 'ConvNet', 'lr_img': 1000, 'lr_lr': 1e-05, 'lr_teacher': 0.01, 'lr_init': 0.01, 'batch_real': 256, 'batch_train': 256, 'batch_syn': 100, 'pix_init': 'real', 'dsa': False, 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': 'CIFAR10data', 'buffer_path': './CIFAR10buffers', 'expert_epochs': 3, 'syn_steps': 20, 'max_start_epoch': 25, 'load_all': False, 'no_aug': False, 'zca': False, 'texture': False, 'canvas_size': 2, 'canvas_samples': 1, 'max_files': None, 'max_experts': None, 'force_save': False, 'ipc': 10, 'eval_mode': 'S', 'num_eval': 5, 'eval_it': 100, 'epoch_eval_train': 1000, 'Iteration': 2000, 'device': 'cuda', 'im_size': [32, 32], 'dc_aug_param': None, 'dsa_param': <utils.ParamDiffAug object at 0x000002088FEA1900>, '_wandb': {}, 'zca_trans': None, 'distributed': False}\n",
      "BUILDING DATASET\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 50000/50000 [00:09<00:00, 5155.12it/s]\n",
      "50000it [00:00, 2908066.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class c = 0: 5000 real images\n",
      "class c = 1: 5000 real images\n",
      "class c = 2: 5000 real images\n",
      "class c = 3: 5000 real images\n",
      "class c = 4: 5000 real images\n",
      "class c = 5: 5000 real images\n",
      "class c = 6: 5000 real images\n",
      "class c = 7: 5000 real images\n",
      "class c = 8: 5000 real images\n",
      "class c = 9: 5000 real images\n",
      "real images channel 0, mean = -0.0000, std = 1.2211\n",
      "real images channel 1, mean = -0.0002, std = 1.2211\n",
      "real images channel 2, mean = 0.0002, std = 1.3014\n",
      "initialize synthetic data from random real images\n",
      "[2022-11-30 20:35:51] training begins\n",
      "Expert Dir: ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zixua\\AppData\\Local\\Temp\\ipykernel_22916\\119007861.py:107: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  label_syn = torch.tensor([np.ones(args.ipc,dtype=np.int_)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-30 20:35:55] iter = 0000, loss = 1.0818\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:36:03] iter = 0010, loss = 0.9840\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:36:10] iter = 0020, loss = 0.9682\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:36:17] iter = 0030, loss = 0.9748\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:36:24] iter = 0040, loss = 0.9798\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:36:31] iter = 0050, loss = 0.9781\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:36:38] iter = 0060, loss = 0.9645\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:36:45] iter = 0070, loss = 0.9662\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:36:52] iter = 0080, loss = 0.9010\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:36:59] iter = 0090, loss = 0.9744\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:37:06] iter = 0100, loss = 0.9761\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:37:13] iter = 0110, loss = 0.9706\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:37:20] iter = 0120, loss = 0.9853\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:37:27] iter = 0130, loss = 0.9674\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:37:34] iter = 0140, loss = 0.9609\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:37:41] iter = 0150, loss = 0.9748\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:37:48] iter = 0160, loss = 0.8736\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:37:55] iter = 0170, loss = 0.9737\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:38:02] iter = 0180, loss = 0.9134\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:38:09] iter = 0190, loss = 0.9092\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:38:16] iter = 0200, loss = 0.8302\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:38:23] iter = 0210, loss = 0.9767\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:38:30] iter = 0220, loss = 0.8411\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:38:37] iter = 0230, loss = 0.9069\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:38:44] iter = 0240, loss = 0.9452\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:38:51] iter = 0250, loss = 0.9554\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:38:58] iter = 0260, loss = 0.9462\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:39:05] iter = 0270, loss = 0.9768\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:39:11] iter = 0280, loss = 0.9842\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:39:18] iter = 0290, loss = 0.8807\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:39:25] iter = 0300, loss = 0.8657\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:39:33] iter = 0310, loss = 0.9731\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:39:40] iter = 0320, loss = 0.8469\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:39:47] iter = 0330, loss = 0.8305\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:39:54] iter = 0340, loss = 0.9587\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:40:00] iter = 0350, loss = 0.9466\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:40:07] iter = 0360, loss = 0.9361\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:40:14] iter = 0370, loss = 0.8776\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:40:21] iter = 0380, loss = 0.9846\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:40:28] iter = 0390, loss = 0.9497\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:40:35] iter = 0400, loss = 0.9716\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:40:43] iter = 0410, loss = 0.9270\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:40:50] iter = 0420, loss = 0.9749\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:40:57] iter = 0430, loss = 0.9773\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:41:04] iter = 0440, loss = 0.9659\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:41:11] iter = 0450, loss = 0.9674\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:41:18] iter = 0460, loss = 0.9727\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:41:25] iter = 0470, loss = 0.9778\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:41:32] iter = 0480, loss = 0.9671\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:41:39] iter = 0490, loss = 0.9704\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:41:46] iter = 0500, loss = 0.9083\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:41:53] iter = 0510, loss = 0.9246\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:42:00] iter = 0520, loss = 0.9760\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:42:07] iter = 0530, loss = 0.9756\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:42:14] iter = 0540, loss = 0.9740\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:42:21] iter = 0550, loss = 0.9711\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:42:28] iter = 0560, loss = 0.9798\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:42:35] iter = 0570, loss = 0.9332\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:42:42] iter = 0580, loss = 0.9761\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:42:48] iter = 0590, loss = 0.8277\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:42:55] iter = 0600, loss = 0.8680\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:43:03] iter = 0610, loss = 0.8650\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:43:10] iter = 0620, loss = 0.9685\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:43:17] iter = 0630, loss = 0.9862\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:43:24] iter = 0640, loss = 0.8754\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:43:31] iter = 0650, loss = 0.9036\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:43:38] iter = 0660, loss = 0.9704\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:43:44] iter = 0670, loss = 0.7883\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:43:52] iter = 0680, loss = 0.9790\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:43:58] iter = 0690, loss = 0.9757\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:44:05] iter = 0700, loss = 0.8990\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:44:13] iter = 0710, loss = 0.8180\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:44:20] iter = 0720, loss = 0.7661\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:44:27] iter = 0730, loss = 0.9766\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:44:34] iter = 0740, loss = 0.8697\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:44:40] iter = 0750, loss = 0.9703\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:44:47] iter = 0760, loss = 0.6700\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:44:54] iter = 0770, loss = 0.9744\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:45:01] iter = 0780, loss = 0.9273\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:45:08] iter = 0790, loss = 0.7679\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:45:15] iter = 0800, loss = 0.9389\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:45:23] iter = 0810, loss = 0.9471\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:45:30] iter = 0820, loss = 0.9576\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:45:37] iter = 0830, loss = 0.9387\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:45:44] iter = 0840, loss = 0.9573\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:45:51] iter = 0850, loss = 0.9590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:45:58] iter = 0860, loss = 0.9135\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:46:05] iter = 0870, loss = 0.9727\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:46:12] iter = 0880, loss = 0.9623\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:46:18] iter = 0890, loss = 0.9614\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:46:25] iter = 0900, loss = 0.9527\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:46:33] iter = 0910, loss = 0.9830\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:46:40] iter = 0920, loss = 0.9865\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:46:47] iter = 0930, loss = 0.7505\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:46:54] iter = 0940, loss = 0.9709\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:47:01] iter = 0950, loss = 0.7539\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:47:08] iter = 0960, loss = 0.8923\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:47:15] iter = 0970, loss = 0.9816\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:47:22] iter = 0980, loss = 0.8227\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:47:29] iter = 0990, loss = 0.9697\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:47:35] iter = 1000, loss = 0.9758\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:47:43] iter = 1010, loss = 0.9840\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:47:50] iter = 1020, loss = 0.7886\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:47:57] iter = 1030, loss = 0.9734\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:48:04] iter = 1040, loss = 0.9770\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:48:11] iter = 1050, loss = 0.9743\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:48:18] iter = 1060, loss = 0.9837\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:48:25] iter = 1070, loss = 0.9686\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:48:31] iter = 1080, loss = 0.9401\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:48:38] iter = 1090, loss = 0.7582\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:48:45] iter = 1100, loss = 0.9477\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:48:53] iter = 1110, loss = 0.9815\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:49:00] iter = 1120, loss = 0.9553\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:49:07] iter = 1130, loss = 0.9493\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:49:14] iter = 1140, loss = 0.9687\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:49:21] iter = 1150, loss = 0.8409\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:49:28] iter = 1160, loss = 0.8443\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:49:34] iter = 1170, loss = 0.8289\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:49:42] iter = 1180, loss = 0.9120\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:49:48] iter = 1190, loss = 0.9715\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:49:55] iter = 1200, loss = 0.7929\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:50:03] iter = 1210, loss = 0.7828\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:50:10] iter = 1220, loss = 0.9386\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:50:17] iter = 1230, loss = 0.9434\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:50:24] iter = 1240, loss = 0.9644\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:50:31] iter = 1250, loss = 0.7252\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:50:38] iter = 1260, loss = 0.9648\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:50:45] iter = 1270, loss = 0.9463\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-30 20:50:52] iter = 1280, loss = 0.8457\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:50:59] iter = 1290, loss = 0.9757\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:51:05] iter = 1300, loss = 0.9797\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:51:13] iter = 1310, loss = 0.9759\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:51:20] iter = 1320, loss = 0.7132\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:51:27] iter = 1330, loss = 0.6772\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:51:34] iter = 1340, loss = 0.7376\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:51:41] iter = 1350, loss = 0.8408\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:51:48] iter = 1360, loss = 0.8993\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:51:55] iter = 1370, loss = 0.7318\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:52:02] iter = 1380, loss = 0.9860\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:52:08] iter = 1390, loss = 0.9707\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:52:16] iter = 1400, loss = 0.9604\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:52:23] iter = 1410, loss = 0.9839\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:52:30] iter = 1420, loss = 0.6939\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:52:37] iter = 1430, loss = 0.9798\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:52:44] iter = 1440, loss = 0.9773\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:52:51] iter = 1450, loss = 0.9523\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:52:58] iter = 1460, loss = 0.9564\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:53:05] iter = 1470, loss = 0.8401\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:53:12] iter = 1480, loss = 0.6907\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:53:19] iter = 1490, loss = 0.7743\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:53:25] iter = 1500, loss = 0.9577\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:53:33] iter = 1510, loss = 0.9695\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:53:40] iter = 1520, loss = 0.9349\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:53:47] iter = 1530, loss = 0.9462\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:53:54] iter = 1540, loss = 0.8951\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:54:01] iter = 1550, loss = 0.7898\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:54:08] iter = 1560, loss = 0.8697\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:54:15] iter = 1570, loss = 0.9788\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:54:22] iter = 1580, loss = 0.8574\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:54:29] iter = 1590, loss = 0.6826\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:54:36] iter = 1600, loss = 0.9872\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:54:43] iter = 1610, loss = 0.7498\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:54:50] iter = 1620, loss = 0.9539\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:54:57] iter = 1630, loss = 0.6376\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:55:04] iter = 1640, loss = 0.6682\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:55:11] iter = 1650, loss = 0.6405\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:55:18] iter = 1660, loss = 0.9698\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:55:25] iter = 1670, loss = 0.9015\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:55:32] iter = 1680, loss = 0.6117\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:55:39] iter = 1690, loss = 0.9728\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:55:45] iter = 1700, loss = 0.9642\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:55:53] iter = 1710, loss = 0.9776\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:56:00] iter = 1720, loss = 0.9805\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:56:07] iter = 1730, loss = 0.9594\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:56:14] iter = 1740, loss = 0.9733\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:56:21] iter = 1750, loss = 0.9339\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:56:28] iter = 1760, loss = 0.9728\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:56:35] iter = 1770, loss = 0.8454\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:56:42] iter = 1780, loss = 0.9806\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:56:49] iter = 1790, loss = 0.9735\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:56:56] iter = 1800, loss = 0.8389\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:57:03] iter = 1810, loss = 0.9539\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:57:10] iter = 1820, loss = 0.9816\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:57:17] iter = 1830, loss = 0.9511\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:57:24] iter = 1840, loss = 0.7587\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:57:31] iter = 1850, loss = 0.8550\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:57:38] iter = 1860, loss = 0.9686\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:57:45] iter = 1870, loss = 0.9781\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:57:52] iter = 1880, loss = 0.8069\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:57:59] iter = 1890, loss = 0.8025\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:58:06] iter = 1900, loss = 0.6668\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:58:13] iter = 1910, loss = 0.9582\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:58:20] iter = 1920, loss = 0.9794\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:58:27] iter = 1930, loss = 0.7694\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:58:34] iter = 1940, loss = 0.9484\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:58:41] iter = 1950, loss = 0.6878\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:58:48] iter = 1960, loss = 0.9809\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:58:55] iter = 1970, loss = 0.9218\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "[2022-11-30 20:59:02] iter = 1980, loss = 0.7225\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:59:09] iter = 1990, loss = 0.9302\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "loading file ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n",
      "[2022-11-30 20:59:16] iter = 2000, loss = 0.8346\n",
      "-------------------------\n",
      "Evaluation\n",
      "model_train = ConvNet, model_eval = ConvNet, iteration = 2000\n",
      "\n",
      "==================== Final Results ====================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1001/1001 [00:13<00:00, 72.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-30 20:59:29] Evaluate: epoch = 1000 train time = 13 s train loss = 0.000547 train acc = 1.0000, test acc = 0.4353\n",
      "After 2000 iterations, the model test accuracy on synthetic data is 43.53%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Grand_Loss</td><td>▆█▆█▇▇▅▇▆█▃▆█▂▇█▇█▅▃▅▄██████▃▁█▄▇█▇█▆██▅</td></tr><tr><td>Progress</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>Start_Epoch</td><td>▂▅▂▅▃▄▃▆▃█▂▃█▂▄▆▄█▃▂▃▁▇█▇▇▆▇▂▁▇▃▄█▅█▃▇█▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Grand_Loss</td><td>0.83461</td></tr><tr><td>Progress</td><td>2000</td></tr><tr><td>Start_Epoch</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">graceful-yogurt-22</strong>: <a href=\"https://wandb.ai/ece1512/DatasetDistillation/runs/vci56iw4\" target=\"_blank\">https://wandb.ai/ece1512/DatasetDistillation/runs/vci56iw4</a><br/>Synced 5 W&B file(s), 42 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221130_203540-vci56iw4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils\n",
    "from tqdm import tqdm\n",
    "from utils import get_dataset, get_network, get_eval_pool, evaluate_synset, get_time, DiffAugment, ParamDiffAug\n",
    "import wandb\n",
    "import copy\n",
    "import random\n",
    "from reparam_module import ReparamModule\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    if args.zca and args.texture:\n",
    "        raise AssertionError(\"Cannot use zca and texture together\")\n",
    "\n",
    "    if args.texture and args.pix_init == \"real\":\n",
    "        print(\"WARNING: Using texture with real initialization will take a very long time to smooth out the boundaries between images.\")\n",
    "\n",
    "    if args.max_experts is not None and args.max_files is not None:\n",
    "        args.total_experts = args.max_experts * args.max_files\n",
    "\n",
    "    print(\"CUDNN STATUS: {}\".format(torch.backends.cudnn.enabled))\n",
    "\n",
    "    args.dsa = True if args.dsa == 'True' else False\n",
    "    args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    eval_it_pool = [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]\n",
    "    channel, im_size, num_classes, class_names, mean_orig, std_orig, dst_train, dst_test, testloader, loader_train_dict, class_map, class_map_inv = get_dataset(args.dataset, args.data_path, args.batch_real, args.subset, args=args)\n",
    "    mean = mean_orig.copy()\n",
    "    std = std_orig.copy()\n",
    "    im_res = im_size[0]\n",
    "\n",
    "    args.im_size = im_size\n",
    "\n",
    "    data_save = []\n",
    "\n",
    "    if args.dsa:\n",
    "        # args.epoch_eval_train = 1000\n",
    "        args.dc_aug_param = None\n",
    "    args.dc_aug_param = None\n",
    "    args.dsa_param = ParamDiffAug()\n",
    "\n",
    "    dsa_params = args.dsa_param\n",
    "    if args.zca:\n",
    "        zca_trans = args.zca_trans\n",
    "    else:\n",
    "        zca_trans = None\n",
    "\n",
    "    wandb.init(sync_tensorboard=False,\n",
    "               project=\"DatasetDistillation\",\n",
    "               job_type=\"CleanRepo\",\n",
    "               config=args,\n",
    "               )\n",
    "\n",
    "    args = type('', (), {})()\n",
    "\n",
    "    for key in wandb.config._items:\n",
    "        setattr(args, key, wandb.config._items[key])\n",
    "\n",
    "    args.dsa_param = dsa_params\n",
    "    args.zca_trans = zca_trans\n",
    "\n",
    "    if args.batch_syn is None:\n",
    "        args.batch_syn = num_classes * args.ipc\n",
    "\n",
    "    args.distributed = torch.cuda.device_count() > 1\n",
    "\n",
    "\n",
    "    print('Hyper-parameters: \\n', args.__dict__)\n",
    "\n",
    "    ''' organize the real dataset '''\n",
    "    images_all = []\n",
    "    labels_all = []\n",
    "    indices_class = [[] for c in range(num_classes)]\n",
    "    print(\"BUILDING DATASET\")\n",
    "    for i in tqdm(range(len(dst_train))):\n",
    "        sample = dst_train[i]\n",
    "        images_all.append(torch.unsqueeze(sample[0], dim=0))\n",
    "        labels_all.append(class_map[torch.tensor(sample[1]).item()])\n",
    "\n",
    "    for i, lab in tqdm(enumerate(labels_all)):\n",
    "        indices_class[lab].append(i)\n",
    "    images_all = torch.cat(images_all, dim=0).to(\"cpu\")\n",
    "    labels_all = torch.tensor(labels_all, dtype=torch.long, device=\"cpu\")\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        print('class c = %d: %d real images'%(c, len(indices_class[c])))\n",
    "\n",
    "    for ch in range(channel):\n",
    "        print('real images channel %d, mean = %.4f, std = %.4f'%(ch, torch.mean(images_all[:, ch]), torch.std(images_all[:, ch])))\n",
    "\n",
    "\n",
    "    def get_images(c, n):  # get random n images from class c\n",
    "        idx_shuffle = np.random.permutation(indices_class[c])[:n]\n",
    "        return images_all[idx_shuffle]\n",
    "\n",
    "\n",
    "    ''' initialize the synthetic data '''\n",
    "    label_syn = torch.tensor([np.ones(args.ipc,dtype=np.int_)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]\n",
    "\n",
    "    if args.texture:\n",
    "        image_syn = torch.randn(size=(num_classes * args.ipc, channel, im_size[0]*args.canvas_size, im_size[1]*args.canvas_size), dtype=torch.float)\n",
    "    else:\n",
    "        image_syn = torch.randn(size=(num_classes * args.ipc, channel, im_size[0], im_size[1]), dtype=torch.float)\n",
    "\n",
    "    syn_lr = torch.tensor(args.lr_teacher).to(args.device)\n",
    "\n",
    "    if args.pix_init == 'real':\n",
    "        print('initialize synthetic data from random real images')\n",
    "        if args.texture:\n",
    "            for c in range(num_classes):\n",
    "                for i in range(args.canvas_size):\n",
    "                    for j in range(args.canvas_size):\n",
    "                        image_syn.data[c * args.ipc:(c + 1) * args.ipc, :, i * im_size[0]:(i + 1) * im_size[0],\n",
    "                        j * im_size[1]:(j + 1) * im_size[1]] = torch.cat(\n",
    "                            [get_images(c, 1).detach().data for s in range(args.ipc)])\n",
    "        for c in range(num_classes):\n",
    "            image_syn.data[c * args.ipc:(c + 1) * args.ipc] = get_images(c, args.ipc).detach().data\n",
    "    else:\n",
    "        print('initialize synthetic data from random noise')\n",
    "\n",
    "\n",
    "    ''' training '''\n",
    "    image_syn = image_syn.detach().to(args.device).requires_grad_(True)\n",
    "    syn_lr = syn_lr.detach().to(args.device).requires_grad_(True)\n",
    "    optimizer_img = torch.optim.SGD([image_syn], lr=args.lr_img, momentum=0.5)\n",
    "    optimizer_lr = torch.optim.SGD([syn_lr], lr=args.lr_lr, momentum=0.5)\n",
    "    optimizer_img.zero_grad()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(args.device)\n",
    "    print('%s training begins'%get_time())\n",
    "\n",
    "    expert_dir = os.path.join(args.buffer_path, args.dataset)\n",
    "    if args.dataset == \"ImageNet\":\n",
    "        expert_dir = os.path.join(expert_dir, args.subset, str(args.res))\n",
    "    if args.dataset in [\"CIFAR10\", \"CIFAR100\"] and not args.zca:\n",
    "        expert_dir += \"_NO_ZCA\"\n",
    "    expert_dir = os.path.join(expert_dir, args.model)\n",
    "    print(\"Expert Dir: {}\".format(expert_dir))\n",
    "\n",
    "    if args.load_all:\n",
    "        buffer = []\n",
    "        n = 0\n",
    "        while os.path.exists(os.path.join(expert_dir, \"replay_buffer_{}.pt\".format(n))):\n",
    "            buffer = buffer + torch.load(os.path.join(expert_dir, \"replay_buffer_{}.pt\".format(n)))\n",
    "            n += 1\n",
    "        if n == 0:\n",
    "            raise AssertionError(\"No buffers detected at {}\".format(expert_dir))\n",
    "\n",
    "    else:\n",
    "        expert_files = []\n",
    "        n = 0\n",
    "        while os.path.exists(os.path.join(expert_dir, \"replay_buffer_{}.pt\".format(n))):\n",
    "            expert_files.append(os.path.join(expert_dir, \"replay_buffer_{}.pt\".format(n)))\n",
    "            n += 1\n",
    "        if n == 0:\n",
    "            raise AssertionError(\"No buffers detected at {}\".format(expert_dir))\n",
    "        file_idx = 0\n",
    "        expert_idx = 0\n",
    "        random.shuffle(expert_files)\n",
    "        if args.max_files is not None:\n",
    "            expert_files = expert_files[:args.max_files]\n",
    "        print(\"loading file {}\".format(expert_files[file_idx]))\n",
    "        buffer = torch.load(expert_files[file_idx])\n",
    "        if args.max_experts is not None:\n",
    "            buffer = buffer[:args.max_experts]\n",
    "        random.shuffle(buffer)\n",
    "\n",
    "    for it in range(0, args.Iteration+1):\n",
    "        save_this_it = False\n",
    "\n",
    "        # writer.add_scalar('Progress', it, it)\n",
    "        wandb.log({\"Progress\": it}, step=it)\n",
    "\n",
    "        student_net = get_network(args.model, channel, num_classes, im_size, dist=False).to(args.device)  # get a random model\n",
    "\n",
    "        student_net = ReparamModule(student_net)\n",
    "\n",
    "        if args.distributed:\n",
    "            student_net = torch.nn.DataParallel(student_net)\n",
    "\n",
    "        student_net.train()\n",
    "\n",
    "        num_params = sum([np.prod(p.size()) for p in (student_net.parameters())])\n",
    "\n",
    "        if args.load_all:\n",
    "            expert_trajectory = buffer[np.random.randint(0, len(buffer))]\n",
    "        else:\n",
    "            expert_trajectory = buffer[expert_idx]\n",
    "            expert_idx += 1\n",
    "            if expert_idx == len(buffer):\n",
    "                expert_idx = 0\n",
    "                file_idx += 1\n",
    "                if file_idx == len(expert_files):\n",
    "                    file_idx = 0\n",
    "                    random.shuffle(expert_files)\n",
    "                print(\"loading file {}\".format(expert_files[file_idx]))\n",
    "                if args.max_files != 1:\n",
    "                    del buffer\n",
    "                    buffer = torch.load(expert_files[file_idx])\n",
    "                if args.max_experts is not None:\n",
    "                    buffer = buffer[:args.max_experts]\n",
    "                random.shuffle(buffer)\n",
    "\n",
    "        start_epoch = np.random.randint(0, args.max_start_epoch)\n",
    "        starting_params = expert_trajectory[start_epoch]\n",
    "\n",
    "        target_params = expert_trajectory[start_epoch+args.expert_epochs]\n",
    "        target_params = torch.cat([p.data.to(args.device).reshape(-1) for p in target_params], 0)\n",
    "\n",
    "        student_params = [torch.cat([p.data.to(args.device).reshape(-1) for p in starting_params], 0).requires_grad_(True)]\n",
    "\n",
    "        starting_params = torch.cat([p.data.to(args.device).reshape(-1) for p in starting_params], 0)\n",
    "\n",
    "        syn_images = image_syn\n",
    "\n",
    "        y_hat = label_syn.to(args.device)\n",
    "\n",
    "        param_loss_list = []\n",
    "        param_dist_list = []\n",
    "        indices_chunks = []\n",
    "\n",
    "        for step in range(args.syn_steps):\n",
    "\n",
    "            if not indices_chunks:\n",
    "                indices = torch.randperm(len(syn_images))\n",
    "                indices_chunks = list(torch.split(indices, args.batch_syn))\n",
    "\n",
    "            these_indices = indices_chunks.pop()\n",
    "\n",
    "            x = syn_images[these_indices]\n",
    "            this_y = y_hat[these_indices]\n",
    "\n",
    "            if args.texture:\n",
    "                x = torch.cat([torch.stack([torch.roll(im, (torch.randint(im_size[0]*args.canvas_size, (1,)), torch.randint(im_size[1]*args.canvas_size, (1,))), (1,2))[:,:im_size[0],:im_size[1]] for im in x]) for _ in range(args.canvas_samples)])\n",
    "                this_y = torch.cat([this_y for _ in range(args.canvas_samples)])\n",
    "\n",
    "            if args.dsa and (not args.no_aug):\n",
    "                x = DiffAugment(x, args.dsa_strategy, param=args.dsa_param)\n",
    "\n",
    "            if args.distributed:\n",
    "                forward_params = student_params[-1].unsqueeze(0).expand(torch.cuda.device_count(), -1)\n",
    "            else:\n",
    "                forward_params = student_params[-1]\n",
    "            x = student_net(x, flat_param=forward_params)\n",
    "            ce_loss = criterion(x, this_y)\n",
    "\n",
    "            grad = torch.autograd.grad(ce_loss, student_params[-1], create_graph=True)[0]\n",
    "\n",
    "            student_params.append(student_params[-1] - syn_lr * grad)\n",
    "\n",
    "\n",
    "        param_loss = torch.tensor(0.0).to(args.device)\n",
    "        param_dist = torch.tensor(0.0).to(args.device)\n",
    "\n",
    "        param_loss += torch.nn.functional.mse_loss(student_params[-1], target_params, reduction=\"sum\")\n",
    "        param_dist += torch.nn.functional.mse_loss(starting_params, target_params, reduction=\"sum\")\n",
    "\n",
    "        param_loss_list.append(param_loss)\n",
    "        param_dist_list.append(param_dist)\n",
    "\n",
    "\n",
    "        param_loss /= num_params\n",
    "        param_dist /= num_params\n",
    "\n",
    "        param_loss /= param_dist\n",
    "\n",
    "        grand_loss = param_loss\n",
    "\n",
    "        optimizer_img.zero_grad()\n",
    "        optimizer_lr.zero_grad()\n",
    "\n",
    "        grand_loss.backward()\n",
    "\n",
    "        optimizer_img.step()\n",
    "        optimizer_lr.step()\n",
    "\n",
    "        wandb.log({\"Grand_Loss\": grand_loss.detach().cpu(),\n",
    "                   \"Start_Epoch\": start_epoch})\n",
    "\n",
    "        for _ in student_params:\n",
    "            del _\n",
    "\n",
    "        if it%10 == 0:\n",
    "            print('%s iter = %04d, loss = %.4f' % (get_time(), it, grand_loss.item()))\n",
    "            \n",
    "        ''' Evaluate synthetic data '''\n",
    "        if it == eval_it_pool[-1]:\n",
    "#         if it in eval_it_pool:     \n",
    "            print('-------------------------\\nEvaluation\\nmodel_train = %s, model_eval = %s, iteration = %d'%(args.model, args.model, it))\n",
    "            print('\\n==================== Final Results ====================\\n')\n",
    "            net_eval = get_network(args.model, channel, num_classes, im_size).to(args.device) # get a random model\n",
    "\n",
    "            eval_labs = label_syn\n",
    "            with torch.no_grad():\n",
    "                image_save = image_syn\n",
    "            image_syn_eval, label_syn_eval = copy.deepcopy(image_save.detach()), copy.deepcopy(eval_labs.detach()) # avoid any unaware modification\n",
    "\n",
    "            args.lr_net = syn_lr.item()\n",
    "            _, acc_train, acc_test = evaluate_synset(net_eval, image_syn_eval, label_syn_eval, testloader, args, texture=args.texture)\n",
    "            print('After {} iterations, the model test accuracy on synthetic data is {}%'.format(it, acc_test*100))\n",
    "\n",
    "        if it in eval_it_pool or save_this_it:\n",
    "            with torch.no_grad():\n",
    "                image_save = image_syn.cuda()\n",
    "\n",
    "                save_dir = os.path.join(\".\", \"CIFAR10result\")\n",
    "\n",
    "                if not os.path.exists(save_dir):\n",
    "                    os.makedirs(save_dir)\n",
    "                    \n",
    "                if it in eval_it_pool:\n",
    "                    save_name = os.path.join(save_dir, 'images_{}.png'.format(it))\n",
    "                    image_syn_vis = copy.deepcopy(image_save.detach().cpu())\n",
    "                    for ch in range(channel):\n",
    "                        image_syn_vis[:, ch] = image_syn_vis[:, ch]  * std_orig[ch] + mean_orig[ch]\n",
    "                    image_syn_vis[image_syn_vis<0] = 0.0\n",
    "                    image_syn_vis[image_syn_vis>1] = 1.0\n",
    "                    save_image(image_syn_vis, save_name, nrow=args.ipc) # Trying normalize = True/False may get better visual effects.\n",
    "\n",
    "                if it == eval_it_pool[-1]:\n",
    "                    torch.save(image_save.cpu(), os.path.join(save_dir, \"images_{}.pt\".format(it)))\n",
    "                    torch.save(label_syn.cpu(), os.path.join(save_dir, \"labels_{}.pt\".format(it)))\n",
    "\n",
    "                if save_this_it:\n",
    "                    torch.save(image_save.cpu(), os.path.join(save_dir, \"images_best.pt\".format(it)))\n",
    "                    torch.save(label_syn.cpu(), os.path.join(save_dir, \"labels_best.pt\".format(it)))\n",
    "\n",
    "                wandb.log({\"Pixels\": wandb.Histogram(torch.nan_to_num(image_syn.detach().cpu()))}, step=it)\n",
    "\n",
    "                if args.ipc < 50 or args.force_save:\n",
    "                    upsampled = image_save\n",
    "                    if args.dataset != \"ImageNet\":\n",
    "                        upsampled = torch.repeat_interleave(upsampled, repeats=4, dim=2)\n",
    "                        upsampled = torch.repeat_interleave(upsampled, repeats=4, dim=3)\n",
    "                    grid = torchvision.utils.make_grid(upsampled, nrow=10, normalize=True, scale_each=True)\n",
    "                    wandb.log({\"Synthetic_Images\": wandb.Image(torch.nan_to_num(grid.detach().cpu()))}, step=it)\n",
    "                    wandb.log({'Synthetic_Pixels': wandb.Histogram(torch.nan_to_num(image_save.detach().cpu()))}, step=it)\n",
    "\n",
    "                    for clip_val in [2.5]:\n",
    "                        std = torch.std(image_save)\n",
    "                        mean = torch.mean(image_save)\n",
    "                        upsampled = torch.clip(image_save, min=mean-clip_val*std, max=mean+clip_val*std)\n",
    "                        if args.dataset != \"ImageNet\":\n",
    "                            upsampled = torch.repeat_interleave(upsampled, repeats=4, dim=2)\n",
    "                            upsampled = torch.repeat_interleave(upsampled, repeats=4, dim=3)\n",
    "                        grid = torchvision.utils.make_grid(upsampled, nrow=10, normalize=True, scale_each=True)\n",
    "                        wandb.log({\"Clipped_Synthetic_Images/std_{}\".format(clip_val): wandb.Image(torch.nan_to_num(grid.detach().cpu()))}, step=it)\n",
    "\n",
    "                    if args.zca:\n",
    "                        image_save = image_save.to(args.device)\n",
    "                        image_save = args.zca_trans.inverse_transform(image_save)\n",
    "                        image_save.cpu()\n",
    "\n",
    "                        torch.save(image_save.cpu(), os.path.join(save_dir, \"images_zca_{}.pt\".format(it)))\n",
    "\n",
    "                        upsampled = image_save\n",
    "                        if args.dataset != \"ImageNet\":\n",
    "                            upsampled = torch.repeat_interleave(upsampled, repeats=4, dim=2)\n",
    "                            upsampled = torch.repeat_interleave(upsampled, repeats=4, dim=3)\n",
    "                        grid = torchvision.utils.make_grid(upsampled, nrow=10, normalize=True, scale_each=True)\n",
    "                        wandb.log({\"Reconstructed_Images\": wandb.Image(torch.nan_to_num(grid.detach().cpu()))}, step=it)\n",
    "                        wandb.log({'Reconstructed_Pixels': wandb.Histogram(torch.nan_to_num(image_save.detach().cpu()))}, step=it)\n",
    "\n",
    "                        for clip_val in [2.5]:\n",
    "                            std = torch.std(image_save)\n",
    "                            mean = torch.mean(image_save)\n",
    "                            upsampled = torch.clip(image_save, min=mean - clip_val * std, max=mean + clip_val * std)\n",
    "                            if args.dataset != \"ImageNet\":\n",
    "                                upsampled = torch.repeat_interleave(upsampled, repeats=4, dim=2)\n",
    "                                upsampled = torch.repeat_interleave(upsampled, repeats=4, dim=3)\n",
    "                            grid = torchvision.utils.make_grid(upsampled, nrow=10, normalize=True, scale_each=True)\n",
    "                            wandb.log({\"Clipped_Reconstructed_Images/std_{}\".format(clip_val): wandb.Image(\n",
    "                                torch.nan_to_num(grid.detach().cpu()))}, step=it)\n",
    "\n",
    "        wandb.log({\"Synthetic_LR\": syn_lr.detach().cpu()}, step=it)\n",
    "        \n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "class arguments():\n",
    "    def __init__(self,): \n",
    "        self.dataset = 'CIFAR10'\n",
    "        self.subset = 'imagenette'\n",
    "        self.model = 'ConvNet'\n",
    "        self.lr_img = 1000\n",
    "        self.lr_lr = 1e-05\n",
    "        self.lr_teacher = 0.01\n",
    "        self.lr_init = 0.01 \n",
    "        self.batch_real = 256\n",
    "        self.batch_train = 256\n",
    "        self.batch_syn = None\n",
    "        self.pix_init = 'real'\n",
    "        self.dsa = 'False'\n",
    "        self.dsa_strategy = 'color_crop_cutout_flip_scale_rotate'\n",
    "        self.data_path = 'CIFAR10data'\n",
    "        self.buffer_path = './CIFAR10buffers'\n",
    "        self.expert_epochs = 3\n",
    "        self.syn_steps = 20\n",
    "        self.max_start_epoch = 25\n",
    "        self.load_all = False\n",
    "        self.no_aug = False\n",
    "        self.zca = False\n",
    "        self.texture = False\n",
    "        self.canvas_size = 2\n",
    "        self.canvas_samples = 1\n",
    "        self.max_files = None\n",
    "        self.max_experts = None\n",
    "        self.force_save = False\n",
    "        self.ipc = 10\n",
    "        self.eval_mode = 'S'\n",
    "        self.num_eval = 5\n",
    "        self.eval_it = 100\n",
    "        self.epoch_eval_train = 1000\n",
    "        self.Iteration = 2000\n",
    "        \n",
    "\n",
    "args = arguments()\n",
    "\n",
    "main(args)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4b4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
