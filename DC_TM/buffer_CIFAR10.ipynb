{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28296f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Hyper-parameters: \n",
      " {'dataset': 'CIFAR10', 'subset': 'imagenette', 'model': 'ConvNet', 'num_experts': 10, 'lr_teacher': 0.01, 'batch_real': 256, 'batch_train': 256, 'dsa': False, 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': 'CIFAR10data', 'buffer_path': './CIFAR10buffers', 'train_epochs': 30, 'zca': False, 'decay': False, 'mom': 0, 'l2': 0, 'save_interval': 5, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x0000029AB440F3A0>}\n",
      "BUILDING DATASET\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 50000/50000 [00:08<00:00, 5569.16it/s]\n",
      "50000it [00:00, 16134420.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class c = 0: 5000 real images\n",
      "class c = 1: 5000 real images\n",
      "class c = 2: 5000 real images\n",
      "class c = 3: 5000 real images\n",
      "class c = 4: 5000 real images\n",
      "class c = 5: 5000 real images\n",
      "class c = 6: 5000 real images\n",
      "class c = 7: 5000 real images\n",
      "class c = 8: 5000 real images\n",
      "class c = 9: 5000 real images\n",
      "real images channel 0, mean = -0.0000, std = 1.2211\n",
      "real images channel 1, mean = -0.0002, std = 1.2211\n",
      "real images channel 2, mean = 0.0002, std = 1.3014\n",
      "DC augmentation parameters: \n",
      " {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'crop_scale_rotate'}\n",
      "Itr: 0\tEpoch: 0\tTrain Acc: 0.34928\tTest Acc: 0.4378\n",
      "Itr: 0\tEpoch: 1\tTrain Acc: 0.45586\tTest Acc: 0.4968\n",
      "Itr: 0\tEpoch: 2\tTrain Acc: 0.50108\tTest Acc: 0.5337\n",
      "Itr: 0\tEpoch: 3\tTrain Acc: 0.53628\tTest Acc: 0.5639\n",
      "Itr: 0\tEpoch: 4\tTrain Acc: 0.55692\tTest Acc: 0.5706\n",
      "Itr: 0\tEpoch: 5\tTrain Acc: 0.57772\tTest Acc: 0.5999\n",
      "Itr: 0\tEpoch: 6\tTrain Acc: 0.59556\tTest Acc: 0.6139\n",
      "Itr: 0\tEpoch: 7\tTrain Acc: 0.60658\tTest Acc: 0.6247\n",
      "Itr: 0\tEpoch: 8\tTrain Acc: 0.62152\tTest Acc: 0.6437\n",
      "Itr: 0\tEpoch: 9\tTrain Acc: 0.63024\tTest Acc: 0.6473\n",
      "Itr: 0\tEpoch: 10\tTrain Acc: 0.63786\tTest Acc: 0.6686\n",
      "Itr: 0\tEpoch: 11\tTrain Acc: 0.65244\tTest Acc: 0.65\n",
      "Itr: 0\tEpoch: 12\tTrain Acc: 0.65672\tTest Acc: 0.6841\n",
      "Itr: 0\tEpoch: 13\tTrain Acc: 0.6669\tTest Acc: 0.6232\n",
      "Itr: 0\tEpoch: 14\tTrain Acc: 0.67268\tTest Acc: 0.6695\n",
      "Itr: 0\tEpoch: 15\tTrain Acc: 0.67966\tTest Acc: 0.6877\n",
      "Itr: 0\tEpoch: 16\tTrain Acc: 0.6834\tTest Acc: 0.6977\n",
      "Itr: 0\tEpoch: 17\tTrain Acc: 0.68944\tTest Acc: 0.6828\n",
      "Itr: 0\tEpoch: 18\tTrain Acc: 0.69236\tTest Acc: 0.7025\n",
      "Itr: 0\tEpoch: 19\tTrain Acc: 0.7014\tTest Acc: 0.6958\n",
      "Itr: 0\tEpoch: 20\tTrain Acc: 0.70326\tTest Acc: 0.7062\n",
      "Itr: 0\tEpoch: 21\tTrain Acc: 0.70812\tTest Acc: 0.6964\n",
      "Itr: 0\tEpoch: 22\tTrain Acc: 0.71438\tTest Acc: 0.7084\n",
      "Itr: 0\tEpoch: 23\tTrain Acc: 0.71588\tTest Acc: 0.7126\n",
      "Itr: 0\tEpoch: 24\tTrain Acc: 0.72244\tTest Acc: 0.6971\n",
      "Itr: 0\tEpoch: 25\tTrain Acc: 0.7258\tTest Acc: 0.6988\n",
      "Itr: 0\tEpoch: 26\tTrain Acc: 0.73106\tTest Acc: 0.7229\n",
      "Itr: 0\tEpoch: 27\tTrain Acc: 0.73202\tTest Acc: 0.7269\n",
      "Itr: 0\tEpoch: 28\tTrain Acc: 0.73664\tTest Acc: 0.7089\n",
      "Itr: 0\tEpoch: 29\tTrain Acc: 0.73768\tTest Acc: 0.7187\n",
      "Itr: 1\tEpoch: 0\tTrain Acc: 0.3489\tTest Acc: 0.4356\n",
      "Itr: 1\tEpoch: 1\tTrain Acc: 0.45438\tTest Acc: 0.5031\n",
      "Itr: 1\tEpoch: 2\tTrain Acc: 0.50138\tTest Acc: 0.5399\n",
      "Itr: 1\tEpoch: 3\tTrain Acc: 0.5292\tTest Acc: 0.5698\n",
      "Itr: 1\tEpoch: 4\tTrain Acc: 0.55762\tTest Acc: 0.5824\n",
      "Itr: 1\tEpoch: 5\tTrain Acc: 0.57598\tTest Acc: 0.6033\n",
      "Itr: 1\tEpoch: 6\tTrain Acc: 0.59278\tTest Acc: 0.5983\n",
      "Itr: 1\tEpoch: 7\tTrain Acc: 0.61032\tTest Acc: 0.6308\n",
      "Itr: 1\tEpoch: 8\tTrain Acc: 0.62016\tTest Acc: 0.6426\n",
      "Itr: 1\tEpoch: 9\tTrain Acc: 0.6306\tTest Acc: 0.6619\n",
      "Itr: 1\tEpoch: 10\tTrain Acc: 0.64024\tTest Acc: 0.6651\n",
      "Itr: 1\tEpoch: 11\tTrain Acc: 0.64548\tTest Acc: 0.6744\n",
      "Itr: 1\tEpoch: 12\tTrain Acc: 0.6541\tTest Acc: 0.6638\n",
      "Itr: 1\tEpoch: 13\tTrain Acc: 0.6639\tTest Acc: 0.6653\n",
      "Itr: 1\tEpoch: 14\tTrain Acc: 0.66748\tTest Acc: 0.6661\n",
      "Itr: 1\tEpoch: 15\tTrain Acc: 0.67592\tTest Acc: 0.6321\n",
      "Itr: 1\tEpoch: 16\tTrain Acc: 0.68186\tTest Acc: 0.6924\n",
      "Itr: 1\tEpoch: 17\tTrain Acc: 0.68738\tTest Acc: 0.6902\n",
      "Itr: 1\tEpoch: 18\tTrain Acc: 0.69018\tTest Acc: 0.7013\n",
      "Itr: 1\tEpoch: 19\tTrain Acc: 0.69608\tTest Acc: 0.6987\n",
      "Itr: 1\tEpoch: 20\tTrain Acc: 0.69968\tTest Acc: 0.7158\n",
      "Itr: 1\tEpoch: 21\tTrain Acc: 0.7064\tTest Acc: 0.7166\n",
      "Itr: 1\tEpoch: 22\tTrain Acc: 0.71044\tTest Acc: 0.7164\n",
      "Itr: 1\tEpoch: 23\tTrain Acc: 0.71286\tTest Acc: 0.7062\n",
      "Itr: 1\tEpoch: 24\tTrain Acc: 0.72076\tTest Acc: 0.6909\n",
      "Itr: 1\tEpoch: 25\tTrain Acc: 0.72494\tTest Acc: 0.72\n",
      "Itr: 1\tEpoch: 26\tTrain Acc: 0.729\tTest Acc: 0.7267\n",
      "Itr: 1\tEpoch: 27\tTrain Acc: 0.72594\tTest Acc: 0.692\n",
      "Itr: 1\tEpoch: 28\tTrain Acc: 0.73316\tTest Acc: 0.7178\n",
      "Itr: 1\tEpoch: 29\tTrain Acc: 0.73538\tTest Acc: 0.7221\n",
      "Itr: 2\tEpoch: 0\tTrain Acc: 0.35132\tTest Acc: 0.4351\n",
      "Itr: 2\tEpoch: 1\tTrain Acc: 0.452\tTest Acc: 0.4918\n",
      "Itr: 2\tEpoch: 2\tTrain Acc: 0.50136\tTest Acc: 0.5448\n",
      "Itr: 2\tEpoch: 3\tTrain Acc: 0.53478\tTest Acc: 0.5693\n",
      "Itr: 2\tEpoch: 4\tTrain Acc: 0.56198\tTest Acc: 0.5684\n",
      "Itr: 2\tEpoch: 5\tTrain Acc: 0.5793\tTest Acc: 0.5953\n",
      "Itr: 2\tEpoch: 6\tTrain Acc: 0.59552\tTest Acc: 0.5983\n",
      "Itr: 2\tEpoch: 7\tTrain Acc: 0.60872\tTest Acc: 0.6221\n",
      "Itr: 2\tEpoch: 8\tTrain Acc: 0.62222\tTest Acc: 0.646\n",
      "Itr: 2\tEpoch: 9\tTrain Acc: 0.63058\tTest Acc: 0.6537\n",
      "Itr: 2\tEpoch: 10\tTrain Acc: 0.64198\tTest Acc: 0.6511\n",
      "Itr: 2\tEpoch: 11\tTrain Acc: 0.65146\tTest Acc: 0.6751\n",
      "Itr: 2\tEpoch: 12\tTrain Acc: 0.66002\tTest Acc: 0.6752\n",
      "Itr: 2\tEpoch: 13\tTrain Acc: 0.66398\tTest Acc: 0.6559\n",
      "Itr: 2\tEpoch: 14\tTrain Acc: 0.67116\tTest Acc: 0.6862\n",
      "Itr: 2\tEpoch: 15\tTrain Acc: 0.68028\tTest Acc: 0.6984\n",
      "Itr: 2\tEpoch: 16\tTrain Acc: 0.68404\tTest Acc: 0.7068\n",
      "Itr: 2\tEpoch: 17\tTrain Acc: 0.69262\tTest Acc: 0.6955\n",
      "Itr: 2\tEpoch: 18\tTrain Acc: 0.69562\tTest Acc: 0.7049\n",
      "Itr: 2\tEpoch: 19\tTrain Acc: 0.69968\tTest Acc: 0.686\n",
      "Itr: 2\tEpoch: 20\tTrain Acc: 0.7042\tTest Acc: 0.7162\n",
      "Itr: 2\tEpoch: 21\tTrain Acc: 0.70854\tTest Acc: 0.7066\n",
      "Itr: 2\tEpoch: 22\tTrain Acc: 0.71384\tTest Acc: 0.726\n",
      "Itr: 2\tEpoch: 23\tTrain Acc: 0.71766\tTest Acc: 0.7177\n",
      "Itr: 2\tEpoch: 24\tTrain Acc: 0.72272\tTest Acc: 0.7088\n",
      "Itr: 2\tEpoch: 25\tTrain Acc: 0.72852\tTest Acc: 0.7167\n",
      "Itr: 2\tEpoch: 26\tTrain Acc: 0.72872\tTest Acc: 0.7335\n",
      "Itr: 2\tEpoch: 27\tTrain Acc: 0.73538\tTest Acc: 0.7054\n",
      "Itr: 2\tEpoch: 28\tTrain Acc: 0.73528\tTest Acc: 0.7179\n",
      "Itr: 2\tEpoch: 29\tTrain Acc: 0.74082\tTest Acc: 0.7361\n",
      "Itr: 3\tEpoch: 0\tTrain Acc: 0.34508\tTest Acc: 0.4296\n",
      "Itr: 3\tEpoch: 1\tTrain Acc: 0.44562\tTest Acc: 0.4934\n",
      "Itr: 3\tEpoch: 2\tTrain Acc: 0.49478\tTest Acc: 0.5196\n",
      "Itr: 3\tEpoch: 3\tTrain Acc: 0.52888\tTest Acc: 0.5574\n",
      "Itr: 3\tEpoch: 4\tTrain Acc: 0.55066\tTest Acc: 0.5774\n",
      "Itr: 3\tEpoch: 5\tTrain Acc: 0.57108\tTest Acc: 0.5877\n",
      "Itr: 3\tEpoch: 6\tTrain Acc: 0.59024\tTest Acc: 0.6118\n",
      "Itr: 3\tEpoch: 7\tTrain Acc: 0.60258\tTest Acc: 0.6131\n",
      "Itr: 3\tEpoch: 8\tTrain Acc: 0.61724\tTest Acc: 0.6359\n",
      "Itr: 3\tEpoch: 9\tTrain Acc: 0.62714\tTest Acc: 0.6514\n",
      "Itr: 3\tEpoch: 10\tTrain Acc: 0.63868\tTest Acc: 0.6608\n",
      "Itr: 3\tEpoch: 11\tTrain Acc: 0.64502\tTest Acc: 0.6689\n",
      "Itr: 3\tEpoch: 12\tTrain Acc: 0.65618\tTest Acc: 0.6262\n",
      "Itr: 3\tEpoch: 13\tTrain Acc: 0.66374\tTest Acc: 0.6226\n",
      "Itr: 3\tEpoch: 14\tTrain Acc: 0.67244\tTest Acc: 0.6445\n",
      "Itr: 3\tEpoch: 15\tTrain Acc: 0.6764\tTest Acc: 0.6936\n",
      "Itr: 3\tEpoch: 16\tTrain Acc: 0.68446\tTest Acc: 0.6875\n",
      "Itr: 3\tEpoch: 17\tTrain Acc: 0.68618\tTest Acc: 0.7044\n",
      "Itr: 3\tEpoch: 18\tTrain Acc: 0.69406\tTest Acc: 0.6844\n",
      "Itr: 3\tEpoch: 19\tTrain Acc: 0.69938\tTest Acc: 0.7004\n",
      "Itr: 3\tEpoch: 20\tTrain Acc: 0.7049\tTest Acc: 0.6968\n",
      "Itr: 3\tEpoch: 21\tTrain Acc: 0.70976\tTest Acc: 0.711\n",
      "Itr: 3\tEpoch: 22\tTrain Acc: 0.71284\tTest Acc: 0.7188\n",
      "Itr: 3\tEpoch: 23\tTrain Acc: 0.71586\tTest Acc: 0.6727\n",
      "Itr: 3\tEpoch: 24\tTrain Acc: 0.7215\tTest Acc: 0.664\n",
      "Itr: 3\tEpoch: 25\tTrain Acc: 0.72172\tTest Acc: 0.6976\n",
      "Itr: 3\tEpoch: 26\tTrain Acc: 0.72512\tTest Acc: 0.7296\n",
      "Itr: 3\tEpoch: 27\tTrain Acc: 0.7334\tTest Acc: 0.7381\n",
      "Itr: 3\tEpoch: 28\tTrain Acc: 0.73522\tTest Acc: 0.7116\n",
      "Itr: 3\tEpoch: 29\tTrain Acc: 0.73494\tTest Acc: 0.7382\n",
      "Itr: 4\tEpoch: 0\tTrain Acc: 0.35434\tTest Acc: 0.4406\n",
      "Itr: 4\tEpoch: 1\tTrain Acc: 0.4593\tTest Acc: 0.5002\n",
      "Itr: 4\tEpoch: 2\tTrain Acc: 0.50432\tTest Acc: 0.5191\n",
      "Itr: 4\tEpoch: 3\tTrain Acc: 0.53592\tTest Acc: 0.5744\n",
      "Itr: 4\tEpoch: 4\tTrain Acc: 0.5608\tTest Acc: 0.5657\n",
      "Itr: 4\tEpoch: 5\tTrain Acc: 0.58364\tTest Acc: 0.5913\n",
      "Itr: 4\tEpoch: 6\tTrain Acc: 0.59888\tTest Acc: 0.6197\n",
      "Itr: 4\tEpoch: 7\tTrain Acc: 0.61052\tTest Acc: 0.6401\n",
      "Itr: 4\tEpoch: 8\tTrain Acc: 0.62482\tTest Acc: 0.6534\n",
      "Itr: 4\tEpoch: 9\tTrain Acc: 0.6343\tTest Acc: 0.6378\n",
      "Itr: 4\tEpoch: 10\tTrain Acc: 0.64164\tTest Acc: 0.6387\n",
      "Itr: 4\tEpoch: 11\tTrain Acc: 0.65118\tTest Acc: 0.6685\n",
      "Itr: 4\tEpoch: 12\tTrain Acc: 0.65938\tTest Acc: 0.6548\n",
      "Itr: 4\tEpoch: 13\tTrain Acc: 0.66916\tTest Acc: 0.6653\n",
      "Itr: 4\tEpoch: 14\tTrain Acc: 0.67182\tTest Acc: 0.6895\n",
      "Itr: 4\tEpoch: 15\tTrain Acc: 0.68062\tTest Acc: 0.6753\n",
      "Itr: 4\tEpoch: 16\tTrain Acc: 0.68562\tTest Acc: 0.6897\n",
      "Itr: 4\tEpoch: 17\tTrain Acc: 0.69348\tTest Acc: 0.6983\n",
      "Itr: 4\tEpoch: 18\tTrain Acc: 0.69498\tTest Acc: 0.7137\n",
      "Itr: 4\tEpoch: 19\tTrain Acc: 0.70122\tTest Acc: 0.7113\n",
      "Itr: 4\tEpoch: 20\tTrain Acc: 0.7062\tTest Acc: 0.6869\n",
      "Itr: 4\tEpoch: 21\tTrain Acc: 0.70808\tTest Acc: 0.6815\n",
      "Itr: 4\tEpoch: 22\tTrain Acc: 0.71578\tTest Acc: 0.6723\n",
      "Itr: 4\tEpoch: 23\tTrain Acc: 0.72056\tTest Acc: 0.7233\n",
      "Itr: 4\tEpoch: 24\tTrain Acc: 0.72208\tTest Acc: 0.7203\n",
      "Itr: 4\tEpoch: 25\tTrain Acc: 0.72556\tTest Acc: 0.7186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itr: 4\tEpoch: 26\tTrain Acc: 0.72956\tTest Acc: 0.7194\n",
      "Itr: 4\tEpoch: 27\tTrain Acc: 0.73288\tTest Acc: 0.7195\n",
      "Itr: 4\tEpoch: 28\tTrain Acc: 0.73508\tTest Acc: 0.7353\n",
      "Itr: 4\tEpoch: 29\tTrain Acc: 0.73796\tTest Acc: 0.7359\n",
      "Saving ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_0.pt\n",
      "Itr: 5\tEpoch: 0\tTrain Acc: 0.3458\tTest Acc: 0.4429\n",
      "Itr: 5\tEpoch: 1\tTrain Acc: 0.45272\tTest Acc: 0.4972\n",
      "Itr: 5\tEpoch: 2\tTrain Acc: 0.50056\tTest Acc: 0.5381\n",
      "Itr: 5\tEpoch: 3\tTrain Acc: 0.5351\tTest Acc: 0.5582\n",
      "Itr: 5\tEpoch: 4\tTrain Acc: 0.55664\tTest Acc: 0.5778\n",
      "Itr: 5\tEpoch: 5\tTrain Acc: 0.57694\tTest Acc: 0.5982\n",
      "Itr: 5\tEpoch: 6\tTrain Acc: 0.58854\tTest Acc: 0.6207\n",
      "Itr: 5\tEpoch: 7\tTrain Acc: 0.60716\tTest Acc: 0.6229\n",
      "Itr: 5\tEpoch: 8\tTrain Acc: 0.6201\tTest Acc: 0.6387\n",
      "Itr: 5\tEpoch: 9\tTrain Acc: 0.63158\tTest Acc: 0.6472\n",
      "Itr: 5\tEpoch: 10\tTrain Acc: 0.63952\tTest Acc: 0.6648\n",
      "Itr: 5\tEpoch: 11\tTrain Acc: 0.64748\tTest Acc: 0.6798\n",
      "Itr: 5\tEpoch: 12\tTrain Acc: 0.65634\tTest Acc: 0.6633\n",
      "Itr: 5\tEpoch: 13\tTrain Acc: 0.66298\tTest Acc: 0.6838\n",
      "Itr: 5\tEpoch: 14\tTrain Acc: 0.67066\tTest Acc: 0.6553\n",
      "Itr: 5\tEpoch: 15\tTrain Acc: 0.67828\tTest Acc: 0.6838\n",
      "Itr: 5\tEpoch: 16\tTrain Acc: 0.68212\tTest Acc: 0.6984\n",
      "Itr: 5\tEpoch: 17\tTrain Acc: 0.68794\tTest Acc: 0.684\n",
      "Itr: 5\tEpoch: 18\tTrain Acc: 0.69666\tTest Acc: 0.6845\n",
      "Itr: 5\tEpoch: 19\tTrain Acc: 0.69698\tTest Acc: 0.7011\n",
      "Itr: 5\tEpoch: 20\tTrain Acc: 0.70364\tTest Acc: 0.6368\n",
      "Itr: 5\tEpoch: 21\tTrain Acc: 0.70936\tTest Acc: 0.7182\n",
      "Itr: 5\tEpoch: 22\tTrain Acc: 0.71432\tTest Acc: 0.7108\n",
      "Itr: 5\tEpoch: 23\tTrain Acc: 0.71748\tTest Acc: 0.7202\n",
      "Itr: 5\tEpoch: 24\tTrain Acc: 0.72242\tTest Acc: 0.7124\n",
      "Itr: 5\tEpoch: 25\tTrain Acc: 0.7221\tTest Acc: 0.7104\n",
      "Itr: 5\tEpoch: 26\tTrain Acc: 0.72736\tTest Acc: 0.7342\n",
      "Itr: 5\tEpoch: 27\tTrain Acc: 0.72944\tTest Acc: 0.7336\n",
      "Itr: 5\tEpoch: 28\tTrain Acc: 0.73688\tTest Acc: 0.7176\n",
      "Itr: 5\tEpoch: 29\tTrain Acc: 0.73874\tTest Acc: 0.6948\n",
      "Itr: 6\tEpoch: 0\tTrain Acc: 0.34534\tTest Acc: 0.4296\n",
      "Itr: 6\tEpoch: 1\tTrain Acc: 0.44862\tTest Acc: 0.4898\n",
      "Itr: 6\tEpoch: 2\tTrain Acc: 0.4933\tTest Acc: 0.53\n",
      "Itr: 6\tEpoch: 3\tTrain Acc: 0.52326\tTest Acc: 0.5386\n",
      "Itr: 6\tEpoch: 4\tTrain Acc: 0.54914\tTest Acc: 0.5834\n",
      "Itr: 6\tEpoch: 5\tTrain Acc: 0.56742\tTest Acc: 0.5793\n",
      "Itr: 6\tEpoch: 6\tTrain Acc: 0.58376\tTest Acc: 0.6068\n",
      "Itr: 6\tEpoch: 7\tTrain Acc: 0.60018\tTest Acc: 0.6339\n",
      "Itr: 6\tEpoch: 8\tTrain Acc: 0.61\tTest Acc: 0.6457\n",
      "Itr: 6\tEpoch: 9\tTrain Acc: 0.6231\tTest Acc: 0.6483\n",
      "Itr: 6\tEpoch: 10\tTrain Acc: 0.6353\tTest Acc: 0.6406\n",
      "Itr: 6\tEpoch: 11\tTrain Acc: 0.64218\tTest Acc: 0.6555\n",
      "Itr: 6\tEpoch: 12\tTrain Acc: 0.65148\tTest Acc: 0.6556\n",
      "Itr: 6\tEpoch: 13\tTrain Acc: 0.65892\tTest Acc: 0.6685\n",
      "Itr: 6\tEpoch: 14\tTrain Acc: 0.66516\tTest Acc: 0.6794\n",
      "Itr: 6\tEpoch: 15\tTrain Acc: 0.673\tTest Acc: 0.6799\n",
      "Itr: 6\tEpoch: 16\tTrain Acc: 0.67756\tTest Acc: 0.6682\n",
      "Itr: 6\tEpoch: 17\tTrain Acc: 0.685\tTest Acc: 0.681\n",
      "Itr: 6\tEpoch: 18\tTrain Acc: 0.6874\tTest Acc: 0.6891\n",
      "Itr: 6\tEpoch: 19\tTrain Acc: 0.69466\tTest Acc: 0.685\n",
      "Itr: 6\tEpoch: 20\tTrain Acc: 0.6968\tTest Acc: 0.6939\n",
      "Itr: 6\tEpoch: 21\tTrain Acc: 0.70726\tTest Acc: 0.6978\n",
      "Itr: 6\tEpoch: 22\tTrain Acc: 0.70754\tTest Acc: 0.7125\n",
      "Itr: 6\tEpoch: 23\tTrain Acc: 0.70922\tTest Acc: 0.7152\n",
      "Itr: 6\tEpoch: 24\tTrain Acc: 0.71728\tTest Acc: 0.7178\n",
      "Itr: 6\tEpoch: 25\tTrain Acc: 0.7205\tTest Acc: 0.6907\n",
      "Itr: 6\tEpoch: 26\tTrain Acc: 0.72426\tTest Acc: 0.7235\n",
      "Itr: 6\tEpoch: 27\tTrain Acc: 0.72934\tTest Acc: 0.7318\n",
      "Itr: 6\tEpoch: 28\tTrain Acc: 0.73322\tTest Acc: 0.7397\n",
      "Itr: 6\tEpoch: 29\tTrain Acc: 0.73204\tTest Acc: 0.7348\n",
      "Itr: 7\tEpoch: 0\tTrain Acc: 0.34658\tTest Acc: 0.4382\n",
      "Itr: 7\tEpoch: 1\tTrain Acc: 0.4533\tTest Acc: 0.4994\n",
      "Itr: 7\tEpoch: 2\tTrain Acc: 0.49628\tTest Acc: 0.5405\n",
      "Itr: 7\tEpoch: 3\tTrain Acc: 0.5324\tTest Acc: 0.513\n",
      "Itr: 7\tEpoch: 4\tTrain Acc: 0.5597\tTest Acc: 0.5841\n",
      "Itr: 7\tEpoch: 5\tTrain Acc: 0.58016\tTest Acc: 0.5998\n",
      "Itr: 7\tEpoch: 6\tTrain Acc: 0.59548\tTest Acc: 0.6104\n",
      "Itr: 7\tEpoch: 7\tTrain Acc: 0.61086\tTest Acc: 0.6417\n",
      "Itr: 7\tEpoch: 8\tTrain Acc: 0.62256\tTest Acc: 0.6261\n",
      "Itr: 7\tEpoch: 9\tTrain Acc: 0.6306\tTest Acc: 0.6536\n",
      "Itr: 7\tEpoch: 10\tTrain Acc: 0.64374\tTest Acc: 0.6646\n",
      "Itr: 7\tEpoch: 11\tTrain Acc: 0.6521\tTest Acc: 0.6751\n",
      "Itr: 7\tEpoch: 12\tTrain Acc: 0.65874\tTest Acc: 0.6903\n",
      "Itr: 7\tEpoch: 13\tTrain Acc: 0.6633\tTest Acc: 0.6523\n",
      "Itr: 7\tEpoch: 14\tTrain Acc: 0.67402\tTest Acc: 0.6867\n",
      "Itr: 7\tEpoch: 15\tTrain Acc: 0.67864\tTest Acc: 0.6877\n",
      "Itr: 7\tEpoch: 16\tTrain Acc: 0.6856\tTest Acc: 0.6901\n",
      "Itr: 7\tEpoch: 17\tTrain Acc: 0.693\tTest Acc: 0.7014\n",
      "Itr: 7\tEpoch: 18\tTrain Acc: 0.69302\tTest Acc: 0.7093\n",
      "Itr: 7\tEpoch: 19\tTrain Acc: 0.70202\tTest Acc: 0.708\n",
      "Itr: 7\tEpoch: 20\tTrain Acc: 0.70486\tTest Acc: 0.7171\n",
      "Itr: 7\tEpoch: 21\tTrain Acc: 0.70808\tTest Acc: 0.7162\n",
      "Itr: 7\tEpoch: 22\tTrain Acc: 0.71318\tTest Acc: 0.6795\n",
      "Itr: 7\tEpoch: 23\tTrain Acc: 0.71632\tTest Acc: 0.7197\n",
      "Itr: 7\tEpoch: 24\tTrain Acc: 0.71962\tTest Acc: 0.6985\n",
      "Itr: 7\tEpoch: 25\tTrain Acc: 0.72506\tTest Acc: 0.7198\n",
      "Itr: 7\tEpoch: 26\tTrain Acc: 0.72888\tTest Acc: 0.7414\n",
      "Itr: 7\tEpoch: 27\tTrain Acc: 0.73202\tTest Acc: 0.7147\n",
      "Itr: 7\tEpoch: 28\tTrain Acc: 0.73578\tTest Acc: 0.7167\n",
      "Itr: 7\tEpoch: 29\tTrain Acc: 0.73914\tTest Acc: 0.7168\n",
      "Itr: 8\tEpoch: 0\tTrain Acc: 0.35\tTest Acc: 0.4338\n",
      "Itr: 8\tEpoch: 1\tTrain Acc: 0.45518\tTest Acc: 0.4892\n",
      "Itr: 8\tEpoch: 2\tTrain Acc: 0.49978\tTest Acc: 0.5333\n",
      "Itr: 8\tEpoch: 3\tTrain Acc: 0.53438\tTest Acc: 0.5545\n",
      "Itr: 8\tEpoch: 4\tTrain Acc: 0.55728\tTest Acc: 0.566\n",
      "Itr: 8\tEpoch: 5\tTrain Acc: 0.57438\tTest Acc: 0.6156\n",
      "Itr: 8\tEpoch: 6\tTrain Acc: 0.5917\tTest Acc: 0.6108\n",
      "Itr: 8\tEpoch: 7\tTrain Acc: 0.60662\tTest Acc: 0.6195\n",
      "Itr: 8\tEpoch: 8\tTrain Acc: 0.61608\tTest Acc: 0.6486\n",
      "Itr: 8\tEpoch: 9\tTrain Acc: 0.6316\tTest Acc: 0.6503\n",
      "Itr: 8\tEpoch: 10\tTrain Acc: 0.64038\tTest Acc: 0.6553\n",
      "Itr: 8\tEpoch: 11\tTrain Acc: 0.65042\tTest Acc: 0.6751\n",
      "Itr: 8\tEpoch: 12\tTrain Acc: 0.65922\tTest Acc: 0.6556\n",
      "Itr: 8\tEpoch: 13\tTrain Acc: 0.66344\tTest Acc: 0.6493\n",
      "Itr: 8\tEpoch: 14\tTrain Acc: 0.67136\tTest Acc: 0.6793\n",
      "Itr: 8\tEpoch: 15\tTrain Acc: 0.67798\tTest Acc: 0.6982\n",
      "Itr: 8\tEpoch: 16\tTrain Acc: 0.68612\tTest Acc: 0.6729\n",
      "Itr: 8\tEpoch: 17\tTrain Acc: 0.68874\tTest Acc: 0.6898\n",
      "Itr: 8\tEpoch: 18\tTrain Acc: 0.69354\tTest Acc: 0.6945\n",
      "Itr: 8\tEpoch: 19\tTrain Acc: 0.70122\tTest Acc: 0.7047\n",
      "Itr: 8\tEpoch: 20\tTrain Acc: 0.70808\tTest Acc: 0.708\n",
      "Itr: 8\tEpoch: 21\tTrain Acc: 0.71096\tTest Acc: 0.7126\n",
      "Itr: 8\tEpoch: 22\tTrain Acc: 0.71166\tTest Acc: 0.7178\n",
      "Itr: 8\tEpoch: 23\tTrain Acc: 0.71686\tTest Acc: 0.7229\n",
      "Itr: 8\tEpoch: 24\tTrain Acc: 0.72376\tTest Acc: 0.7108\n",
      "Itr: 8\tEpoch: 25\tTrain Acc: 0.72622\tTest Acc: 0.7303\n",
      "Itr: 8\tEpoch: 26\tTrain Acc: 0.7303\tTest Acc: 0.7027\n",
      "Itr: 8\tEpoch: 27\tTrain Acc: 0.73146\tTest Acc: 0.7361\n",
      "Itr: 8\tEpoch: 28\tTrain Acc: 0.73408\tTest Acc: 0.7245\n",
      "Itr: 8\tEpoch: 29\tTrain Acc: 0.73916\tTest Acc: 0.7283\n",
      "Itr: 9\tEpoch: 0\tTrain Acc: 0.35348\tTest Acc: 0.43\n",
      "Itr: 9\tEpoch: 1\tTrain Acc: 0.45972\tTest Acc: 0.5121\n",
      "Itr: 9\tEpoch: 2\tTrain Acc: 0.5048\tTest Acc: 0.5454\n",
      "Itr: 9\tEpoch: 3\tTrain Acc: 0.53542\tTest Acc: 0.5641\n",
      "Itr: 9\tEpoch: 4\tTrain Acc: 0.56104\tTest Acc: 0.5824\n",
      "Itr: 9\tEpoch: 5\tTrain Acc: 0.5802\tTest Acc: 0.6036\n",
      "Itr: 9\tEpoch: 6\tTrain Acc: 0.59528\tTest Acc: 0.6303\n",
      "Itr: 9\tEpoch: 7\tTrain Acc: 0.60906\tTest Acc: 0.6341\n",
      "Itr: 9\tEpoch: 8\tTrain Acc: 0.62202\tTest Acc: 0.6516\n",
      "Itr: 9\tEpoch: 9\tTrain Acc: 0.6293\tTest Acc: 0.6535\n",
      "Itr: 9\tEpoch: 10\tTrain Acc: 0.64224\tTest Acc: 0.666\n",
      "Itr: 9\tEpoch: 11\tTrain Acc: 0.6498\tTest Acc: 0.6747\n",
      "Itr: 9\tEpoch: 12\tTrain Acc: 0.66038\tTest Acc: 0.6639\n",
      "Itr: 9\tEpoch: 13\tTrain Acc: 0.66452\tTest Acc: 0.668\n",
      "Itr: 9\tEpoch: 14\tTrain Acc: 0.67422\tTest Acc: 0.6639\n",
      "Itr: 9\tEpoch: 15\tTrain Acc: 0.67752\tTest Acc: 0.6836\n",
      "Itr: 9\tEpoch: 16\tTrain Acc: 0.6827\tTest Acc: 0.7011\n",
      "Itr: 9\tEpoch: 17\tTrain Acc: 0.68966\tTest Acc: 0.681\n",
      "Itr: 9\tEpoch: 18\tTrain Acc: 0.69394\tTest Acc: 0.7\n",
      "Itr: 9\tEpoch: 19\tTrain Acc: 0.70006\tTest Acc: 0.7147\n",
      "Itr: 9\tEpoch: 20\tTrain Acc: 0.70634\tTest Acc: 0.6993\n",
      "Itr: 9\tEpoch: 21\tTrain Acc: 0.7106\tTest Acc: 0.7056\n",
      "Itr: 9\tEpoch: 22\tTrain Acc: 0.7124\tTest Acc: 0.7052\n",
      "Itr: 9\tEpoch: 23\tTrain Acc: 0.71862\tTest Acc: 0.7017\n",
      "Itr: 9\tEpoch: 24\tTrain Acc: 0.72328\tTest Acc: 0.7236\n",
      "Itr: 9\tEpoch: 25\tTrain Acc: 0.72738\tTest Acc: 0.7239\n",
      "Itr: 9\tEpoch: 26\tTrain Acc: 0.73064\tTest Acc: 0.7324\n",
      "Itr: 9\tEpoch: 27\tTrain Acc: 0.73326\tTest Acc: 0.6895\n",
      "Itr: 9\tEpoch: 28\tTrain Acc: 0.73608\tTest Acc: 0.7311\n",
      "Itr: 9\tEpoch: 29\tTrain Acc: 0.73934\tTest Acc: 0.7232\n",
      "Saving ./CIFAR10buffers\\CIFAR10_NO_ZCA\\ConvNet\\replay_buffer_1.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from utils import get_dataset, get_network, get_daparam, TensorDataset, epoch, ParamDiffAug\n",
    "import copy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    args.dsa = True if args.dsa == 'True' else False\n",
    "    args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    args.dsa_param = ParamDiffAug()\n",
    "\n",
    "    channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader, loader_train_dict, class_map, class_map_inv = get_dataset(args.dataset, args.data_path, args.batch_real, args.subset, args=args)\n",
    "\n",
    "    # print('\\n================== Exp %d ==================\\n '%exp)\n",
    "    print('Hyper-parameters: \\n', args.__dict__)\n",
    "\n",
    "    save_dir = os.path.join(args.buffer_path, args.dataset)\n",
    "    if args.dataset == \"ImageNet\":\n",
    "        save_dir = os.path.join(save_dir, args.subset, str(args.res))\n",
    "    if args.dataset in [\"CIFAR10\", \"CIFAR100\"] and not args.zca:\n",
    "        save_dir += \"_NO_ZCA\"\n",
    "    save_dir = os.path.join(save_dir, args.model)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "\n",
    "    ''' organize the real dataset '''\n",
    "    images_all = []\n",
    "    labels_all = []\n",
    "    indices_class = [[] for c in range(num_classes)]\n",
    "    print(\"BUILDING DATASET\")\n",
    "    for i in tqdm(range(len(dst_train))):\n",
    "        sample = dst_train[i]\n",
    "        images_all.append(torch.unsqueeze(sample[0], dim=0))\n",
    "        labels_all.append(class_map[torch.tensor(sample[1]).item()])\n",
    "\n",
    "    for i, lab in tqdm(enumerate(labels_all)):\n",
    "        indices_class[lab].append(i)\n",
    "    images_all = torch.cat(images_all, dim=0).to(\"cpu\")\n",
    "    labels_all = torch.tensor(labels_all, dtype=torch.long, device=\"cpu\")\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        print('class c = %d: %d real images'%(c, len(indices_class[c])))\n",
    "\n",
    "    for ch in range(channel):\n",
    "        print('real images channel %d, mean = %.4f, std = %.4f'%(ch, torch.mean(images_all[:, ch]), torch.std(images_all[:, ch])))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(args.device)\n",
    "\n",
    "    trajectories = []\n",
    "\n",
    "    dst_train = TensorDataset(copy.deepcopy(images_all.detach()), copy.deepcopy(labels_all.detach()))\n",
    "    trainloader = torch.utils.data.DataLoader(dst_train, batch_size=args.batch_train, shuffle=True, num_workers=0)\n",
    "\n",
    "    ''' set augmentation for whole-dataset training '''\n",
    "    args.dc_aug_param = get_daparam(args.dataset, args.model, args.model, None)\n",
    "    args.dc_aug_param['strategy'] = 'crop_scale_rotate'  # for whole-dataset training\n",
    "    print('DC augmentation parameters: \\n', args.dc_aug_param)\n",
    "\n",
    "    for it in range(0, args.num_experts):\n",
    "\n",
    "        ''' Train synthetic data '''\n",
    "        teacher_net = get_network(args.model, channel, num_classes, im_size).to(args.device) # get a random model\n",
    "        teacher_net.train()\n",
    "        lr = args.lr_teacher\n",
    "        teacher_optim = torch.optim.SGD(teacher_net.parameters(), lr=lr, momentum=args.mom, weight_decay=args.l2)  # optimizer_img for synthetic data\n",
    "        teacher_optim.zero_grad()\n",
    "\n",
    "        timestamps = []\n",
    "\n",
    "        timestamps.append([p.detach().cpu() for p in teacher_net.parameters()])\n",
    "\n",
    "        lr_schedule = [args.train_epochs // 2 + 1]\n",
    "\n",
    "        for e in range(args.train_epochs):\n",
    "\n",
    "            train_loss, train_acc = epoch(\"train\", dataloader=trainloader, net=teacher_net, optimizer=teacher_optim,\n",
    "                                        criterion=criterion, args=args, aug=True)\n",
    "\n",
    "            test_loss, test_acc = epoch(\"test\", dataloader=testloader, net=teacher_net, optimizer=None,\n",
    "                                        criterion=criterion, args=args, aug=False)\n",
    "\n",
    "            print(\"Itr: {}\\tEpoch: {}\\tTrain Acc: {}\\tTest Acc: {}\".format(it, e, train_acc, test_acc))\n",
    "\n",
    "            timestamps.append([p.detach().cpu() for p in teacher_net.parameters()])\n",
    "\n",
    "            if e in lr_schedule and args.decay:\n",
    "                lr *= 0.1\n",
    "                teacher_optim = torch.optim.SGD(teacher_net.parameters(), lr=lr, momentum=args.mom, weight_decay=args.l2)\n",
    "                teacher_optim.zero_grad()\n",
    "\n",
    "        trajectories.append(timestamps)\n",
    "\n",
    "        if len(trajectories) == args.save_interval:\n",
    "            n = 0\n",
    "            while os.path.exists(os.path.join(save_dir, \"replay_buffer_{}.pt\".format(n))):\n",
    "                n += 1\n",
    "            print(\"Saving {}\".format(os.path.join(save_dir, \"replay_buffer_{}.pt\".format(n))))\n",
    "            torch.save(trajectories, os.path.join(save_dir, \"replay_buffer_{}.pt\".format(n)))\n",
    "            trajectories = []\n",
    "\n",
    "\n",
    "class arguments():\n",
    "    def __init__(self,): \n",
    "        self.dataset = 'CIFAR10'\n",
    "        self.subset = 'imagenette'\n",
    "        self.model = 'ConvNet'\n",
    "        self.num_experts = 10\n",
    "        self.lr_teacher = 0.01\n",
    "        self.batch_real = 256\n",
    "        self.batch_train = 256\n",
    "        self.dsa = 'False'\n",
    "        self.dsa_strategy = 'color_crop_cutout_flip_scale_rotate'\n",
    "        self.data_path = 'CIFAR10data'\n",
    "        self.buffer_path = './CIFAR10buffers'\n",
    "        self.train_epochs = 30\n",
    "        self.zca = False\n",
    "        self.decay = False\n",
    "        self.mom = 0\n",
    "        self.l2 = 0\n",
    "        self.save_interval = 5\n",
    "\n",
    "args = arguments()\n",
    "main(args)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f384fc57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
