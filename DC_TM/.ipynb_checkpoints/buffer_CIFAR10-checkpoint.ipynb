{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28296f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Hyper-parameters: \n",
      " {'dataset': 'CIFAR10', 'subset': 'imagenette', 'model': 'ConvNet', 'num_experts': 10, 'lr_teacher': 0.01, 'batch_real': 256, 'batch_train': 256, 'dsa': False, 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': 'CIFAR10data', 'buffer_path': './CIFAR10buffers', 'train_epochs': 30, 'zca': False, 'decay': False, 'mom': 0, 'l2': 0, 'save_interval': 5, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x0000029AB440F3A0>}\n",
      "BUILDING DATASET\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 50000/50000 [00:08<00:00, 5569.16it/s]\n",
      "50000it [00:00, 16134420.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class c = 0: 5000 real images\n",
      "class c = 1: 5000 real images\n",
      "class c = 2: 5000 real images\n",
      "class c = 3: 5000 real images\n",
      "class c = 4: 5000 real images\n",
      "class c = 5: 5000 real images\n",
      "class c = 6: 5000 real images\n",
      "class c = 7: 5000 real images\n",
      "class c = 8: 5000 real images\n",
      "class c = 9: 5000 real images\n",
      "real images channel 0, mean = -0.0000, std = 1.2211\n",
      "real images channel 1, mean = -0.0002, std = 1.2211\n",
      "real images channel 2, mean = 0.0002, std = 1.3014\n",
      "DC augmentation parameters: \n",
      " {'crop': 4, 'scale': 0.2, 'rotate': 45, 'noise': 0.001, 'strategy': 'crop_scale_rotate'}\n",
      "Itr: 0\tEpoch: 0\tTrain Acc: 0.34928\tTest Acc: 0.4378\n",
      "Itr: 0\tEpoch: 1\tTrain Acc: 0.45586\tTest Acc: 0.4968\n",
      "Itr: 0\tEpoch: 2\tTrain Acc: 0.50108\tTest Acc: 0.5337\n",
      "Itr: 0\tEpoch: 3\tTrain Acc: 0.53628\tTest Acc: 0.5639\n",
      "Itr: 0\tEpoch: 4\tTrain Acc: 0.55692\tTest Acc: 0.5706\n",
      "Itr: 0\tEpoch: 5\tTrain Acc: 0.57772\tTest Acc: 0.5999\n",
      "Itr: 0\tEpoch: 6\tTrain Acc: 0.59556\tTest Acc: 0.6139\n",
      "Itr: 0\tEpoch: 7\tTrain Acc: 0.60658\tTest Acc: 0.6247\n",
      "Itr: 0\tEpoch: 8\tTrain Acc: 0.62152\tTest Acc: 0.6437\n",
      "Itr: 0\tEpoch: 9\tTrain Acc: 0.63024\tTest Acc: 0.6473\n",
      "Itr: 0\tEpoch: 10\tTrain Acc: 0.63786\tTest Acc: 0.6686\n",
      "Itr: 0\tEpoch: 11\tTrain Acc: 0.65244\tTest Acc: 0.65\n",
      "Itr: 0\tEpoch: 12\tTrain Acc: 0.65672\tTest Acc: 0.6841\n",
      "Itr: 0\tEpoch: 13\tTrain Acc: 0.6669\tTest Acc: 0.6232\n",
      "Itr: 0\tEpoch: 14\tTrain Acc: 0.67268\tTest Acc: 0.6695\n",
      "Itr: 0\tEpoch: 15\tTrain Acc: 0.67966\tTest Acc: 0.6877\n",
      "Itr: 0\tEpoch: 16\tTrain Acc: 0.6834\tTest Acc: 0.6977\n",
      "Itr: 0\tEpoch: 17\tTrain Acc: 0.68944\tTest Acc: 0.6828\n",
      "Itr: 0\tEpoch: 18\tTrain Acc: 0.69236\tTest Acc: 0.7025\n",
      "Itr: 0\tEpoch: 19\tTrain Acc: 0.7014\tTest Acc: 0.6958\n",
      "Itr: 0\tEpoch: 20\tTrain Acc: 0.70326\tTest Acc: 0.7062\n",
      "Itr: 0\tEpoch: 21\tTrain Acc: 0.70812\tTest Acc: 0.6964\n",
      "Itr: 0\tEpoch: 22\tTrain Acc: 0.71438\tTest Acc: 0.7084\n",
      "Itr: 0\tEpoch: 23\tTrain Acc: 0.71588\tTest Acc: 0.7126\n",
      "Itr: 0\tEpoch: 24\tTrain Acc: 0.72244\tTest Acc: 0.6971\n",
      "Itr: 0\tEpoch: 25\tTrain Acc: 0.7258\tTest Acc: 0.6988\n",
      "Itr: 0\tEpoch: 26\tTrain Acc: 0.73106\tTest Acc: 0.7229\n",
      "Itr: 0\tEpoch: 27\tTrain Acc: 0.73202\tTest Acc: 0.7269\n",
      "Itr: 0\tEpoch: 28\tTrain Acc: 0.73664\tTest Acc: 0.7089\n",
      "Itr: 0\tEpoch: 29\tTrain Acc: 0.73768\tTest Acc: 0.7187\n",
      "Itr: 1\tEpoch: 0\tTrain Acc: 0.3489\tTest Acc: 0.4356\n",
      "Itr: 1\tEpoch: 1\tTrain Acc: 0.45438\tTest Acc: 0.5031\n",
      "Itr: 1\tEpoch: 2\tTrain Acc: 0.50138\tTest Acc: 0.5399\n",
      "Itr: 1\tEpoch: 3\tTrain Acc: 0.5292\tTest Acc: 0.5698\n",
      "Itr: 1\tEpoch: 4\tTrain Acc: 0.55762\tTest Acc: 0.5824\n",
      "Itr: 1\tEpoch: 5\tTrain Acc: 0.57598\tTest Acc: 0.6033\n",
      "Itr: 1\tEpoch: 6\tTrain Acc: 0.59278\tTest Acc: 0.5983\n",
      "Itr: 1\tEpoch: 7\tTrain Acc: 0.61032\tTest Acc: 0.6308\n",
      "Itr: 1\tEpoch: 8\tTrain Acc: 0.62016\tTest Acc: 0.6426\n",
      "Itr: 1\tEpoch: 9\tTrain Acc: 0.6306\tTest Acc: 0.6619\n",
      "Itr: 1\tEpoch: 10\tTrain Acc: 0.64024\tTest Acc: 0.6651\n",
      "Itr: 1\tEpoch: 11\tTrain Acc: 0.64548\tTest Acc: 0.6744\n",
      "Itr: 1\tEpoch: 12\tTrain Acc: 0.6541\tTest Acc: 0.6638\n",
      "Itr: 1\tEpoch: 13\tTrain Acc: 0.6639\tTest Acc: 0.6653\n",
      "Itr: 1\tEpoch: 14\tTrain Acc: 0.66748\tTest Acc: 0.6661\n",
      "Itr: 1\tEpoch: 15\tTrain Acc: 0.67592\tTest Acc: 0.6321\n",
      "Itr: 1\tEpoch: 16\tTrain Acc: 0.68186\tTest Acc: 0.6924\n",
      "Itr: 1\tEpoch: 17\tTrain Acc: 0.68738\tTest Acc: 0.6902\n",
      "Itr: 1\tEpoch: 18\tTrain Acc: 0.69018\tTest Acc: 0.7013\n",
      "Itr: 1\tEpoch: 19\tTrain Acc: 0.69608\tTest Acc: 0.6987\n",
      "Itr: 1\tEpoch: 20\tTrain Acc: 0.69968\tTest Acc: 0.7158\n",
      "Itr: 1\tEpoch: 21\tTrain Acc: 0.7064\tTest Acc: 0.7166\n",
      "Itr: 1\tEpoch: 22\tTrain Acc: 0.71044\tTest Acc: 0.7164\n",
      "Itr: 1\tEpoch: 23\tTrain Acc: 0.71286\tTest Acc: 0.7062\n",
      "Itr: 1\tEpoch: 24\tTrain Acc: 0.72076\tTest Acc: 0.6909\n",
      "Itr: 1\tEpoch: 25\tTrain Acc: 0.72494\tTest Acc: 0.72\n",
      "Itr: 1\tEpoch: 26\tTrain Acc: 0.729\tTest Acc: 0.7267\n",
      "Itr: 1\tEpoch: 27\tTrain Acc: 0.72594\tTest Acc: 0.692\n",
      "Itr: 1\tEpoch: 28\tTrain Acc: 0.73316\tTest Acc: 0.7178\n",
      "Itr: 1\tEpoch: 29\tTrain Acc: 0.73538\tTest Acc: 0.7221\n",
      "Itr: 2\tEpoch: 0\tTrain Acc: 0.35132\tTest Acc: 0.4351\n",
      "Itr: 2\tEpoch: 1\tTrain Acc: 0.452\tTest Acc: 0.4918\n",
      "Itr: 2\tEpoch: 2\tTrain Acc: 0.50136\tTest Acc: 0.5448\n",
      "Itr: 2\tEpoch: 3\tTrain Acc: 0.53478\tTest Acc: 0.5693\n",
      "Itr: 2\tEpoch: 4\tTrain Acc: 0.56198\tTest Acc: 0.5684\n",
      "Itr: 2\tEpoch: 5\tTrain Acc: 0.5793\tTest Acc: 0.5953\n",
      "Itr: 2\tEpoch: 6\tTrain Acc: 0.59552\tTest Acc: 0.5983\n",
      "Itr: 2\tEpoch: 7\tTrain Acc: 0.60872\tTest Acc: 0.6221\n",
      "Itr: 2\tEpoch: 8\tTrain Acc: 0.62222\tTest Acc: 0.646\n",
      "Itr: 2\tEpoch: 9\tTrain Acc: 0.63058\tTest Acc: 0.6537\n",
      "Itr: 2\tEpoch: 10\tTrain Acc: 0.64198\tTest Acc: 0.6511\n",
      "Itr: 2\tEpoch: 11\tTrain Acc: 0.65146\tTest Acc: 0.6751\n",
      "Itr: 2\tEpoch: 12\tTrain Acc: 0.66002\tTest Acc: 0.6752\n",
      "Itr: 2\tEpoch: 13\tTrain Acc: 0.66398\tTest Acc: 0.6559\n",
      "Itr: 2\tEpoch: 14\tTrain Acc: 0.67116\tTest Acc: 0.6862\n",
      "Itr: 2\tEpoch: 15\tTrain Acc: 0.68028\tTest Acc: 0.6984\n",
      "Itr: 2\tEpoch: 16\tTrain Acc: 0.68404\tTest Acc: 0.7068\n",
      "Itr: 2\tEpoch: 17\tTrain Acc: 0.69262\tTest Acc: 0.6955\n",
      "Itr: 2\tEpoch: 18\tTrain Acc: 0.69562\tTest Acc: 0.7049\n",
      "Itr: 2\tEpoch: 19\tTrain Acc: 0.69968\tTest Acc: 0.686\n",
      "Itr: 2\tEpoch: 20\tTrain Acc: 0.7042\tTest Acc: 0.7162\n",
      "Itr: 2\tEpoch: 21\tTrain Acc: 0.70854\tTest Acc: 0.7066\n",
      "Itr: 2\tEpoch: 22\tTrain Acc: 0.71384\tTest Acc: 0.726\n",
      "Itr: 2\tEpoch: 23\tTrain Acc: 0.71766\tTest Acc: 0.7177\n",
      "Itr: 2\tEpoch: 24\tTrain Acc: 0.72272\tTest Acc: 0.7088\n",
      "Itr: 2\tEpoch: 25\tTrain Acc: 0.72852\tTest Acc: 0.7167\n",
      "Itr: 2\tEpoch: 26\tTrain Acc: 0.72872\tTest Acc: 0.7335\n",
      "Itr: 2\tEpoch: 27\tTrain Acc: 0.73538\tTest Acc: 0.7054\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from utils import get_dataset, get_network, get_daparam, TensorDataset, epoch, ParamDiffAug\n",
    "import copy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    args.dsa = True if args.dsa == 'True' else False\n",
    "    args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    args.dsa_param = ParamDiffAug()\n",
    "\n",
    "    channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader, loader_train_dict, class_map, class_map_inv = get_dataset(args.dataset, args.data_path, args.batch_real, args.subset, args=args)\n",
    "\n",
    "    # print('\\n================== Exp %d ==================\\n '%exp)\n",
    "    print('Hyper-parameters: \\n', args.__dict__)\n",
    "\n",
    "    save_dir = os.path.join(args.buffer_path, args.dataset)\n",
    "    if args.dataset == \"ImageNet\":\n",
    "        save_dir = os.path.join(save_dir, args.subset, str(args.res))\n",
    "    if args.dataset in [\"CIFAR10\", \"CIFAR100\"] and not args.zca:\n",
    "        save_dir += \"_NO_ZCA\"\n",
    "    save_dir = os.path.join(save_dir, args.model)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "\n",
    "    ''' organize the real dataset '''\n",
    "    images_all = []\n",
    "    labels_all = []\n",
    "    indices_class = [[] for c in range(num_classes)]\n",
    "    print(\"BUILDING DATASET\")\n",
    "    for i in tqdm(range(len(dst_train))):\n",
    "        sample = dst_train[i]\n",
    "        images_all.append(torch.unsqueeze(sample[0], dim=0))\n",
    "        labels_all.append(class_map[torch.tensor(sample[1]).item()])\n",
    "\n",
    "    for i, lab in tqdm(enumerate(labels_all)):\n",
    "        indices_class[lab].append(i)\n",
    "    images_all = torch.cat(images_all, dim=0).to(\"cpu\")\n",
    "    labels_all = torch.tensor(labels_all, dtype=torch.long, device=\"cpu\")\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        print('class c = %d: %d real images'%(c, len(indices_class[c])))\n",
    "\n",
    "    for ch in range(channel):\n",
    "        print('real images channel %d, mean = %.4f, std = %.4f'%(ch, torch.mean(images_all[:, ch]), torch.std(images_all[:, ch])))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(args.device)\n",
    "\n",
    "    trajectories = []\n",
    "\n",
    "    dst_train = TensorDataset(copy.deepcopy(images_all.detach()), copy.deepcopy(labels_all.detach()))\n",
    "    trainloader = torch.utils.data.DataLoader(dst_train, batch_size=args.batch_train, shuffle=True, num_workers=0)\n",
    "\n",
    "    ''' set augmentation for whole-dataset training '''\n",
    "    args.dc_aug_param = get_daparam(args.dataset, args.model, args.model, None)\n",
    "    args.dc_aug_param['strategy'] = 'crop_scale_rotate'  # for whole-dataset training\n",
    "    print('DC augmentation parameters: \\n', args.dc_aug_param)\n",
    "\n",
    "    for it in range(0, args.num_experts):\n",
    "\n",
    "        ''' Train synthetic data '''\n",
    "        teacher_net = get_network(args.model, channel, num_classes, im_size).to(args.device) # get a random model\n",
    "        teacher_net.train()\n",
    "        lr = args.lr_teacher\n",
    "        teacher_optim = torch.optim.SGD(teacher_net.parameters(), lr=lr, momentum=args.mom, weight_decay=args.l2)  # optimizer_img for synthetic data\n",
    "        teacher_optim.zero_grad()\n",
    "\n",
    "        timestamps = []\n",
    "\n",
    "        timestamps.append([p.detach().cpu() for p in teacher_net.parameters()])\n",
    "\n",
    "        lr_schedule = [args.train_epochs // 2 + 1]\n",
    "\n",
    "        for e in range(args.train_epochs):\n",
    "\n",
    "            train_loss, train_acc = epoch(\"train\", dataloader=trainloader, net=teacher_net, optimizer=teacher_optim,\n",
    "                                        criterion=criterion, args=args, aug=True)\n",
    "\n",
    "            test_loss, test_acc = epoch(\"test\", dataloader=testloader, net=teacher_net, optimizer=None,\n",
    "                                        criterion=criterion, args=args, aug=False)\n",
    "\n",
    "            print(\"Itr: {}\\tEpoch: {}\\tTrain Acc: {}\\tTest Acc: {}\".format(it, e, train_acc, test_acc))\n",
    "\n",
    "            timestamps.append([p.detach().cpu() for p in teacher_net.parameters()])\n",
    "\n",
    "            if e in lr_schedule and args.decay:\n",
    "                lr *= 0.1\n",
    "                teacher_optim = torch.optim.SGD(teacher_net.parameters(), lr=lr, momentum=args.mom, weight_decay=args.l2)\n",
    "                teacher_optim.zero_grad()\n",
    "\n",
    "        trajectories.append(timestamps)\n",
    "\n",
    "        if len(trajectories) == args.save_interval:\n",
    "            n = 0\n",
    "            while os.path.exists(os.path.join(save_dir, \"replay_buffer_{}.pt\".format(n))):\n",
    "                n += 1\n",
    "            print(\"Saving {}\".format(os.path.join(save_dir, \"replay_buffer_{}.pt\".format(n))))\n",
    "            torch.save(trajectories, os.path.join(save_dir, \"replay_buffer_{}.pt\".format(n)))\n",
    "            trajectories = []\n",
    "\n",
    "\n",
    "class arguments():\n",
    "    def __init__(self,): \n",
    "        self.dataset = 'CIFAR10'\n",
    "        self.subset = 'imagenette'\n",
    "        self.model = 'ConvNet'\n",
    "        self.num_experts = 10\n",
    "        self.lr_teacher = 0.01\n",
    "        self.batch_real = 256\n",
    "        self.batch_train = 256\n",
    "        self.dsa = 'False'\n",
    "        self.dsa_strategy = 'color_crop_cutout_flip_scale_rotate'\n",
    "        self.data_path = 'CIFAR10data'\n",
    "        self.buffer_path = './CIFAR10buffers'\n",
    "        self.train_epochs = 30\n",
    "        self.zca = False\n",
    "        self.decay = False\n",
    "        self.mom = 0\n",
    "        self.l2 = 0\n",
    "        self.save_interval = 5\n",
    "\n",
    "args = arguments()\n",
    "main(args)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f384fc57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
